{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DuFAjgQZSSdk"
   },
   "source": [
    "# Regresiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBsUi_s0SSdm"
   },
   "source": [
    "## Preparación de ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AVvg1dlSSdm"
   },
   "source": [
    "### Carga de módulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T13:30:18.306598Z",
     "start_time": "2026-01-17T13:30:17.699359Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:17:27.933371Z",
     "iopub.status.busy": "2024-02-23T01:17:27.932402Z",
     "iopub.status.idle": "2024-02-23T01:17:29.152451Z",
     "shell.execute_reply": "2024-02-23T01:17:29.151489Z",
     "shell.execute_reply.started": "2024-02-23T01:17:27.933301Z"
    },
    "id": "IYPSDT0RSSdm",
    "outputId": "eddb4f44-bebc-4320-d7c8-5b6f91f8b19d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.4.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.4.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# Data Viz\n",
    "import cufflinks as cf\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Lars, ElasticNet, Lasso, Ridge, BayesianRidge\n",
    "\n",
    "# Enviroment setup\n",
    "cf.go_offline()\n",
    "pd.set_option('display.float_format', lambda x: \"{:,.5f}\".format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDmT3TvfSSdn"
   },
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYXBhHZdSSdn"
   },
   "source": [
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T13:29:59.521890Z",
     "start_time": "2026-01-17T13:29:59.505302Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:17:41.097494Z",
     "iopub.status.busy": "2024-02-23T01:17:41.094837Z",
     "iopub.status.idle": "2024-02-23T01:17:41.115230Z",
     "shell.execute_reply": "2024-02-23T01:17:41.114747Z",
     "shell.execute_reply.started": "2024-02-23T01:17:41.097363Z"
    },
    "id": "bt_1QLI1SSdn",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning:\n",
      "\n",
      "Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this case special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows:\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and:\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:46:56.375198Z",
     "start_time": "2024-10-05T13:46:56.362063Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:18:31.628991Z",
     "iopub.status.busy": "2024-02-23T01:18:31.627934Z",
     "iopub.status.idle": "2024-02-23T01:18:31.665975Z",
     "shell.execute_reply": "2024-02-23T01:18:31.663324Z",
     "shell.execute_reply.started": "2024-02-23T01:18:31.628914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': 'boston_house_prices.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNXLW7ElSSdn"
   },
   "source": [
    "#### Creación de TAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:46:56.814124Z",
     "start_time": "2024-10-05T13:46:56.810820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(boston['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:46:57.067637Z",
     "start_time": "2024-10-05T13:46:57.063762Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:18:49.930200Z",
     "iopub.status.busy": "2024-02-23T01:18:49.929866Z",
     "iopub.status.idle": "2024-02-23T01:18:49.935320Z",
     "shell.execute_reply": "2024-02-23T01:18:49.934353Z",
     "shell.execute_reply.started": "2024-02-23T01:18:49.930176Z"
    },
    "id": "epIvGdIDSSdn"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = boston[\"data\"], columns=boston[\"feature_names\"])\n",
    "df[\"target\"] = boston[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAEzQ96WSSdo"
   },
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:46:57.584011Z",
     "start_time": "2024-10-05T13:46:57.571957Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:18:51.489617Z",
     "iopub.status.busy": "2024-02-23T01:18:51.489121Z",
     "iopub.status.idle": "2024-02-23T01:18:51.507262Z",
     "shell.execute_reply": "2024-02-23T01:18:51.506165Z",
     "shell.execute_reply.started": "2024-02-23T01:18:51.489590Z"
    },
    "id": "xPBzcbZtSSdo",
    "outputId": "adc61bec-5f18-44e8-cdef-fc598f171580"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>2.31000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.53800</td>\n",
       "      <td>6.57500</td>\n",
       "      <td>65.20000</td>\n",
       "      <td>4.09000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>296.00000</td>\n",
       "      <td>15.30000</td>\n",
       "      <td>396.90000</td>\n",
       "      <td>4.98000</td>\n",
       "      <td>24.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.07000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.46900</td>\n",
       "      <td>6.42100</td>\n",
       "      <td>78.90000</td>\n",
       "      <td>4.96710</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>242.00000</td>\n",
       "      <td>17.80000</td>\n",
       "      <td>396.90000</td>\n",
       "      <td>9.14000</td>\n",
       "      <td>21.60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.07000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.46900</td>\n",
       "      <td>7.18500</td>\n",
       "      <td>61.10000</td>\n",
       "      <td>4.96710</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>242.00000</td>\n",
       "      <td>17.80000</td>\n",
       "      <td>392.83000</td>\n",
       "      <td>4.03000</td>\n",
       "      <td>34.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.18000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.45800</td>\n",
       "      <td>6.99800</td>\n",
       "      <td>45.80000</td>\n",
       "      <td>6.06220</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>222.00000</td>\n",
       "      <td>18.70000</td>\n",
       "      <td>394.63000</td>\n",
       "      <td>2.94000</td>\n",
       "      <td>33.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.18000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.45800</td>\n",
       "      <td>7.14700</td>\n",
       "      <td>54.20000</td>\n",
       "      <td>6.06220</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>222.00000</td>\n",
       "      <td>18.70000</td>\n",
       "      <td>396.90000</td>\n",
       "      <td>5.33000</td>\n",
       "      <td>36.20000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CRIM       ZN   INDUS    CHAS     NOX      RM      AGE     DIS     RAD  \\\n",
       "0 0.00632 18.00000 2.31000 0.00000 0.53800 6.57500 65.20000 4.09000 1.00000   \n",
       "1 0.02731  0.00000 7.07000 0.00000 0.46900 6.42100 78.90000 4.96710 2.00000   \n",
       "2 0.02729  0.00000 7.07000 0.00000 0.46900 7.18500 61.10000 4.96710 2.00000   \n",
       "3 0.03237  0.00000 2.18000 0.00000 0.45800 6.99800 45.80000 6.06220 3.00000   \n",
       "4 0.06905  0.00000 2.18000 0.00000 0.45800 7.14700 54.20000 6.06220 3.00000   \n",
       "\n",
       "        TAX  PTRATIO         B   LSTAT   target  \n",
       "0 296.00000 15.30000 396.90000 4.98000 24.00000  \n",
       "1 242.00000 17.80000 396.90000 9.14000 21.60000  \n",
       "2 242.00000 17.80000 392.83000 4.03000 34.70000  \n",
       "3 222.00000 18.70000 394.63000 2.94000 33.40000  \n",
       "4 222.00000 18.70000 396.90000 5.33000 36.20000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:46:57.814238Z",
     "start_time": "2024-10-05T13:46:57.811030Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:18:56.724080Z",
     "iopub.status.busy": "2024-02-23T01:18:56.723097Z",
     "iopub.status.idle": "2024-02-23T01:18:56.736147Z",
     "shell.execute_reply": "2024-02-23T01:18:56.733407Z",
     "shell.execute_reply.started": "2024-02-23T01:18:56.724011Z"
    },
    "id": "bCz7xW7dSSdo",
    "outputId": "f6bda766-c61a-4362-c5ff-06f26a9d86f1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(boston[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UQwEi0bSSdo"
   },
   "source": [
    "### Segmentación de sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:46:58.250961Z",
     "start_time": "2024-10-05T13:46:58.248102Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:23:26.677220Z",
     "iopub.status.busy": "2024-02-23T01:23:26.676110Z",
     "iopub.status.idle": "2024-02-23T01:23:26.690790Z",
     "shell.execute_reply": "2024-02-23T01:23:26.687480Z",
     "shell.execute_reply.started": "2024-02-23T01:23:26.677120Z"
    },
    "id": "cJymR8OJSSdo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tgt = \"target\"\n",
    "ls_pred = [x for x in df.columns if x not in [tgt]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:46:58.464429Z",
     "start_time": "2024-10-05T13:46:58.460129Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:23:33.915519Z",
     "iopub.status.busy": "2024-02-23T01:23:33.914520Z",
     "iopub.status.idle": "2024-02-23T01:23:33.943151Z",
     "shell.execute_reply": "2024-02-23T01:23:33.939412Z",
     "shell.execute_reply.started": "2024-02-23T01:23:33.915442Z"
    },
    "id": "e56aWn59SSdo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df[ls_pred]\n",
    "y = df[tgt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:46:58.695184Z",
     "start_time": "2024-10-05T13:46:58.680696Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:23:34.653304Z",
     "iopub.status.busy": "2024-02-23T01:23:34.652016Z",
     "iopub.status.idle": "2024-02-23T01:23:34.704895Z",
     "shell.execute_reply": "2024-02-23T01:23:34.701824Z",
     "shell.execute_reply.started": "2024-02-23T01:23:34.653211Z"
    },
    "id": "yl7A9lE9SSdo",
    "outputId": "41c7cc71-123b-415e-e75c-f4136cfebf6f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>2.31000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.53800</td>\n",
       "      <td>6.57500</td>\n",
       "      <td>65.20000</td>\n",
       "      <td>4.09000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>296.00000</td>\n",
       "      <td>15.30000</td>\n",
       "      <td>396.90000</td>\n",
       "      <td>4.98000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.07000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.46900</td>\n",
       "      <td>6.42100</td>\n",
       "      <td>78.90000</td>\n",
       "      <td>4.96710</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>242.00000</td>\n",
       "      <td>17.80000</td>\n",
       "      <td>396.90000</td>\n",
       "      <td>9.14000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.07000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.46900</td>\n",
       "      <td>7.18500</td>\n",
       "      <td>61.10000</td>\n",
       "      <td>4.96710</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>242.00000</td>\n",
       "      <td>17.80000</td>\n",
       "      <td>392.83000</td>\n",
       "      <td>4.03000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.18000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.45800</td>\n",
       "      <td>6.99800</td>\n",
       "      <td>45.80000</td>\n",
       "      <td>6.06220</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>222.00000</td>\n",
       "      <td>18.70000</td>\n",
       "      <td>394.63000</td>\n",
       "      <td>2.94000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.18000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.45800</td>\n",
       "      <td>7.14700</td>\n",
       "      <td>54.20000</td>\n",
       "      <td>6.06220</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>222.00000</td>\n",
       "      <td>18.70000</td>\n",
       "      <td>396.90000</td>\n",
       "      <td>5.33000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11.93000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57300</td>\n",
       "      <td>6.59300</td>\n",
       "      <td>69.10000</td>\n",
       "      <td>2.47860</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>273.00000</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>391.99000</td>\n",
       "      <td>9.67000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11.93000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57300</td>\n",
       "      <td>6.12000</td>\n",
       "      <td>76.70000</td>\n",
       "      <td>2.28750</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>273.00000</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>396.90000</td>\n",
       "      <td>9.08000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11.93000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57300</td>\n",
       "      <td>6.97600</td>\n",
       "      <td>91.00000</td>\n",
       "      <td>2.16750</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>273.00000</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>396.90000</td>\n",
       "      <td>5.64000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11.93000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57300</td>\n",
       "      <td>6.79400</td>\n",
       "      <td>89.30000</td>\n",
       "      <td>2.38890</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>273.00000</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>393.45000</td>\n",
       "      <td>6.48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11.93000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57300</td>\n",
       "      <td>6.03000</td>\n",
       "      <td>80.80000</td>\n",
       "      <td>2.50500</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>273.00000</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>396.90000</td>\n",
       "      <td>7.88000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM       ZN    INDUS    CHAS     NOX      RM      AGE     DIS  \\\n",
       "0   0.00632 18.00000  2.31000 0.00000 0.53800 6.57500 65.20000 4.09000   \n",
       "1   0.02731  0.00000  7.07000 0.00000 0.46900 6.42100 78.90000 4.96710   \n",
       "2   0.02729  0.00000  7.07000 0.00000 0.46900 7.18500 61.10000 4.96710   \n",
       "3   0.03237  0.00000  2.18000 0.00000 0.45800 6.99800 45.80000 6.06220   \n",
       "4   0.06905  0.00000  2.18000 0.00000 0.45800 7.14700 54.20000 6.06220   \n",
       "..      ...      ...      ...     ...     ...     ...      ...     ...   \n",
       "501 0.06263  0.00000 11.93000 0.00000 0.57300 6.59300 69.10000 2.47860   \n",
       "502 0.04527  0.00000 11.93000 0.00000 0.57300 6.12000 76.70000 2.28750   \n",
       "503 0.06076  0.00000 11.93000 0.00000 0.57300 6.97600 91.00000 2.16750   \n",
       "504 0.10959  0.00000 11.93000 0.00000 0.57300 6.79400 89.30000 2.38890   \n",
       "505 0.04741  0.00000 11.93000 0.00000 0.57300 6.03000 80.80000 2.50500   \n",
       "\n",
       "        RAD       TAX  PTRATIO         B   LSTAT  \n",
       "0   1.00000 296.00000 15.30000 396.90000 4.98000  \n",
       "1   2.00000 242.00000 17.80000 396.90000 9.14000  \n",
       "2   2.00000 242.00000 17.80000 392.83000 4.03000  \n",
       "3   3.00000 222.00000 18.70000 394.63000 2.94000  \n",
       "4   3.00000 222.00000 18.70000 396.90000 5.33000  \n",
       "..      ...       ...      ...       ...     ...  \n",
       "501 1.00000 273.00000 21.00000 391.99000 9.67000  \n",
       "502 1.00000 273.00000 21.00000 396.90000 9.08000  \n",
       "503 1.00000 273.00000 21.00000 396.90000 5.64000  \n",
       "504 1.00000 273.00000 21.00000 393.45000 6.48000  \n",
       "505 1.00000 273.00000 21.00000 396.90000 7.88000  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzIwKfIgSSdo"
   },
   "source": [
    "## Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsrpMhenSSdo"
   },
   "source": [
    "### Regresión Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0DsJxanSSdo"
   },
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:46:59.663472Z",
     "start_time": "2024-10-05T13:46:59.660936Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:23:51.247529Z",
     "iopub.status.busy": "2024-02-23T01:23:51.246488Z",
     "iopub.status.idle": "2024-02-23T01:23:51.257587Z",
     "shell.execute_reply": "2024-02-23T01:23:51.254567Z",
     "shell.execute_reply.started": "2024-02-23T01:23:51.247439Z"
    },
    "id": "p7BIEkpTSSdo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:46:59.899014Z",
     "start_time": "2024-10-05T13:46:59.892479Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:23:54.166795Z",
     "iopub.status.busy": "2024-02-23T01:23:54.164894Z",
     "iopub.status.idle": "2024-02-23T01:23:54.216567Z",
     "shell.execute_reply": "2024-02-23T01:23:54.213544Z",
     "shell.execute_reply.started": "2024-02-23T01:23:54.166687Z"
    },
    "id": "dqKwMAMmSSdo",
    "outputId": "42c447dc-be69-42d7-b18d-6d567993122e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFE2A5o6SSdo"
   },
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:01.003192Z",
     "start_time": "2024-10-05T13:47:00.360659Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:24:06.917543Z",
     "iopub.status.busy": "2024-02-23T01:24:06.916742Z",
     "iopub.status.idle": "2024-02-23T01:24:08.255021Z",
     "shell.execute_reply": "2024-02-23T01:24:08.254274Z",
     "shell.execute_reply.started": "2024-02-23T01:24:06.917474Z"
    },
    "id": "YrYe3c3rSSdo",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "ls_res = cross_val_score(estimator = linreg, X=X, y=y, cv=4, n_jobs=-1, scoring=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:01.034599Z",
     "start_time": "2024-10-05T13:47:01.031281Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:26:38.745777Z",
     "iopub.status.busy": "2024-02-23T01:26:38.743394Z",
     "iopub.status.idle": "2024-02-23T01:26:38.767418Z",
     "shell.execute_reply": "2024-02-23T01:26:38.764264Z",
     "shell.execute_reply.started": "2024-02-23T01:26:38.745650Z"
    },
    "id": "xSILM8CmSSdo",
    "outputId": "c95e4736-4607-40cb-8d2c-2c9d81c410c9",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11405301290101522, 0.712956573713099)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ls_res), np.std(ls_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:01.056977Z",
     "start_time": "2024-10-05T13:47:01.053926Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:28:36.444931Z",
     "iopub.status.busy": "2024-02-23T01:28:36.443432Z",
     "iopub.status.idle": "2024-02-23T01:28:36.459851Z",
     "shell.execute_reply": "2024-02-23T01:28:36.457157Z",
     "shell.execute_reply.started": "2024-02-23T01:28:36.444852Z"
    },
    "id": "Lm_pt4xhSSdo",
    "outputId": "c1badb7d-9531-4e84-abe8-86f03812902d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.45948838508978"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:01.088224Z",
     "start_time": "2024-10-05T13:47:01.081780Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:28:55.941909Z",
     "iopub.status.busy": "2024-02-23T01:28:55.941180Z",
     "iopub.status.idle": "2024-02-23T01:28:55.970878Z",
     "shell.execute_reply": "2024-02-23T01:28:55.968261Z",
     "shell.execute_reply.started": "2024-02-23T01:28:55.941847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   506.00000\n",
       "mean     22.53281\n",
       "std       9.19710\n",
       "min       5.00000\n",
       "25%      17.02500\n",
       "50%      21.20000\n",
       "75%      25.00000\n",
       "max      50.00000\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:01.289831Z",
     "start_time": "2024-10-05T13:47:01.275656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.53281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.91508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.28131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.44574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.11865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.41002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>44.67308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          y_hat\n",
       "count 506.00000\n",
       "mean   22.53281\n",
       "std     7.91508\n",
       "min    -4.28131\n",
       "25%    17.44574\n",
       "50%    22.11865\n",
       "75%    27.41002\n",
       "max    44.67308"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(linreg.predict(X),columns=['y_hat']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVM-vYADSSdo"
   },
   "source": [
    "#### Pre-análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:01.836929Z",
     "start_time": "2024-10-05T13:47:01.827717Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:29:32.834670Z",
     "iopub.status.busy": "2024-02-23T01:29:32.833882Z",
     "iopub.status.idle": "2024-02-23T01:29:32.869378Z",
     "shell.execute_reply": "2024-02-23T01:29:32.865743Z",
     "shell.execute_reply.started": "2024-02-23T01:29:32.834600Z"
    },
    "id": "9umspZ7KSSdp",
    "outputId": "f5fbf2e1-d2e3-48d3-926a-ab9678be3972",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>-17.76661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-1.47557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-0.95275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-0.52476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.10801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.01233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.00069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.00931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>0.02056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.04642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.30605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>2.68673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>3.80987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "4       NOX -17.76661\n",
       "7       DIS  -1.47557\n",
       "10  PTRATIO  -0.95275\n",
       "12    LSTAT  -0.52476\n",
       "0      CRIM  -0.10801\n",
       "9       TAX  -0.01233\n",
       "6       AGE   0.00069\n",
       "11        B   0.00931\n",
       "2     INDUS   0.02056\n",
       "1        ZN   0.04642\n",
       "8       RAD   0.30605\n",
       "3      CHAS   2.68673\n",
       "5        RM   3.80987"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip(X.columns, linreg.coef_)).sort_values(by=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:02.125219Z",
     "start_time": "2024-10-05T13:47:02.115633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>17.76661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>3.80987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>2.68673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>1.47557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>0.95275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>0.52476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.30605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>0.10801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.04642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>0.02056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>0.01233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.00931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.00069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1\n",
       "4       NOX 17.76661\n",
       "5        RM  3.80987\n",
       "3      CHAS  2.68673\n",
       "7       DIS  1.47557\n",
       "10  PTRATIO  0.95275\n",
       "12    LSTAT  0.52476\n",
       "8       RAD  0.30605\n",
       "0      CRIM  0.10801\n",
       "1        ZN  0.04642\n",
       "2     INDUS  0.02056\n",
       "9       TAX  0.01233\n",
       "11        B  0.00931\n",
       "6       AGE  0.00069"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip(X.columns, pd.Series(linreg.coef_).map(abs))).sort_values(by=1,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>506.00000</td>\n",
       "      <td>3.61352</td>\n",
       "      <td>8.60155</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>0.08204</td>\n",
       "      <td>0.25651</td>\n",
       "      <td>3.67708</td>\n",
       "      <td>88.97620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>506.00000</td>\n",
       "      <td>11.36364</td>\n",
       "      <td>23.32245</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>12.50000</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>506.00000</td>\n",
       "      <td>11.13678</td>\n",
       "      <td>6.86035</td>\n",
       "      <td>0.46000</td>\n",
       "      <td>5.19000</td>\n",
       "      <td>9.69000</td>\n",
       "      <td>18.10000</td>\n",
       "      <td>27.74000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>506.00000</td>\n",
       "      <td>0.06917</td>\n",
       "      <td>0.25399</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>506.00000</td>\n",
       "      <td>0.55470</td>\n",
       "      <td>0.11588</td>\n",
       "      <td>0.38500</td>\n",
       "      <td>0.44900</td>\n",
       "      <td>0.53800</td>\n",
       "      <td>0.62400</td>\n",
       "      <td>0.87100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>506.00000</td>\n",
       "      <td>6.28463</td>\n",
       "      <td>0.70262</td>\n",
       "      <td>3.56100</td>\n",
       "      <td>5.88550</td>\n",
       "      <td>6.20850</td>\n",
       "      <td>6.62350</td>\n",
       "      <td>8.78000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>506.00000</td>\n",
       "      <td>68.57490</td>\n",
       "      <td>28.14886</td>\n",
       "      <td>2.90000</td>\n",
       "      <td>45.02500</td>\n",
       "      <td>77.50000</td>\n",
       "      <td>94.07500</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>506.00000</td>\n",
       "      <td>3.79504</td>\n",
       "      <td>2.10571</td>\n",
       "      <td>1.12960</td>\n",
       "      <td>2.10018</td>\n",
       "      <td>3.20745</td>\n",
       "      <td>5.18843</td>\n",
       "      <td>12.12650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>506.00000</td>\n",
       "      <td>9.54941</td>\n",
       "      <td>8.70726</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>24.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>506.00000</td>\n",
       "      <td>408.23715</td>\n",
       "      <td>168.53712</td>\n",
       "      <td>187.00000</td>\n",
       "      <td>279.00000</td>\n",
       "      <td>330.00000</td>\n",
       "      <td>666.00000</td>\n",
       "      <td>711.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>506.00000</td>\n",
       "      <td>18.45553</td>\n",
       "      <td>2.16495</td>\n",
       "      <td>12.60000</td>\n",
       "      <td>17.40000</td>\n",
       "      <td>19.05000</td>\n",
       "      <td>20.20000</td>\n",
       "      <td>22.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>506.00000</td>\n",
       "      <td>356.67403</td>\n",
       "      <td>91.29486</td>\n",
       "      <td>0.32000</td>\n",
       "      <td>375.37750</td>\n",
       "      <td>391.44000</td>\n",
       "      <td>396.22500</td>\n",
       "      <td>396.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>506.00000</td>\n",
       "      <td>12.65306</td>\n",
       "      <td>7.14106</td>\n",
       "      <td>1.73000</td>\n",
       "      <td>6.95000</td>\n",
       "      <td>11.36000</td>\n",
       "      <td>16.95500</td>\n",
       "      <td>37.97000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count      mean       std       min       25%       50%       75%  \\\n",
       "CRIM    506.00000   3.61352   8.60155   0.00632   0.08204   0.25651   3.67708   \n",
       "ZN      506.00000  11.36364  23.32245   0.00000   0.00000   0.00000  12.50000   \n",
       "INDUS   506.00000  11.13678   6.86035   0.46000   5.19000   9.69000  18.10000   \n",
       "CHAS    506.00000   0.06917   0.25399   0.00000   0.00000   0.00000   0.00000   \n",
       "NOX     506.00000   0.55470   0.11588   0.38500   0.44900   0.53800   0.62400   \n",
       "RM      506.00000   6.28463   0.70262   3.56100   5.88550   6.20850   6.62350   \n",
       "AGE     506.00000  68.57490  28.14886   2.90000  45.02500  77.50000  94.07500   \n",
       "DIS     506.00000   3.79504   2.10571   1.12960   2.10018   3.20745   5.18843   \n",
       "RAD     506.00000   9.54941   8.70726   1.00000   4.00000   5.00000  24.00000   \n",
       "TAX     506.00000 408.23715 168.53712 187.00000 279.00000 330.00000 666.00000   \n",
       "PTRATIO 506.00000  18.45553   2.16495  12.60000  17.40000  19.05000  20.20000   \n",
       "B       506.00000 356.67403  91.29486   0.32000 375.37750 391.44000 396.22500   \n",
       "LSTAT   506.00000  12.65306   7.14106   1.73000   6.95000  11.36000  16.95500   \n",
       "\n",
       "              max  \n",
       "CRIM     88.97620  \n",
       "ZN      100.00000  \n",
       "INDUS    27.74000  \n",
       "CHAS      1.00000  \n",
       "NOX       0.87100  \n",
       "RM        8.78000  \n",
       "AGE     100.00000  \n",
       "DIS      12.12650  \n",
       "RAD      24.00000  \n",
       "TAX     711.00000  \n",
       "PTRATIO  22.00000  \n",
       "B       396.90000  \n",
       "LSTAT    37.97000  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:02.350633Z",
     "start_time": "2024-10-05T13:47:02.347945Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:31:06.967675Z",
     "iopub.status.busy": "2024-02-23T01:31:06.966404Z",
     "iopub.status.idle": "2024-02-23T01:31:06.982777Z",
     "shell.execute_reply": "2024-02-23T01:31:06.979270Z",
     "shell.execute_reply.started": "2024-02-23T01:31:06.967558Z"
    },
    "id": "Pk1K3kAgSSdp"
   },
   "outputs": [],
   "source": [
    "dc_scores = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:02.591059Z",
     "start_time": "2024-10-05T13:47:02.587685Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:31:57.572393Z",
     "iopub.status.busy": "2024-02-23T01:31:57.571195Z",
     "iopub.status.idle": "2024-02-23T01:31:57.590271Z",
     "shell.execute_reply": "2024-02-23T01:31:57.587508Z",
     "shell.execute_reply.started": "2024-02-23T01:31:57.572286Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LinearRegression'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(linreg).split(\"(\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:02.822685Z",
     "start_time": "2024-10-05T13:47:02.819512Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:32:03.491004Z",
     "iopub.status.busy": "2024-02-23T01:32:03.489115Z",
     "iopub.status.idle": "2024-02-23T01:32:03.506083Z",
     "shell.execute_reply": "2024-02-23T01:32:03.502966Z",
     "shell.execute_reply.started": "2024-02-23T01:32:03.490890Z"
    },
    "id": "I_DQQemgSSdp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dc_scores.update({str(linreg).split(\"(\")[0]: np.mean(ls_res)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:03.055888Z",
     "start_time": "2024-10-05T13:47:03.052243Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:32:03.887290Z",
     "iopub.status.busy": "2024-02-23T01:32:03.886484Z",
     "iopub.status.idle": "2024-02-23T01:32:03.899767Z",
     "shell.execute_reply": "2024-02-23T01:32:03.897015Z",
     "shell.execute_reply.started": "2024-02-23T01:32:03.887222Z"
    },
    "id": "Y_CperTLSSdp",
    "outputId": "71f4bb55-f148-4ff4-f209-8788255ab33c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression': 0.11405301290101522}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlkGGzODSSdp"
   },
   "source": [
    "### Regresión LARS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtyKleAKSSdp"
   },
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T14:27:18.683571Z",
     "start_time": "2024-10-05T14:27:18.675799Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:32:29.396917Z",
     "iopub.status.busy": "2024-02-23T01:32:29.395702Z",
     "iopub.status.idle": "2024-02-23T01:32:29.557160Z",
     "shell.execute_reply": "2024-02-23T01:32:29.553944Z",
     "shell.execute_reply.started": "2024-02-23T01:32:29.396818Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mLars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprecompute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_nonzero_coefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.220446049250313e-16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcopy_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfit_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mjitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Least Angle Regression model a.k.a. LAR.\n",
      "\n",
      "Read more in the :ref:`User Guide <least_angle_regression>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "fit_intercept : bool, default=True\n",
      "    Whether to calculate the intercept for this model. If set\n",
      "    to false, no intercept will be used in calculations\n",
      "    (i.e. data is expected to be centered).\n",
      "\n",
      "verbose : bool or int, default=False\n",
      "    Sets the verbosity amount.\n",
      "\n",
      "normalize : bool, default=True\n",
      "    This parameter is ignored when ``fit_intercept`` is set to False.\n",
      "    If True, the regressors X will be normalized before regression by\n",
      "    subtracting the mean and dividing by the l2-norm.\n",
      "    If you wish to standardize, please use\n",
      "    :class:`~sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
      "    on an estimator with ``normalize=False``.\n",
      "\n",
      "    .. deprecated:: 1.0\n",
      "        ``normalize`` was deprecated in version 1.0. It will default\n",
      "        to False in 1.2 and be removed in 1.4.\n",
      "\n",
      "precompute : bool, 'auto' or array-like , default='auto'\n",
      "    Whether to use a precomputed Gram matrix to speed up\n",
      "    calculations. If set to ``'auto'`` let us decide. The Gram\n",
      "    matrix can also be passed as argument.\n",
      "\n",
      "n_nonzero_coefs : int, default=500\n",
      "    Target number of non-zero coefficients. Use ``np.inf`` for no limit.\n",
      "\n",
      "eps : float, default=np.finfo(float).eps\n",
      "    The machine-precision regularization in the computation of the\n",
      "    Cholesky diagonal factors. Increase this for very ill-conditioned\n",
      "    systems. Unlike the ``tol`` parameter in some iterative\n",
      "    optimization-based algorithms, this parameter does not control\n",
      "    the tolerance of the optimization.\n",
      "\n",
      "copy_X : bool, default=True\n",
      "    If ``True``, X will be copied; else, it may be overwritten.\n",
      "\n",
      "fit_path : bool, default=True\n",
      "    If True the full path is stored in the ``coef_path_`` attribute.\n",
      "    If you compute the solution for a large problem or many targets,\n",
      "    setting ``fit_path`` to ``False`` will lead to a speedup, especially\n",
      "    with a small alpha.\n",
      "\n",
      "jitter : float, default=None\n",
      "    Upper bound on a uniform noise parameter to be added to the\n",
      "    `y` values, to satisfy the model's assumption of\n",
      "    one-at-a-time computations. Might help with stability.\n",
      "\n",
      "    .. versionadded:: 0.23\n",
      "\n",
      "random_state : int, RandomState instance or None, default=None\n",
      "    Determines random number generation for jittering. Pass an int\n",
      "    for reproducible output across multiple function calls.\n",
      "    See :term:`Glossary <random_state>`. Ignored if `jitter` is None.\n",
      "\n",
      "    .. versionadded:: 0.23\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "alphas_ : array-like of shape (n_alphas + 1,) or list of such arrays\n",
      "    Maximum of covariances (in absolute value) at each iteration.\n",
      "    ``n_alphas`` is either ``max_iter``, ``n_features`` or the\n",
      "    number of nodes in the path with ``alpha >= alpha_min``, whichever\n",
      "    is smaller. If this is a list of array-like, the length of the outer\n",
      "    list is `n_targets`.\n",
      "\n",
      "active_ : list of shape (n_alphas,) or list of such lists\n",
      "    Indices of active variables at the end of the path.\n",
      "    If this is a list of list, the length of the outer list is `n_targets`.\n",
      "\n",
      "coef_path_ : array-like of shape (n_features, n_alphas + 1) or list             of such arrays\n",
      "    The varying values of the coefficients along the path. It is not\n",
      "    present if the ``fit_path`` parameter is ``False``. If this is a list\n",
      "    of array-like, the length of the outer list is `n_targets`.\n",
      "\n",
      "coef_ : array-like of shape (n_features,) or (n_targets, n_features)\n",
      "    Parameter vector (w in the formulation formula).\n",
      "\n",
      "intercept_ : float or array-like of shape (n_targets,)\n",
      "    Independent term in decision function.\n",
      "\n",
      "n_iter_ : array-like or int\n",
      "    The number of iterations taken by lars_path to find the\n",
      "    grid of alphas for each target.\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Defined only when `X`\n",
      "    has feature names that are all strings.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "See Also\n",
      "--------\n",
      "lars_path: Compute Least Angle Regression or Lasso\n",
      "    path using LARS algorithm.\n",
      "LarsCV : Cross-validated Least Angle Regression model.\n",
      "sklearn.decomposition.sparse_encode : Sparse coding.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn import linear_model\n",
      ">>> reg = linear_model.Lars(n_nonzero_coefs=1, normalize=False)\n",
      ">>> reg.fit([[-1, 1], [0, 0], [1, 1]], [-1.1111, 0, -1.1111])\n",
      "Lars(n_nonzero_coefs=1, normalize=False)\n",
      ">>> print(reg.coef_)\n",
      "[ 0. -1.11...]\n",
      "\u001b[0;31mFile:\u001b[0m           ~/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py\n",
      "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     LassoLars, LarsCV\n"
     ]
    }
   ],
   "source": [
    "Lars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:04.065359Z",
     "start_time": "2024-10-05T13:47:04.062067Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:32:26.048416Z",
     "iopub.status.busy": "2024-02-23T01:32:26.046641Z",
     "iopub.status.idle": "2024-02-23T01:32:26.057978Z",
     "shell.execute_reply": "2024-02-23T01:32:26.055522Z",
     "shell.execute_reply.started": "2024-02-23T01:32:26.048337Z"
    },
    "id": "szoa6WE3SSdp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "larsreg = Lars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:04.188757Z",
     "start_time": "2024-10-05T13:47:04.172455Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:34:28.573018Z",
     "iopub.status.busy": "2024-02-23T01:34:28.571673Z",
     "iopub.status.idle": "2024-02-23T01:34:28.605395Z",
     "shell.execute_reply": "2024-02-23T01:34:28.603090Z",
     "shell.execute_reply.started": "2024-02-23T01:34:28.572905Z"
    },
    "id": "Rpjxc9QtSSdp",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning:\n",
      "\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "larsreg = larsreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5YJ2Yo9SSdp"
   },
   "source": [
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:08.034829Z",
     "start_time": "2024-10-05T13:47:07.680744Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:34:43.881566Z",
     "iopub.status.busy": "2024-02-23T01:34:43.879836Z",
     "iopub.status.idle": "2024-02-23T01:34:45.193510Z",
     "shell.execute_reply": "2024-02-23T01:34:45.192595Z",
     "shell.execute_reply.started": "2024-02-23T01:34:43.881452Z"
    },
    "id": "Dsa91tJOSSdp",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ls_res = cross_val_score(estimator = larsreg, X=X, y=y, cv=4, n_jobs=-1, scoring=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:08.280485Z",
     "start_time": "2024-10-05T13:47:08.277775Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:34:58.203530Z",
     "iopub.status.busy": "2024-02-23T01:34:58.201089Z",
     "iopub.status.idle": "2024-02-23T01:34:58.221814Z",
     "shell.execute_reply": "2024-02-23T01:34:58.219027Z",
     "shell.execute_reply.started": "2024-02-23T01:34:58.203423Z"
    },
    "id": "1xU3B93WSSdp",
    "outputId": "815561b0-7ccb-4d7a-bb6b-cc4467ff9c43",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.6015054 ,  0.60398145,  0.35873597, -1.10867706])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:08.586019Z",
     "start_time": "2024-10-05T13:47:08.581993Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:35:10.234833Z",
     "iopub.status.busy": "2024-02-23T01:35:10.234088Z",
     "iopub.status.idle": "2024-02-23T01:35:10.250273Z",
     "shell.execute_reply": "2024-02-23T01:35:10.246925Z",
     "shell.execute_reply.started": "2024-02-23T01:35:10.234770Z"
    },
    "id": "uLSsioQ2SSdp",
    "outputId": "1e98ba25-7ff1-4e28-d83c-2a3f99b3c80d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11388643958845451, 0.7128425802035525)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ls_res), np.std(ls_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:08.835416Z",
     "start_time": "2024-10-05T13:47:08.830791Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:37:46.124998Z",
     "iopub.status.busy": "2024-02-23T01:37:46.123676Z",
     "iopub.status.idle": "2024-02-23T01:37:46.139570Z",
     "shell.execute_reply": "2024-02-23T01:37:46.136479Z",
     "shell.execute_reply.started": "2024-02-23T01:37:46.124926Z"
    },
    "id": "VnPrz6gjSSdp",
    "outputId": "f2934727-196f-4a8a-b98c-82af70afd958",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.95133114391081"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "larsreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:09.082130Z",
     "start_time": "2024-10-05T13:47:09.079416Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:38:09.268836Z",
     "iopub.status.busy": "2024-02-23T01:38:09.267965Z",
     "iopub.status.idle": "2024-02-23T01:38:09.286417Z",
     "shell.execute_reply": "2024-02-23T01:38:09.282890Z",
     "shell.execute_reply.started": "2024-02-23T01:38:09.268760Z"
    },
    "id": "rmO89UzqSSds",
    "outputId": "63608139-8fee-4158-8d45-6c41c8091c6b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.09921668e-01,  4.77494449e-02,  3.42654195e-02,  2.67396468e+00,\n",
       "       -1.82501210e+01,  3.80245356e+00,  9.79271355e-04, -1.48628516e+00,\n",
       "        3.20424027e-01, -1.31267747e-02, -9.60367186e-01,  9.38636165e-03,\n",
       "       -5.26015958e-01])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "larsreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:09.294013Z",
     "start_time": "2024-10-05T13:47:09.290629Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:38:13.969486Z",
     "iopub.status.busy": "2024-02-23T01:38:13.967068Z",
     "iopub.status.idle": "2024-02-23T01:38:13.987473Z",
     "shell.execute_reply": "2024-02-23T01:38:13.982244Z",
     "shell.execute_reply.started": "2024-02-23T01:38:13.969361Z"
    },
    "id": "jgwhDPwbSSds",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dc_scores.update({str(larsreg).split(\"(\")[0]: np.mean(ls_res)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:09.507292Z",
     "start_time": "2024-10-05T13:47:09.503429Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:38:16.081374Z",
     "iopub.status.busy": "2024-02-23T01:38:16.080129Z",
     "iopub.status.idle": "2024-02-23T01:38:16.100438Z",
     "shell.execute_reply": "2024-02-23T01:38:16.097757Z",
     "shell.execute_reply.started": "2024-02-23T01:38:16.081267Z"
    },
    "id": "vpFQfVyiSSds",
    "outputId": "95c2b839-4ad3-4b3c-ee95-004e517364cd",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression': 0.11405301290101522, 'Lars': 0.11388643958845451}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wSrFLVEZSSds"
   },
   "source": [
    "### Regresión Cresta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YvNMklkSSds"
   },
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcopy_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Linear least squares with l2 regularization.\n",
      "\n",
      "Minimizes the objective function::\n",
      "\n",
      "||y - Xw||^2_2 + alpha * ||w||^2_2\n",
      "\n",
      "This model solves a regression model where the loss function is\n",
      "the linear least squares function and regularization is given by\n",
      "the l2-norm. Also known as Ridge Regression or Tikhonov regularization.\n",
      "This estimator has built-in support for multi-variate regression\n",
      "(i.e., when y is a 2d-array of shape (n_samples, n_targets)).\n",
      "\n",
      "Read more in the :ref:`User Guide <ridge_regression>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "alpha : {float, ndarray of shape (n_targets,)}, default=1.0\n",
      "    Regularization strength; must be a positive float. Regularization\n",
      "    improves the conditioning of the problem and reduces the variance of\n",
      "    the estimates. Larger values specify stronger regularization.\n",
      "    Alpha corresponds to ``1 / (2C)`` in other linear models such as\n",
      "    :class:`~sklearn.linear_model.LogisticRegression` or\n",
      "    :class:`~sklearn.svm.LinearSVC`. If an array is passed, penalties are\n",
      "    assumed to be specific to the targets. Hence they must correspond in\n",
      "    number.\n",
      "\n",
      "fit_intercept : bool, default=True\n",
      "    Whether to fit the intercept for this model. If set\n",
      "    to false, no intercept will be used in calculations\n",
      "    (i.e. ``X`` and ``y`` are expected to be centered).\n",
      "\n",
      "normalize : bool, default=False\n",
      "    This parameter is ignored when ``fit_intercept`` is set to False.\n",
      "    If True, the regressors X will be normalized before regression by\n",
      "    subtracting the mean and dividing by the l2-norm.\n",
      "    If you wish to standardize, please use\n",
      "    :class:`~sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
      "    on an estimator with ``normalize=False``.\n",
      "\n",
      "    .. deprecated:: 1.0\n",
      "        ``normalize`` was deprecated in version 1.0 and\n",
      "        will be removed in 1.2.\n",
      "\n",
      "copy_X : bool, default=True\n",
      "    If True, X will be copied; else, it may be overwritten.\n",
      "\n",
      "max_iter : int, default=None\n",
      "    Maximum number of iterations for conjugate gradient solver.\n",
      "    For 'sparse_cg' and 'lsqr' solvers, the default value is determined\n",
      "    by scipy.sparse.linalg. For 'sag' solver, the default value is 1000.\n",
      "    For 'lbfgs' solver, the default value is 15000.\n",
      "\n",
      "tol : float, default=1e-3\n",
      "    Precision of the solution.\n",
      "\n",
      "solver : {'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg',             'sag', 'saga', 'lbfgs'}, default='auto'\n",
      "    Solver to use in the computational routines:\n",
      "\n",
      "    - 'auto' chooses the solver automatically based on the type of data.\n",
      "\n",
      "    - 'svd' uses a Singular Value Decomposition of X to compute the Ridge\n",
      "      coefficients. More stable for singular matrices than 'cholesky'.\n",
      "\n",
      "    - 'cholesky' uses the standard scipy.linalg.solve function to\n",
      "      obtain a closed-form solution.\n",
      "\n",
      "    - 'sparse_cg' uses the conjugate gradient solver as found in\n",
      "      scipy.sparse.linalg.cg. As an iterative algorithm, this solver is\n",
      "      more appropriate than 'cholesky' for large-scale data\n",
      "      (possibility to set `tol` and `max_iter`).\n",
      "\n",
      "    - 'lsqr' uses the dedicated regularized least-squares routine\n",
      "      scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative\n",
      "      procedure.\n",
      "\n",
      "    - 'sag' uses a Stochastic Average Gradient descent, and 'saga' uses\n",
      "      its improved, unbiased version named SAGA. Both methods also use an\n",
      "      iterative procedure, and are often faster than other solvers when\n",
      "      both n_samples and n_features are large. Note that 'sag' and\n",
      "      'saga' fast convergence is only guaranteed on features with\n",
      "      approximately the same scale. You can preprocess the data with a\n",
      "      scaler from sklearn.preprocessing.\n",
      "\n",
      "    - 'lbfgs' uses L-BFGS-B algorithm implemented in\n",
      "      `scipy.optimize.minimize`. It can be used only when `positive`\n",
      "      is True.\n",
      "\n",
      "    All last six solvers support both dense and sparse data. However, only\n",
      "    'sag', 'sparse_cg', and 'lbfgs' support sparse input when `fit_intercept`\n",
      "    is True.\n",
      "\n",
      "    .. versionadded:: 0.17\n",
      "       Stochastic Average Gradient descent solver.\n",
      "    .. versionadded:: 0.19\n",
      "       SAGA solver.\n",
      "\n",
      "positive : bool, default=False\n",
      "    When set to ``True``, forces the coefficients to be positive.\n",
      "    Only 'lbfgs' solver is supported in this case.\n",
      "\n",
      "random_state : int, RandomState instance, default=None\n",
      "    Used when ``solver`` == 'sag' or 'saga' to shuffle the data.\n",
      "    See :term:`Glossary <random_state>` for details.\n",
      "\n",
      "    .. versionadded:: 0.17\n",
      "       `random_state` to support Stochastic Average Gradient.\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
      "    Weight vector(s).\n",
      "\n",
      "intercept_ : float or ndarray of shape (n_targets,)\n",
      "    Independent term in decision function. Set to 0.0 if\n",
      "    ``fit_intercept = False``.\n",
      "\n",
      "n_iter_ : None or ndarray of shape (n_targets,)\n",
      "    Actual number of iterations for each target. Available only for\n",
      "    sag and lsqr solvers. Other solvers will return None.\n",
      "\n",
      "    .. versionadded:: 0.17\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Defined only when `X`\n",
      "    has feature names that are all strings.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "See Also\n",
      "--------\n",
      "RidgeClassifier : Ridge classifier.\n",
      "RidgeCV : Ridge regression with built-in cross validation.\n",
      ":class:`~sklearn.kernel_ridge.KernelRidge` : Kernel ridge regression\n",
      "    combines ridge regression with the kernel trick.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.linear_model import Ridge\n",
      ">>> import numpy as np\n",
      ">>> n_samples, n_features = 10, 5\n",
      ">>> rng = np.random.RandomState(0)\n",
      ">>> y = rng.randn(n_samples)\n",
      ">>> X = rng.randn(n_samples, n_features)\n",
      ">>> clf = Ridge(alpha=1.0)\n",
      ">>> clf.fit(X, y)\n",
      "Ridge()\n",
      "\u001b[0;31mFile:\u001b[0m           ~/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py\n",
      "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "Ridge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:10.231751Z",
     "start_time": "2024-10-05T13:47:10.229016Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:38:57.880380Z",
     "iopub.status.busy": "2024-02-23T01:38:57.878885Z",
     "iopub.status.idle": "2024-02-23T01:38:57.894185Z",
     "shell.execute_reply": "2024-02-23T01:38:57.891205Z",
     "shell.execute_reply.started": "2024-02-23T01:38:57.880278Z"
    },
    "id": "wyVf2kUvSSds",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ridgereg = Ridge(alpha=170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:10.450062Z",
     "start_time": "2024-10-05T13:47:10.437386Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:39:01.590200Z",
     "iopub.status.busy": "2024-02-23T01:39:01.588887Z",
     "iopub.status.idle": "2024-02-23T01:39:01.630829Z",
     "shell.execute_reply": "2024-02-23T01:39:01.627595Z",
     "shell.execute_reply.started": "2024-02-23T01:39:01.590088Z"
    },
    "id": "Bs9NNIxsSSds",
    "outputId": "cc1697c8-3b33-40a1-fe56-6f75fb56777b",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=170)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgereg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LhzTCv5SSds"
   },
   "source": [
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:11.281521Z",
     "start_time": "2024-10-05T13:47:10.911990Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:39:16.849819Z",
     "iopub.status.busy": "2024-02-23T01:39:16.849015Z",
     "iopub.status.idle": "2024-02-23T01:39:17.772927Z",
     "shell.execute_reply": "2024-02-23T01:39:17.771131Z",
     "shell.execute_reply.started": "2024-02-23T01:39:16.849746Z"
    },
    "id": "j0Uo0SoDSSds",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "ls_res = cross_val_score(estimator = ridgereg, X=X, y=y, cv=4, n_jobs=-1, scoring=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:11.304344Z",
     "start_time": "2024-10-05T13:47:11.301418Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:39:17.775463Z",
     "iopub.status.busy": "2024-02-23T01:39:17.775035Z",
     "iopub.status.idle": "2024-02-23T01:39:17.788533Z",
     "shell.execute_reply": "2024-02-23T01:39:17.787425Z",
     "shell.execute_reply.started": "2024-02-23T01:39:17.775424Z"
    },
    "id": "hQbtALJCSSds",
    "outputId": "4c6b30ea-04b7-47a1-b66b-90fd63efbf90",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.58979113,  0.58231525,  0.47761264, -0.26179644])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:11.362497Z",
     "start_time": "2024-10-05T13:47:11.358464Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:39:28.828823Z",
     "iopub.status.busy": "2024-02-23T01:39:28.828000Z",
     "iopub.status.idle": "2024-02-23T01:39:28.843705Z",
     "shell.execute_reply": "2024-02-23T01:39:28.841780Z",
     "shell.execute_reply.started": "2024-02-23T01:39:28.828754Z"
    },
    "id": "kI8BIN90SSds",
    "outputId": "b662cc63-7a27-4f95-961e-8d2104236b59",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.34698064785515315, 0.35426457700618036)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ls_res), np.std(ls_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hp5oAn78SSds"
   },
   "source": [
    "#### Búsqueda del mejor $\\alpha$ ($\\lambda$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:11.830450Z",
     "start_time": "2024-10-05T13:47:11.825005Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:40:49.199434Z",
     "iopub.status.busy": "2024-02-23T01:40:49.198011Z",
     "iopub.status.idle": "2024-02-23T01:40:49.227150Z",
     "shell.execute_reply": "2024-02-23T01:40:49.223698Z",
     "shell.execute_reply.started": "2024-02-23T01:40:49.199321Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcopy_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Linear least squares with l2 regularization.\n",
      "\n",
      "Minimizes the objective function::\n",
      "\n",
      "||y - Xw||^2_2 + alpha * ||w||^2_2\n",
      "\n",
      "This model solves a regression model where the loss function is\n",
      "the linear least squares function and regularization is given by\n",
      "the l2-norm. Also known as Ridge Regression or Tikhonov regularization.\n",
      "This estimator has built-in support for multi-variate regression\n",
      "(i.e., when y is a 2d-array of shape (n_samples, n_targets)).\n",
      "\n",
      "Read more in the :ref:`User Guide <ridge_regression>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "alpha : {float, ndarray of shape (n_targets,)}, default=1.0\n",
      "    Regularization strength; must be a positive float. Regularization\n",
      "    improves the conditioning of the problem and reduces the variance of\n",
      "    the estimates. Larger values specify stronger regularization.\n",
      "    Alpha corresponds to ``1 / (2C)`` in other linear models such as\n",
      "    :class:`~sklearn.linear_model.LogisticRegression` or\n",
      "    :class:`~sklearn.svm.LinearSVC`. If an array is passed, penalties are\n",
      "    assumed to be specific to the targets. Hence they must correspond in\n",
      "    number.\n",
      "\n",
      "fit_intercept : bool, default=True\n",
      "    Whether to fit the intercept for this model. If set\n",
      "    to false, no intercept will be used in calculations\n",
      "    (i.e. ``X`` and ``y`` are expected to be centered).\n",
      "\n",
      "normalize : bool, default=False\n",
      "    This parameter is ignored when ``fit_intercept`` is set to False.\n",
      "    If True, the regressors X will be normalized before regression by\n",
      "    subtracting the mean and dividing by the l2-norm.\n",
      "    If you wish to standardize, please use\n",
      "    :class:`~sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
      "    on an estimator with ``normalize=False``.\n",
      "\n",
      "    .. deprecated:: 1.0\n",
      "        ``normalize`` was deprecated in version 1.0 and\n",
      "        will be removed in 1.2.\n",
      "\n",
      "copy_X : bool, default=True\n",
      "    If True, X will be copied; else, it may be overwritten.\n",
      "\n",
      "max_iter : int, default=None\n",
      "    Maximum number of iterations for conjugate gradient solver.\n",
      "    For 'sparse_cg' and 'lsqr' solvers, the default value is determined\n",
      "    by scipy.sparse.linalg. For 'sag' solver, the default value is 1000.\n",
      "    For 'lbfgs' solver, the default value is 15000.\n",
      "\n",
      "tol : float, default=1e-3\n",
      "    Precision of the solution.\n",
      "\n",
      "solver : {'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg',             'sag', 'saga', 'lbfgs'}, default='auto'\n",
      "    Solver to use in the computational routines:\n",
      "\n",
      "    - 'auto' chooses the solver automatically based on the type of data.\n",
      "\n",
      "    - 'svd' uses a Singular Value Decomposition of X to compute the Ridge\n",
      "      coefficients. More stable for singular matrices than 'cholesky'.\n",
      "\n",
      "    - 'cholesky' uses the standard scipy.linalg.solve function to\n",
      "      obtain a closed-form solution.\n",
      "\n",
      "    - 'sparse_cg' uses the conjugate gradient solver as found in\n",
      "      scipy.sparse.linalg.cg. As an iterative algorithm, this solver is\n",
      "      more appropriate than 'cholesky' for large-scale data\n",
      "      (possibility to set `tol` and `max_iter`).\n",
      "\n",
      "    - 'lsqr' uses the dedicated regularized least-squares routine\n",
      "      scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative\n",
      "      procedure.\n",
      "\n",
      "    - 'sag' uses a Stochastic Average Gradient descent, and 'saga' uses\n",
      "      its improved, unbiased version named SAGA. Both methods also use an\n",
      "      iterative procedure, and are often faster than other solvers when\n",
      "      both n_samples and n_features are large. Note that 'sag' and\n",
      "      'saga' fast convergence is only guaranteed on features with\n",
      "      approximately the same scale. You can preprocess the data with a\n",
      "      scaler from sklearn.preprocessing.\n",
      "\n",
      "    - 'lbfgs' uses L-BFGS-B algorithm implemented in\n",
      "      `scipy.optimize.minimize`. It can be used only when `positive`\n",
      "      is True.\n",
      "\n",
      "    All last six solvers support both dense and sparse data. However, only\n",
      "    'sag', 'sparse_cg', and 'lbfgs' support sparse input when `fit_intercept`\n",
      "    is True.\n",
      "\n",
      "    .. versionadded:: 0.17\n",
      "       Stochastic Average Gradient descent solver.\n",
      "    .. versionadded:: 0.19\n",
      "       SAGA solver.\n",
      "\n",
      "positive : bool, default=False\n",
      "    When set to ``True``, forces the coefficients to be positive.\n",
      "    Only 'lbfgs' solver is supported in this case.\n",
      "\n",
      "random_state : int, RandomState instance, default=None\n",
      "    Used when ``solver`` == 'sag' or 'saga' to shuffle the data.\n",
      "    See :term:`Glossary <random_state>` for details.\n",
      "\n",
      "    .. versionadded:: 0.17\n",
      "       `random_state` to support Stochastic Average Gradient.\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
      "    Weight vector(s).\n",
      "\n",
      "intercept_ : float or ndarray of shape (n_targets,)\n",
      "    Independent term in decision function. Set to 0.0 if\n",
      "    ``fit_intercept = False``.\n",
      "\n",
      "n_iter_ : None or ndarray of shape (n_targets,)\n",
      "    Actual number of iterations for each target. Available only for\n",
      "    sag and lsqr solvers. Other solvers will return None.\n",
      "\n",
      "    .. versionadded:: 0.17\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Defined only when `X`\n",
      "    has feature names that are all strings.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "See Also\n",
      "--------\n",
      "RidgeClassifier : Ridge classifier.\n",
      "RidgeCV : Ridge regression with built-in cross validation.\n",
      ":class:`~sklearn.kernel_ridge.KernelRidge` : Kernel ridge regression\n",
      "    combines ridge regression with the kernel trick.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.linear_model import Ridge\n",
      ">>> import numpy as np\n",
      ">>> n_samples, n_features = 10, 5\n",
      ">>> rng = np.random.RandomState(0)\n",
      ">>> y = rng.randn(n_samples)\n",
      ">>> X = rng.randn(n_samples, n_features)\n",
      ">>> clf = Ridge(alpha=1.0)\n",
      ">>> clf.fit(X, y)\n",
      "Ridge()\n",
      "\u001b[0;31mFile:\u001b[0m           ~/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py\n",
      "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "Ridge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:15.346756Z",
     "start_time": "2024-10-05T13:47:12.068442Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:41:41.858965Z",
     "iopub.status.busy": "2024-02-23T01:41:41.857739Z",
     "iopub.status.idle": "2024-02-23T01:41:47.782245Z",
     "shell.execute_reply": "2024-02-23T01:41:47.780122Z",
     "shell.execute_reply.started": "2024-02-23T01:41:41.858861Z"
    },
    "id": "hTxEb9HqSSds",
    "outputId": "f0e1218c-33fe-4741-a4ce-01696c3fdf34",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 11.41% 0.71\n",
      "5 20.01% 0.61\n",
      "10 22.43% 0.57\n",
      "15 24.22% 0.55\n",
      "20 25.67% 0.53\n",
      "25 26.89% 0.51\n",
      "30 27.92% 0.49\n",
      "35 28.81% 0.48\n",
      "40 29.58% 0.47\n",
      "45 30.25% 0.46\n",
      "50 30.84% 0.45\n",
      "55 31.35% 0.44\n",
      "60 31.79% 0.43\n",
      "65 32.19% 0.42\n",
      "70 32.53% 0.41\n",
      "75 32.84% 0.41\n",
      "80 33.10% 0.40\n",
      "85 33.34% 0.40\n",
      "90 33.55% 0.39\n",
      "95 33.73% 0.39\n",
      "100 33.89% 0.39\n",
      "105 34.02% 0.38\n",
      "110 34.15% 0.38\n",
      "115 34.25% 0.38\n",
      "120 34.34% 0.37\n",
      "125 34.42% 0.37\n",
      "130 34.48% 0.37\n",
      "135 34.54% 0.37\n",
      "140 34.58% 0.36\n",
      "145 34.62% 0.36\n",
      "150 34.65% 0.36\n",
      "155 34.67% 0.36\n",
      "160 34.69% 0.36\n",
      "165 34.69% 0.36\n",
      "170 34.70% 0.35\n",
      "175 34.70% 0.35\n",
      "180 34.69% 0.35\n",
      "185 34.68% 0.35\n",
      "190 34.67% 0.35\n",
      "195 34.65% 0.35\n",
      "200 34.63% 0.35\n",
      "205 34.61% 0.35\n",
      "210 34.58% 0.35\n",
      "215 34.55% 0.35\n",
      "220 34.52% 0.35\n",
      "225 34.49% 0.35\n",
      "230 34.46% 0.34\n",
      "235 34.42% 0.34\n",
      "240 34.38% 0.34\n",
      "245 34.35% 0.34\n",
      "250 34.31% 0.34\n",
      "255 34.26% 0.34\n",
      "260 34.22% 0.34\n",
      "265 34.18% 0.34\n",
      "270 34.14% 0.34\n",
      "275 34.09% 0.34\n",
      "280 34.05% 0.34\n",
      "285 34.00% 0.34\n",
      "290 33.95% 0.34\n",
      "295 33.91% 0.34\n",
      "300 33.86% 0.34\n",
      "305 33.81% 0.34\n",
      "310 33.76% 0.34\n",
      "315 33.72% 0.34\n",
      "320 33.67% 0.34\n",
      "325 33.62% 0.34\n",
      "330 33.57% 0.34\n",
      "335 33.52% 0.34\n",
      "340 33.47% 0.34\n",
      "345 33.42% 0.34\n",
      "350 33.37% 0.34\n",
      "355 33.32% 0.34\n",
      "360 33.27% 0.34\n",
      "365 33.22% 0.34\n",
      "370 33.18% 0.34\n",
      "375 33.13% 0.34\n",
      "380 33.08% 0.34\n",
      "385 33.03% 0.34\n",
      "390 32.98% 0.34\n",
      "395 32.93% 0.34\n",
      "400 32.88% 0.34\n",
      "405 32.83% 0.34\n",
      "410 32.78% 0.34\n",
      "415 32.74% 0.34\n",
      "420 32.69% 0.34\n",
      "425 32.64% 0.34\n",
      "430 32.59% 0.34\n",
      "435 32.55% 0.34\n",
      "440 32.50% 0.34\n",
      "445 32.45% 0.34\n",
      "450 32.41% 0.34\n",
      "455 32.36% 0.34\n",
      "460 32.31% 0.34\n",
      "465 32.27% 0.34\n",
      "470 32.22% 0.33\n",
      "475 32.18% 0.33\n",
      "480 32.13% 0.33\n",
      "485 32.09% 0.33\n",
      "490 32.04% 0.33\n",
      "495 32.00% 0.33\n",
      "500 31.95% 0.33\n",
      "505 31.91% 0.33\n",
      "510 31.86% 0.33\n",
      "515 31.82% 0.33\n",
      "520 31.78% 0.33\n",
      "525 31.73% 0.33\n",
      "530 31.69% 0.33\n",
      "535 31.65% 0.33\n",
      "540 31.61% 0.33\n",
      "545 31.57% 0.33\n",
      "550 31.52% 0.33\n",
      "555 31.48% 0.33\n",
      "560 31.44% 0.33\n",
      "565 31.40% 0.33\n",
      "570 31.36% 0.33\n",
      "575 31.32% 0.33\n",
      "580 31.28% 0.33\n",
      "585 31.24% 0.33\n",
      "590 31.20% 0.33\n",
      "595 31.16% 0.33\n",
      "600 31.12% 0.33\n",
      "605 31.08% 0.33\n",
      "610 31.05% 0.33\n",
      "615 31.01% 0.33\n",
      "620 30.97% 0.33\n",
      "625 30.93% 0.33\n",
      "630 30.89% 0.33\n",
      "635 30.86% 0.33\n",
      "640 30.82% 0.33\n",
      "645 30.78% 0.33\n",
      "650 30.75% 0.33\n",
      "655 30.71% 0.33\n",
      "660 30.68% 0.33\n",
      "665 30.64% 0.33\n",
      "670 30.60% 0.33\n",
      "675 30.57% 0.33\n",
      "680 30.53% 0.33\n",
      "685 30.50% 0.33\n",
      "690 30.46% 0.33\n",
      "695 30.43% 0.33\n",
      "700 30.40% 0.33\n",
      "705 30.36% 0.33\n",
      "710 30.33% 0.33\n",
      "715 30.30% 0.33\n",
      "720 30.26% 0.33\n",
      "725 30.23% 0.33\n",
      "730 30.20% 0.33\n",
      "735 30.16% 0.33\n",
      "740 30.13% 0.33\n",
      "745 30.10% 0.33\n",
      "750 30.07% 0.33\n",
      "755 30.04% 0.33\n",
      "760 30.01% 0.33\n",
      "765 29.97% 0.33\n",
      "770 29.94% 0.33\n",
      "775 29.91% 0.32\n",
      "780 29.88% 0.32\n",
      "785 29.85% 0.32\n",
      "790 29.82% 0.32\n",
      "795 29.79% 0.32\n",
      "800 29.76% 0.32\n",
      "805 29.73% 0.32\n",
      "810 29.70% 0.32\n",
      "815 29.67% 0.32\n",
      "820 29.64% 0.32\n",
      "825 29.62% 0.32\n",
      "830 29.59% 0.32\n",
      "835 29.56% 0.32\n",
      "840 29.53% 0.32\n",
      "845 29.50% 0.32\n",
      "850 29.47% 0.32\n",
      "855 29.45% 0.32\n",
      "860 29.42% 0.32\n",
      "865 29.39% 0.32\n",
      "870 29.36% 0.32\n",
      "875 29.34% 0.32\n",
      "880 29.31% 0.32\n",
      "885 29.28% 0.32\n",
      "890 29.26% 0.32\n",
      "895 29.23% 0.32\n",
      "900 29.20% 0.32\n",
      "905 29.18% 0.32\n",
      "910 29.15% 0.32\n",
      "915 29.13% 0.32\n",
      "920 29.10% 0.32\n",
      "925 29.07% 0.32\n",
      "930 29.05% 0.32\n",
      "935 29.02% 0.32\n",
      "940 29.00% 0.32\n",
      "945 28.97% 0.32\n",
      "950 28.95% 0.32\n",
      "955 28.92% 0.32\n",
      "960 28.90% 0.32\n",
      "965 28.88% 0.32\n",
      "970 28.85% 0.32\n",
      "975 28.83% 0.32\n",
      "980 28.80% 0.32\n",
      "985 28.78% 0.31\n",
      "990 28.76% 0.31\n",
      "995 28.73% 0.31\n"
     ]
    }
   ],
   "source": [
    "df_res = pd.DataFrame()\n",
    "for i in range(0, 1_000, 5):\n",
    "    ridgereg = Ridge(alpha=i)\n",
    "    ridgereg.fit(X, y)\n",
    "    ls_res = cross_val_score(estimator = ridgereg, X=X, y=y, cv=4, n_jobs=-1, scoring=\"r2\")\n",
    "    df_res.loc[i, \"r2_mean\"] = np.mean(ls_res)\n",
    "    df_res.loc[i, \"r2_std\"] = np.std(ls_res)\n",
    "    print(i, \"{:,.2%}\".format(np.mean(ls_res)), \"{:,.2f}\".format(np.std(ls_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:15.537412Z",
     "start_time": "2024-10-05T13:47:15.366663Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:42:46.923637Z",
     "iopub.status.busy": "2024-02-23T01:42:46.922697Z",
     "iopub.status.idle": "2024-02-23T01:42:47.476091Z",
     "shell.execute_reply": "2024-02-23T01:42:47.475256Z",
     "shell.execute_reply.started": "2024-02-23T01:42:46.923556Z"
    },
    "id": "KqnGd-ttSSds",
    "outputId": "25c1e83b-8fb7-489a-e433-9bdf88f5ba35",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(255, 153, 51, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "r2_mean",
         "text": "",
         "type": "scatter",
         "x": [
          0,
          5,
          10,
          15,
          20,
          25,
          30,
          35,
          40,
          45,
          50,
          55,
          60,
          65,
          70,
          75,
          80,
          85,
          90,
          95,
          100,
          105,
          110,
          115,
          120,
          125,
          130,
          135,
          140,
          145,
          150,
          155,
          160,
          165,
          170,
          175,
          180,
          185,
          190,
          195,
          200,
          205,
          210,
          215,
          220,
          225,
          230,
          235,
          240,
          245,
          250,
          255,
          260,
          265,
          270,
          275,
          280,
          285,
          290,
          295,
          300,
          305,
          310,
          315,
          320,
          325,
          330,
          335,
          340,
          345,
          350,
          355,
          360,
          365,
          370,
          375,
          380,
          385,
          390,
          395,
          400,
          405,
          410,
          415,
          420,
          425,
          430,
          435,
          440,
          445,
          450,
          455,
          460,
          465,
          470,
          475,
          480,
          485,
          490,
          495,
          500,
          505,
          510,
          515,
          520,
          525,
          530,
          535,
          540,
          545,
          550,
          555,
          560,
          565,
          570,
          575,
          580,
          585,
          590,
          595,
          600,
          605,
          610,
          615,
          620,
          625,
          630,
          635,
          640,
          645,
          650,
          655,
          660,
          665,
          670,
          675,
          680,
          685,
          690,
          695,
          700,
          705,
          710,
          715,
          720,
          725,
          730,
          735,
          740,
          745,
          750,
          755,
          760,
          765,
          770,
          775,
          780,
          785,
          790,
          795,
          800,
          805,
          810,
          815,
          820,
          825,
          830,
          835,
          840,
          845,
          850,
          855,
          860,
          865,
          870,
          875,
          880,
          885,
          890,
          895,
          900,
          905,
          910,
          915,
          920,
          925,
          930,
          935,
          940,
          945,
          950,
          955,
          960,
          965,
          970,
          975,
          980,
          985,
          990,
          995
         ],
         "y": [
          0.11405301290099573,
          0.2001115486552943,
          0.22427712086906432,
          0.24216924155974912,
          0.25669370156151,
          0.2688637276621117,
          0.27922274632701455,
          0.2881246717218561,
          0.29582440371644947,
          0.30251621304489734,
          0.308353336830497,
          0.3134594018630732,
          0.31793574689211823,
          0.3218664426940128,
          0.3253219018250029,
          0.32836156474805,
          0.33103594971721795,
          0.33338824733601347,
          0.3354555796539036,
          0.3372700064901235,
          0.3388593378765548,
          0.3402477956378446,
          0.34145655617672194,
          0.34250419876881216,
          0.34340707804195425,
          0.3441796351569491,
          0.3448346590874628,
          0.34538350702605564,
          0.3458362911209981,
          0.34620203733408494,
          0.34648882110220713,
          0.3467038836116748,
          0.34685373180005435,
          0.346944224645254,
          0.34698064785515315,
          0.3469677787101549,
          0.3469099425176931,
          0.346811061898245,
          0.34667469992596495,
          0.3465040979853344,
          0.3463022090714348,
          0.34607172715048823,
          0.34581511310482954,
          0.3455346177092187,
          0.3452323020205828,
          0.34491005550878506,
          0.3445696122100184,
          0.34421256514549875,
          0.34384037921511246,
          0.34345440274757005,
          0.34305587786463104,
          0.3426459497964779,
          0.3422256752677302,
          0.34179603005845927,
          0.3413579158316,
          0.34091216630686155,
          0.3404595528515679,
          0.34000078955040924,
          0.3395365378087625,
          0.339067410537887,
          0.3385939759647266,
          0.3381167611042014,
          0.3376362549276296,
          0.33715291125717917,
          0.3366671514129977,
          0.3361793666367645,
          0.3356899203128959,
          0.33519915000637496,
          0.33470736933421946,
          0.3342148696858192,
          0.33372192180584753,
          0.33322877725206385,
          0.3327356697390814,
          0.332242816378108,
          0.3317504188216707,
          0.33125866432148376,
          0.3307677267068175,
          0.3302777672900676,
          0.32978893570556,
          0.32930137068708876,
          0.3288152007891912,
          0.328330545056683,
          0.32784751364659476,
          0.32736620840627695,
          0.3268867234111042,
          0.326409145464915,
          0.32593355456605977,
          0.3254600243416652,
          0.32498862245252713,
          0.32451941097082493,
          0.32405244673267125,
          0.3235877816673519,
          0.32312546310495105,
          0.3226655340639286,
          0.32220803352008226,
          0.3217529966582198,
          0.32130045510775934,
          0.32085043716338446,
          0.3204029679917853,
          0.31995806982545083,
          0.31951576214438837,
          0.3190760618466009,
          0.31863898340806046,
          0.3182045390328959,
          0.3177727387944366,
          0.31734359076771457,
          0.31691710115397953,
          0.3164932743977507,
          0.31607211329688756,
          0.3156536191061165,
          0.31523779163444055,
          0.31482462933681093,
          0.3144141294004275,
          0.31400628782599355,
          0.3136010995042452,
          0.313198558288048,
          0.31279865706032023,
          0.312401387798051,
          0.31200674163264064,
          0.3116147089067876,
          0.311225279228125,
          0.3108384415198081,
          0.31045418406822256,
          0.3100724945679904,
          0.30969336016443044,
          0.30931676749361575,
          0.308942702720179,
          0.3085711515729823,
          0.30820209937878185,
          0.3078355310940031,
          0.3074714313347264,
          0.30710978440499137,
          0.3067505743235139,
          0.3063937848488968,
          0.3060393995034335,
          0.3056874015955655,
          0.3053377742410828,
          0.304990500383127,
          0.30464556281106775,
          0.3043029441783143,
          0.30396262701911775,
          0.3036245937644165,
          0.30328882675678975,
          0.30295530826454875,
          0.3026240204950264,
          0.3022949456071004,
          0.3019680657229972,
          0.3016433629394106,
          0.3013208193379713,
          0.30100041699510455,
          0.3006821379913092,
          0.3003659644198846,
          0.3000518783951348,
          0.2997398620600874,
          0.2994298975937344,
          0.29912196721783835,
          0.29881605320331456,
          0.2985121378762202,
          0.2982102036233601,
          0.2979102328975415,
          0.2976122082224863,
          0.29731611219742593,
          0.29702192750138956,
          0.2967296368972045,
          0.29643922323522487,
          0.2961506694567989,
          0.2958639585974939,
          0.2955790737900874,
          0.2952959982673329,
          0.2950147153645263,
          0.29473520852186486,
          0.29445746128662537,
          0.29418145731515954,
          0.2939071803747219,
          0.2936346143451427,
          0.29336374322033854,
          0.29309455110969523,
          0.2928270222392973,
          0.29256114095304325,
          0.29229689171363354,
          0.29203425910344033,
          0.29177322782527293,
          0.2915137827030372,
          0.2912559086823009,
          0.2909995908307574,
          0.290744814338616,
          0.29049156451889835,
          0.29023982680765875,
          0.28998958676413583,
          0.289740830070831,
          0.2894935425335176,
          0.2892477100811968,
          0.2890033187659847,
          0.28876035476295686,
          0.2885188043699231,
          0.28827865400717323,
          0.2880398902171619,
          0.2878024996641561,
          0.28756646913384293,
          0.2873317855328939
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "r2_std",
         "text": "",
         "type": "scatter",
         "x": [
          0,
          5,
          10,
          15,
          20,
          25,
          30,
          35,
          40,
          45,
          50,
          55,
          60,
          65,
          70,
          75,
          80,
          85,
          90,
          95,
          100,
          105,
          110,
          115,
          120,
          125,
          130,
          135,
          140,
          145,
          150,
          155,
          160,
          165,
          170,
          175,
          180,
          185,
          190,
          195,
          200,
          205,
          210,
          215,
          220,
          225,
          230,
          235,
          240,
          245,
          250,
          255,
          260,
          265,
          270,
          275,
          280,
          285,
          290,
          295,
          300,
          305,
          310,
          315,
          320,
          325,
          330,
          335,
          340,
          345,
          350,
          355,
          360,
          365,
          370,
          375,
          380,
          385,
          390,
          395,
          400,
          405,
          410,
          415,
          420,
          425,
          430,
          435,
          440,
          445,
          450,
          455,
          460,
          465,
          470,
          475,
          480,
          485,
          490,
          495,
          500,
          505,
          510,
          515,
          520,
          525,
          530,
          535,
          540,
          545,
          550,
          555,
          560,
          565,
          570,
          575,
          580,
          585,
          590,
          595,
          600,
          605,
          610,
          615,
          620,
          625,
          630,
          635,
          640,
          645,
          650,
          655,
          660,
          665,
          670,
          675,
          680,
          685,
          690,
          695,
          700,
          705,
          710,
          715,
          720,
          725,
          730,
          735,
          740,
          745,
          750,
          755,
          760,
          765,
          770,
          775,
          780,
          785,
          790,
          795,
          800,
          805,
          810,
          815,
          820,
          825,
          830,
          835,
          840,
          845,
          850,
          855,
          860,
          865,
          870,
          875,
          880,
          885,
          890,
          895,
          900,
          905,
          910,
          915,
          920,
          925,
          930,
          935,
          940,
          945,
          950,
          955,
          960,
          965,
          970,
          975,
          980,
          985,
          990,
          995
         ],
         "y": [
          0.7129565737131365,
          0.6052509236770917,
          0.5745410435992168,
          0.550236990637526,
          0.5293702486380009,
          0.5111037433668251,
          0.4949822351473846,
          0.48068110124831775,
          0.4679443726722579,
          0.45656208660419934,
          0.4463588631090447,
          0.43718670444638785,
          0.42891984305682934,
          0.4214508080381183,
          0.41468732067210845,
          0.40854979944786923,
          0.402969332531768,
          0.3978860172844136,
          0.3932475920748047,
          0.38900830304823614,
          0.3851279610669509,
          0.38157115345175646,
          0.37830658235968967,
          0.3753065072307454,
          0.37254627312632627,
          0.37000391024863777,
          0.3676597926833184,
          0.36549634660480634,
          0.3634977999454831,
          0.36164996694773743,
          0.35994006216441665,
          0.35835653940329437,
          0.35688895186893604,
          0.35552783037472585,
          0.35426457700618036,
          0.35309137203510493,
          0.35200109222999126,
          0.3509872389946387,
          0.3500438750054182,
          0.3491655682164164,
          0.34834734226820935,
          0.3475846324756378,
          0.34687324668762015,
          0.34620933041125207,
          0.3455893356765356,
          0.34500999318936265,
          0.3444682873810894,
          0.3439614340148336,
          0.34348686005287454,
          0.3430421855275367,
          0.3426252071905335,
          0.3422338837438352,
          0.34186632247938625,
          0.34152076717596125,
          0.34119558711960224,
          0.34088926712990436,
          0.34060039848811136,
          0.3403276706749835,
          0.34006986383685567,
          0.3398258419074482,
          0.33959454632102504,
          0.33937499025954637,
          0.3391662533826437,
          0.33896747699473234,
          0.33877785960836243,
          0.338596652867213,
          0.33842315779586385,
          0.3382567213468578,
          0.3380967332184968,
          0.33794262291950705,
          0.3377938570590137,
          0.33764993684236644,
          0.33751039575527053,
          0.3373747974202869,
          0.3372427336113177,
          0.337113822413,
          0.33698770651315474,
          0.33686405161750693,
          0.336742544976872,
          0.33662289401788476,
          0.33650482506911683,
          0.3363880821751696,
          0.3362724259919567,
          0.3361576327569637,
          0.33604349332882005,
          0.3359298122909957,
          0.335816407114837,
          0.3357031073775895,
          0.335589754031397,
          0.33547619871957723,
          0.3353623031367951,
          0.33524793843000894,
          0.3351329846373211,
          0.33501733016207164,
          0.3349008712797459,
          0.3347835116754305,
          0.33466516200973917,
          0.33454573951127803,
          0.3344251675938716,
          0.3343033754968976,
          0.3341802979472073,
          0.33405587484120125,
          0.3339300509457742,
          0.33380277561687943,
          0.3336740025345995,
          0.33354368945366325,
          0.33341179796844406,
          0.33327829329150854,
          0.33314314404488515,
          0.33300632206326436,
          0.33286780220838363,
          0.33272756219392535,
          0.3325855824202773,
          0.3324418458185719,
          0.33229633770343736,
          0.33214904563394043,
          0.33199995928224707,
          0.3318490703095246,
          0.3316963722486903,
          0.33154186039356903,
          0.33138553169413437,
          0.3312273846574345,
          0.33106741925391486,
          0.3309056368288155,
          0.33074204001834495,
          0.3305766326703843,
          0.3304094197694459,
          0.3302404073656568,
          0.3300696025075539,
          0.3298970131784551,
          0.32972264823624015,
          0.3295465173563246,
          0.3293686309776766,
          0.32918900025169817,
          0.32900763699381547,
          0.32882455363764296,
          0.32863976319157157,
          0.32845327919765743,
          0.32826511569268785,
          0.3280752871713104,
          0.3278838085511096,
          0.3276906951395431,
          0.32749596260262054,
          0.32729962693525017,
          0.3271017044331601,
          0.3269022116663118,
          0.3267011654537296,
          0.32649858283967287,
          0.326294481071083,
          0.3260888775762406,
          0.32588178994456773,
          0.32567323590751746,
          0.3254632333204993,
          0.3252518001457845,
          0.3250389544363402,
          0.3248247143205519,
          0.324609097987782,
          0.32439212367472514,
          0.3241738096525253,
          0.3239541742146063,
          0.32373323566519224,
          0.32351101230846785,
          0.3232875224383666,
          0.3230627843289381,
          0.32283681622527116,
          0.32260963633495365,
          0.3223812628200271,
          0.3221517137894221,
          0.3219210072918533,
          0.3216891613091377,
          0.3214561937499276,
          0.32122212244383624,
          0.3209869651359266,
          0.3207507394815624,
          0.32051346304158373,
          0.32027515327781303,
          0.32003582754884835,
          0.3197955031061621,
          0.31955419709045646,
          0.31931192652828794,
          0.3190687083289379,
          0.3188245592815137,
          0.31857949605227776,
          0.3183335351821817,
          0.31808669308461107,
          0.3178389860433088,
          0.3175904302104893,
          0.3173410416051252,
          0.3170908361113868,
          0.3168398294772505,
          0.31658803731324525,
          0.3163354750913403,
          0.31608215814397084,
          0.31582810166317793,
          0.31557332069988336,
          0.3153178301632628,
          0.31506164482023497,
          0.31480477929504813,
          0.3145472480689652,
          0.31428906548003877
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#151516",
         "font": {
          "color": "#D9D9D9"
         }
        },
        "paper_bgcolor": "#151516",
        "plot_bgcolor": "#151516",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "#D9D9D9"
         }
        },
        "xaxis": {
         "gridcolor": "#434343",
         "showgrid": true,
         "tickfont": {
          "color": "#C2C2C2"
         },
         "title": {
          "font": {
           "color": "#D9D9D9"
          },
          "text": ""
         },
         "zerolinecolor": "#666570"
        },
        "yaxis": {
         "gridcolor": "#434343",
         "showgrid": true,
         "tickfont": {
          "color": "#C2C2C2"
         },
         "title": {
          "font": {
           "color": "#D9D9D9"
          },
          "text": ""
         },
         "zerolinecolor": "#666570"
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"1c2616c8-a62d-4f4e-8d5c-d311992dd600\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';                                    if (document.getElementById(\"1c2616c8-a62d-4f4e-8d5c-d311992dd600\")) {                    Plotly.newPlot(                        \"1c2616c8-a62d-4f4e-8d5c-d311992dd600\",                        [{\"line\":{\"color\":\"rgba(255, 153, 51, 1.0)\",\"dash\":\"solid\",\"shape\":\"linear\",\"width\":1.3},\"mode\":\"lines\",\"name\":\"r2_mean\",\"text\":\"\",\"type\":\"scatter\",\"x\":[0,5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100,105,110,115,120,125,130,135,140,145,150,155,160,165,170,175,180,185,190,195,200,205,210,215,220,225,230,235,240,245,250,255,260,265,270,275,280,285,290,295,300,305,310,315,320,325,330,335,340,345,350,355,360,365,370,375,380,385,390,395,400,405,410,415,420,425,430,435,440,445,450,455,460,465,470,475,480,485,490,495,500,505,510,515,520,525,530,535,540,545,550,555,560,565,570,575,580,585,590,595,600,605,610,615,620,625,630,635,640,645,650,655,660,665,670,675,680,685,690,695,700,705,710,715,720,725,730,735,740,745,750,755,760,765,770,775,780,785,790,795,800,805,810,815,820,825,830,835,840,845,850,855,860,865,870,875,880,885,890,895,900,905,910,915,920,925,930,935,940,945,950,955,960,965,970,975,980,985,990,995],\"y\":[0.11405301290099573,0.2001115486552943,0.22427712086906432,0.24216924155974912,0.25669370156151,0.2688637276621117,0.27922274632701455,0.2881246717218561,0.29582440371644947,0.30251621304489734,0.308353336830497,0.3134594018630732,0.31793574689211823,0.3218664426940128,0.3253219018250029,0.32836156474805,0.33103594971721795,0.33338824733601347,0.3354555796539036,0.3372700064901235,0.3388593378765548,0.3402477956378446,0.34145655617672194,0.34250419876881216,0.34340707804195425,0.3441796351569491,0.3448346590874628,0.34538350702605564,0.3458362911209981,0.34620203733408494,0.34648882110220713,0.3467038836116748,0.34685373180005435,0.346944224645254,0.34698064785515315,0.3469677787101549,0.3469099425176931,0.346811061898245,0.34667469992596495,0.3465040979853344,0.3463022090714348,0.34607172715048823,0.34581511310482954,0.3455346177092187,0.3452323020205828,0.34491005550878506,0.3445696122100184,0.34421256514549875,0.34384037921511246,0.34345440274757005,0.34305587786463104,0.3426459497964779,0.3422256752677302,0.34179603005845927,0.3413579158316,0.34091216630686155,0.3404595528515679,0.34000078955040924,0.3395365378087625,0.339067410537887,0.3385939759647266,0.3381167611042014,0.3376362549276296,0.33715291125717917,0.3366671514129977,0.3361793666367645,0.3356899203128959,0.33519915000637496,0.33470736933421946,0.3342148696858192,0.33372192180584753,0.33322877725206385,0.3327356697390814,0.332242816378108,0.3317504188216707,0.33125866432148376,0.3307677267068175,0.3302777672900676,0.32978893570556,0.32930137068708876,0.3288152007891912,0.328330545056683,0.32784751364659476,0.32736620840627695,0.3268867234111042,0.326409145464915,0.32593355456605977,0.3254600243416652,0.32498862245252713,0.32451941097082493,0.32405244673267125,0.3235877816673519,0.32312546310495105,0.3226655340639286,0.32220803352008226,0.3217529966582198,0.32130045510775934,0.32085043716338446,0.3204029679917853,0.31995806982545083,0.31951576214438837,0.3190760618466009,0.31863898340806046,0.3182045390328959,0.3177727387944366,0.31734359076771457,0.31691710115397953,0.3164932743977507,0.31607211329688756,0.3156536191061165,0.31523779163444055,0.31482462933681093,0.3144141294004275,0.31400628782599355,0.3136010995042452,0.313198558288048,0.31279865706032023,0.312401387798051,0.31200674163264064,0.3116147089067876,0.311225279228125,0.3108384415198081,0.31045418406822256,0.3100724945679904,0.30969336016443044,0.30931676749361575,0.308942702720179,0.3085711515729823,0.30820209937878185,0.3078355310940031,0.3074714313347264,0.30710978440499137,0.3067505743235139,0.3063937848488968,0.3060393995034335,0.3056874015955655,0.3053377742410828,0.304990500383127,0.30464556281106775,0.3043029441783143,0.30396262701911775,0.3036245937644165,0.30328882675678975,0.30295530826454875,0.3026240204950264,0.3022949456071004,0.3019680657229972,0.3016433629394106,0.3013208193379713,0.30100041699510455,0.3006821379913092,0.3003659644198846,0.3000518783951348,0.2997398620600874,0.2994298975937344,0.29912196721783835,0.29881605320331456,0.2985121378762202,0.2982102036233601,0.2979102328975415,0.2976122082224863,0.29731611219742593,0.29702192750138956,0.2967296368972045,0.29643922323522487,0.2961506694567989,0.2958639585974939,0.2955790737900874,0.2952959982673329,0.2950147153645263,0.29473520852186486,0.29445746128662537,0.29418145731515954,0.2939071803747219,0.2936346143451427,0.29336374322033854,0.29309455110969523,0.2928270222392973,0.29256114095304325,0.29229689171363354,0.29203425910344033,0.29177322782527293,0.2915137827030372,0.2912559086823009,0.2909995908307574,0.290744814338616,0.29049156451889835,0.29023982680765875,0.28998958676413583,0.289740830070831,0.2894935425335176,0.2892477100811968,0.2890033187659847,0.28876035476295686,0.2885188043699231,0.28827865400717323,0.2880398902171619,0.2878024996641561,0.28756646913384293,0.2873317855328939]},{\"line\":{\"color\":\"rgba(55, 128, 191, 1.0)\",\"dash\":\"solid\",\"shape\":\"linear\",\"width\":1.3},\"mode\":\"lines\",\"name\":\"r2_std\",\"text\":\"\",\"type\":\"scatter\",\"x\":[0,5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100,105,110,115,120,125,130,135,140,145,150,155,160,165,170,175,180,185,190,195,200,205,210,215,220,225,230,235,240,245,250,255,260,265,270,275,280,285,290,295,300,305,310,315,320,325,330,335,340,345,350,355,360,365,370,375,380,385,390,395,400,405,410,415,420,425,430,435,440,445,450,455,460,465,470,475,480,485,490,495,500,505,510,515,520,525,530,535,540,545,550,555,560,565,570,575,580,585,590,595,600,605,610,615,620,625,630,635,640,645,650,655,660,665,670,675,680,685,690,695,700,705,710,715,720,725,730,735,740,745,750,755,760,765,770,775,780,785,790,795,800,805,810,815,820,825,830,835,840,845,850,855,860,865,870,875,880,885,890,895,900,905,910,915,920,925,930,935,940,945,950,955,960,965,970,975,980,985,990,995],\"y\":[0.7129565737131365,0.6052509236770917,0.5745410435992168,0.550236990637526,0.5293702486380009,0.5111037433668251,0.4949822351473846,0.48068110124831775,0.4679443726722579,0.45656208660419934,0.4463588631090447,0.43718670444638785,0.42891984305682934,0.4214508080381183,0.41468732067210845,0.40854979944786923,0.402969332531768,0.3978860172844136,0.3932475920748047,0.38900830304823614,0.3851279610669509,0.38157115345175646,0.37830658235968967,0.3753065072307454,0.37254627312632627,0.37000391024863777,0.3676597926833184,0.36549634660480634,0.3634977999454831,0.36164996694773743,0.35994006216441665,0.35835653940329437,0.35688895186893604,0.35552783037472585,0.35426457700618036,0.35309137203510493,0.35200109222999126,0.3509872389946387,0.3500438750054182,0.3491655682164164,0.34834734226820935,0.3475846324756378,0.34687324668762015,0.34620933041125207,0.3455893356765356,0.34500999318936265,0.3444682873810894,0.3439614340148336,0.34348686005287454,0.3430421855275367,0.3426252071905335,0.3422338837438352,0.34186632247938625,0.34152076717596125,0.34119558711960224,0.34088926712990436,0.34060039848811136,0.3403276706749835,0.34006986383685567,0.3398258419074482,0.33959454632102504,0.33937499025954637,0.3391662533826437,0.33896747699473234,0.33877785960836243,0.338596652867213,0.33842315779586385,0.3382567213468578,0.3380967332184968,0.33794262291950705,0.3377938570590137,0.33764993684236644,0.33751039575527053,0.3373747974202869,0.3372427336113177,0.337113822413,0.33698770651315474,0.33686405161750693,0.336742544976872,0.33662289401788476,0.33650482506911683,0.3363880821751696,0.3362724259919567,0.3361576327569637,0.33604349332882005,0.3359298122909957,0.335816407114837,0.3357031073775895,0.335589754031397,0.33547619871957723,0.3353623031367951,0.33524793843000894,0.3351329846373211,0.33501733016207164,0.3349008712797459,0.3347835116754305,0.33466516200973917,0.33454573951127803,0.3344251675938716,0.3343033754968976,0.3341802979472073,0.33405587484120125,0.3339300509457742,0.33380277561687943,0.3336740025345995,0.33354368945366325,0.33341179796844406,0.33327829329150854,0.33314314404488515,0.33300632206326436,0.33286780220838363,0.33272756219392535,0.3325855824202773,0.3324418458185719,0.33229633770343736,0.33214904563394043,0.33199995928224707,0.3318490703095246,0.3316963722486903,0.33154186039356903,0.33138553169413437,0.3312273846574345,0.33106741925391486,0.3309056368288155,0.33074204001834495,0.3305766326703843,0.3304094197694459,0.3302404073656568,0.3300696025075539,0.3298970131784551,0.32972264823624015,0.3295465173563246,0.3293686309776766,0.32918900025169817,0.32900763699381547,0.32882455363764296,0.32863976319157157,0.32845327919765743,0.32826511569268785,0.3280752871713104,0.3278838085511096,0.3276906951395431,0.32749596260262054,0.32729962693525017,0.3271017044331601,0.3269022116663118,0.3267011654537296,0.32649858283967287,0.326294481071083,0.3260888775762406,0.32588178994456773,0.32567323590751746,0.3254632333204993,0.3252518001457845,0.3250389544363402,0.3248247143205519,0.324609097987782,0.32439212367472514,0.3241738096525253,0.3239541742146063,0.32373323566519224,0.32351101230846785,0.3232875224383666,0.3230627843289381,0.32283681622527116,0.32260963633495365,0.3223812628200271,0.3221517137894221,0.3219210072918533,0.3216891613091377,0.3214561937499276,0.32122212244383624,0.3209869651359266,0.3207507394815624,0.32051346304158373,0.32027515327781303,0.32003582754884835,0.3197955031061621,0.31955419709045646,0.31931192652828794,0.3190687083289379,0.3188245592815137,0.31857949605227776,0.3183335351821817,0.31808669308461107,0.3178389860433088,0.3175904302104893,0.3173410416051252,0.3170908361113868,0.3168398294772505,0.31658803731324525,0.3163354750913403,0.31608215814397084,0.31582810166317793,0.31557332069988336,0.3153178301632628,0.31506164482023497,0.31480477929504813,0.3145472480689652,0.31428906548003877]}],                        {\"legend\":{\"bgcolor\":\"#151516\",\"font\":{\"color\":\"#D9D9D9\"}},\"paper_bgcolor\":\"#151516\",\"plot_bgcolor\":\"#151516\",\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"color\":\"#D9D9D9\"}},\"xaxis\":{\"gridcolor\":\"#434343\",\"showgrid\":true,\"tickfont\":{\"color\":\"#C2C2C2\"},\"title\":{\"font\":{\"color\":\"#D9D9D9\"},\"text\":\"\"},\"zerolinecolor\":\"#666570\"},\"yaxis\":{\"gridcolor\":\"#434343\",\"showgrid\":true,\"tickfont\":{\"color\":\"#C2C2C2\"},\"title\":{\"font\":{\"color\":\"#D9D9D9\"},\"text\":\"\"},\"zerolinecolor\":\"#666570\"}},                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('1c2616c8-a62d-4f4e-8d5c-d311992dd600');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_res.iplot(theme=\"solar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:19.258123Z",
     "start_time": "2024-10-05T13:47:19.249072Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:44:46.307722Z",
     "iopub.status.busy": "2024-02-23T01:44:46.306453Z",
     "iopub.status.idle": "2024-02-23T01:44:46.338214Z",
     "shell.execute_reply": "2024-02-23T01:44:46.335386Z",
     "shell.execute_reply.started": "2024-02-23T01:44:46.307604Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_mean</th>\n",
       "      <th>r2_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.11405</td>\n",
       "      <td>0.71296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.20011</td>\n",
       "      <td>0.60525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.22428</td>\n",
       "      <td>0.57454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.24217</td>\n",
       "      <td>0.55024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.25669</td>\n",
       "      <td>0.52937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.34685</td>\n",
       "      <td>0.35689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.34691</td>\n",
       "      <td>0.35200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.34694</td>\n",
       "      <td>0.35553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.34697</td>\n",
       "      <td>0.35309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.34698</td>\n",
       "      <td>0.35426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     r2_mean  r2_std\n",
       "0    0.11405 0.71296\n",
       "5    0.20011 0.60525\n",
       "10   0.22428 0.57454\n",
       "15   0.24217 0.55024\n",
       "20   0.25669 0.52937\n",
       "..       ...     ...\n",
       "160  0.34685 0.35689\n",
       "180  0.34691 0.35200\n",
       "165  0.34694 0.35553\n",
       "175  0.34697 0.35309\n",
       "170  0.34698 0.35426\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res.sort_values(by=\"r2_mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:19.639922Z",
     "start_time": "2024-10-05T13:47:19.637324Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:44:57.030762Z",
     "iopub.status.busy": "2024-02-23T01:44:57.030529Z",
     "iopub.status.idle": "2024-02-23T01:44:57.033343Z",
     "shell.execute_reply": "2024-02-23T01:44:57.032751Z",
     "shell.execute_reply.started": "2024-02-23T01:44:57.030745Z"
    },
    "id": "66-OJ3FZSSdt"
   },
   "outputs": [],
   "source": [
    "ridgereg = Ridge(alpha=170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:19.907553Z",
     "start_time": "2024-10-05T13:47:19.901137Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:44:58.271471Z",
     "iopub.status.busy": "2024-02-23T01:44:58.271041Z",
     "iopub.status.idle": "2024-02-23T01:44:58.277648Z",
     "shell.execute_reply": "2024-02-23T01:44:58.277213Z",
     "shell.execute_reply.started": "2024-02-23T01:44:58.271453Z"
    },
    "id": "JZ0O7g9fSSdt",
    "outputId": "71027ee5-55b4-4309-e40e-5d7138ce4e03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=170)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgereg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:20.162249Z",
     "start_time": "2024-10-05T13:47:20.158413Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:45:03.928968Z",
     "iopub.status.busy": "2024-02-23T01:45:03.927133Z",
     "iopub.status.idle": "2024-02-23T01:45:03.944086Z",
     "shell.execute_reply": "2024-02-23T01:45:03.941242Z",
     "shell.execute_reply.started": "2024-02-23T01:45:03.928893Z"
    },
    "id": "ZmHY8ttySSdt",
    "outputId": "79695e0b-ad10-41af-b6b5-4cd33e04e44d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.526619339976584"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgereg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:20.380481Z",
     "start_time": "2024-10-05T13:47:20.371799Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:45:15.440644Z",
     "iopub.status.busy": "2024-02-23T01:45:15.438271Z",
     "iopub.status.idle": "2024-02-23T01:45:15.468055Z",
     "shell.execute_reply": "2024-02-23T01:45:15.465195Z",
     "shell.execute_reply.started": "2024-02-23T01:45:15.440536Z"
    },
    "id": "BqZWnuazSSdt",
    "outputId": "c8c7120a-eb00-4f9b-984c-12907cc9b38c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-1.08464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-0.83129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-0.69605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>-0.15001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.10131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>-0.05245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.01632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.00720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.00906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.05540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.32549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>0.42892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>1.82569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1\n",
       "7       DIS -1.08464\n",
       "10  PTRATIO -0.83129\n",
       "12    LSTAT -0.69605\n",
       "4       NOX -0.15001\n",
       "0      CRIM -0.10131\n",
       "2     INDUS -0.05245\n",
       "9       TAX -0.01632\n",
       "6       AGE  0.00720\n",
       "11        B  0.00906\n",
       "1        ZN  0.05540\n",
       "8       RAD  0.32549\n",
       "3      CHAS  0.42892\n",
       "5        RM  1.82569"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip(X.columns, ridgereg.coef_)).sort_values(by=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:20.620601Z",
     "start_time": "2024-10-05T13:47:20.617230Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:46:25.641559Z",
     "iopub.status.busy": "2024-02-23T01:46:25.640741Z",
     "iopub.status.idle": "2024-02-23T01:46:25.653415Z",
     "shell.execute_reply": "2024-02-23T01:46:25.650369Z",
     "shell.execute_reply.started": "2024-02-23T01:46:25.641495Z"
    },
    "id": "bGp9cA-FSSdt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dc_scores.update({str(ridgereg).split(\"(\")[0]: np.mean(ls_res)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:20.846194Z",
     "start_time": "2024-10-05T13:47:20.842447Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:46:26.387182Z",
     "iopub.status.busy": "2024-02-23T01:46:26.384975Z",
     "iopub.status.idle": "2024-02-23T01:46:26.402844Z",
     "shell.execute_reply": "2024-02-23T01:46:26.400167Z",
     "shell.execute_reply.started": "2024-02-23T01:46:26.387068Z"
    },
    "id": "XHHtFG2uSSdt",
    "outputId": "bfeb71b5-1d7f-45f6-f0e9-4520f6e63f18",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression': 0.11405301290101522,\n",
       " 'Lars': 0.11388643958845451,\n",
       " 'Ridge': 0.2873317855328939}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCTrWSc6SSdt"
   },
   "source": [
    "### Regresión Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrW4OjCuSSdt"
   },
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:21.568452Z",
     "start_time": "2024-10-05T13:47:21.566034Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:46:52.072621Z",
     "iopub.status.busy": "2024-02-23T01:46:52.070875Z",
     "iopub.status.idle": "2024-02-23T01:46:52.082005Z",
     "shell.execute_reply": "2024-02-23T01:46:52.079415Z",
     "shell.execute_reply.started": "2024-02-23T01:46:52.072543Z"
    },
    "id": "E5bPxQaQSSdt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "lassreg = Lasso(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:21.786946Z",
     "start_time": "2024-10-05T13:47:21.774251Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:46:55.022440Z",
     "iopub.status.busy": "2024-02-23T01:46:55.021382Z",
     "iopub.status.idle": "2024-02-23T01:46:55.059572Z",
     "shell.execute_reply": "2024-02-23T01:46:55.057000Z",
     "shell.execute_reply.started": "2024-02-23T01:46:55.022345Z"
    },
    "id": "KJmtULYvSSdt",
    "outputId": "57818042-0215-464b-d418-1e3449314312",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.5)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nk_wLOw7SSdt"
   },
   "source": [
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:22.260658Z",
     "start_time": "2024-10-05T13:47:22.242819Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:47:06.004821Z",
     "iopub.status.busy": "2024-02-23T01:47:06.003592Z",
     "iopub.status.idle": "2024-02-23T01:47:07.012391Z",
     "shell.execute_reply": "2024-02-23T01:47:07.011602Z",
     "shell.execute_reply.started": "2024-02-23T01:47:06.004705Z"
    },
    "id": "MS0yW6bcSSdt",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls_res = cross_val_score(estimator = lassreg, X=X, y=y, cv=4, n_jobs=-1, scoring=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:22.499736Z",
     "start_time": "2024-10-05T13:47:22.495763Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:47:07.014448Z",
     "iopub.status.busy": "2024-02-23T01:47:07.013866Z",
     "iopub.status.idle": "2024-02-23T01:47:07.019440Z",
     "shell.execute_reply": "2024-02-23T01:47:07.018749Z",
     "shell.execute_reply.started": "2024-02-23T01:47:07.014421Z"
    },
    "id": "X40YOIIYSSdt",
    "outputId": "61ecd517-2083-4e5d-ba41-1dacb1b11044",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.61654703,  0.54124089,  0.40252425, -0.68206998])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:22.731214Z",
     "start_time": "2024-10-05T13:47:22.726856Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:47:16.630918Z",
     "iopub.status.busy": "2024-02-23T01:47:16.630003Z",
     "iopub.status.idle": "2024-02-23T01:47:16.645824Z",
     "shell.execute_reply": "2024-02-23T01:47:16.643229Z",
     "shell.execute_reply.started": "2024-02-23T01:47:16.630853Z"
    },
    "id": "WP3m0OE2SSdt",
    "outputId": "56458fe6-a954-4102-c42f-811077e6ea5a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.21956054923034524, 0.526186714114679)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ls_res), np.std(ls_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:22.941119Z",
     "start_time": "2024-10-05T13:47:22.937272Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:47:20.822521Z",
     "iopub.status.busy": "2024-02-23T01:47:20.821761Z",
     "iopub.status.idle": "2024-02-23T01:47:20.837567Z",
     "shell.execute_reply": "2024-02-23T01:47:20.834469Z",
     "shell.execute_reply.started": "2024-02-23T01:47:20.822455Z"
    },
    "id": "UaW9SZyVSSdt",
    "outputId": "7685a92c-7073-46f9-88a3-c53e9913b73b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.520860962576535"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:23.213584Z",
     "start_time": "2024-10-05T13:47:23.206187Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:47:23.177994Z",
     "iopub.status.busy": "2024-02-23T01:47:23.177160Z",
     "iopub.status.idle": "2024-02-23T01:47:23.217239Z",
     "shell.execute_reply": "2024-02-23T01:47:23.214228Z",
     "shell.execute_reply.started": "2024-02-23T01:47:23.177923Z"
    },
    "id": "svfukzVLSSdt",
    "outputId": "90dee13b-2ed2-4f52-b096-829ff482b565",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-0.93660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-0.75875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-0.65629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.08329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.01544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>-0.00525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.00360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.00947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.04954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.27745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>2.49821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1\n",
       "7       DIS -0.93660\n",
       "10  PTRATIO -0.75875\n",
       "12    LSTAT -0.65629\n",
       "0      CRIM -0.08329\n",
       "9       TAX -0.01544\n",
       "2     INDUS -0.00525\n",
       "3      CHAS  0.00000\n",
       "4       NOX -0.00000\n",
       "6       AGE  0.00360\n",
       "11        B  0.00947\n",
       "1        ZN  0.04954\n",
       "8       RAD  0.27745\n",
       "5        RM  2.49821"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip(X.columns, lassreg.coef_)).sort_values(by=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NaV6ae5SSdt"
   },
   "source": [
    "#### Búsqueda de la mejor $\\alpha$ ($\\lambda$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:25.107622Z",
     "start_time": "2024-10-05T13:47:23.689420Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:48:09.089076Z",
     "iopub.status.busy": "2024-02-23T01:48:09.088134Z",
     "iopub.status.idle": "2024-02-23T01:48:11.684172Z",
     "shell.execute_reply": "2024-02-23T01:48:11.683193Z",
     "shell.execute_reply.started": "2024-02-23T01:48:09.088997Z"
    },
    "id": "-ODO3QkFSSdt",
    "outputId": "391228a2-e92e-4c01-a714-2ea295eeb4db",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 19.19% 0.61\n",
      "20 21.23% 0.58\n",
      "30 20.97% 0.57\n",
      "40 20.35% 0.57\n",
      "50 21.96% 0.53\n",
      "60 23.64% 0.49\n",
      "70 25.26% 0.45\n",
      "80 26.61% 0.41\n",
      "90 27.71% 0.38\n",
      "100 28.54% 0.35\n",
      "110 29.11% 0.32\n",
      "120 29.58% 0.29\n",
      "130 29.80% 0.26\n",
      "140 30.09% 0.24\n",
      "150 30.35% 0.22\n",
      "160 30.56% 0.21\n",
      "170 30.61% 0.19\n",
      "180 30.28% 0.19\n",
      "190 29.87% 0.18\n",
      "200 29.49% 0.17\n",
      "210 29.15% 0.16\n",
      "220 28.76% 0.16\n",
      "230 28.33% 0.15\n",
      "240 28.03% 0.15\n",
      "250 27.76% 0.14\n",
      "260 27.46% 0.14\n",
      "270 27.14% 0.13\n",
      "280 26.80% 0.13\n",
      "290 26.44% 0.12\n",
      "300 26.05% 0.12\n",
      "310 25.75% 0.11\n",
      "320 25.45% 0.11\n",
      "330 25.11% 0.10\n",
      "340 24.76% 0.10\n",
      "350 24.44% 0.10\n",
      "360 24.17% 0.10\n",
      "370 24.07% 0.09\n",
      "380 24.11% 0.09\n",
      "390 24.15% 0.09\n",
      "400 24.17% 0.09\n",
      "410 24.19% 0.09\n",
      "420 24.19% 0.09\n",
      "430 24.21% 0.09\n",
      "440 24.22% 0.09\n",
      "450 24.22% 0.08\n",
      "460 24.21% 0.08\n",
      "470 24.24% 0.08\n",
      "480 24.28% 0.08\n",
      "490 24.28% 0.08\n",
      "500 24.23% 0.08\n",
      "510 24.17% 0.08\n",
      "520 24.12% 0.08\n",
      "530 24.06% 0.08\n",
      "540 23.99% 0.08\n",
      "550 23.93% 0.08\n",
      "560 23.86% 0.08\n",
      "570 23.78% 0.08\n",
      "580 23.71% 0.08\n",
      "590 23.63% 0.08\n",
      "600 23.54% 0.08\n",
      "610 23.46% 0.08\n",
      "620 23.37% 0.08\n",
      "630 23.27% 0.07\n",
      "640 23.18% 0.07\n",
      "650 23.08% 0.07\n",
      "660 22.98% 0.07\n",
      "670 22.87% 0.07\n",
      "680 22.76% 0.07\n",
      "690 22.65% 0.07\n",
      "700 22.54% 0.07\n",
      "710 22.42% 0.07\n",
      "720 22.30% 0.07\n",
      "730 22.17% 0.07\n",
      "740 22.05% 0.07\n",
      "750 21.92% 0.07\n",
      "760 21.78% 0.07\n",
      "770 21.65% 0.07\n",
      "780 21.51% 0.07\n",
      "790 21.36% 0.07\n",
      "800 21.22% 0.07\n",
      "810 21.07% 0.07\n",
      "820 20.91% 0.07\n",
      "830 20.75% 0.07\n",
      "840 20.60% 0.07\n",
      "850 20.44% 0.07\n",
      "860 20.28% 0.07\n",
      "870 20.12% 0.07\n",
      "880 19.96% 0.07\n",
      "890 19.79% 0.07\n",
      "900 19.62% 0.07\n",
      "910 19.45% 0.07\n",
      "920 19.27% 0.07\n",
      "930 19.09% 0.07\n",
      "940 18.91% 0.07\n",
      "950 18.72% 0.07\n",
      "960 18.54% 0.07\n",
      "970 18.35% 0.07\n",
      "980 18.15% 0.07\n",
      "990 17.95% 0.07\n",
      "1000 17.75% 0.07\n"
     ]
    }
   ],
   "source": [
    "df_res = pd.DataFrame()\n",
    "for i in range(10, 1010, 10):\n",
    "    lasso = Lasso(alpha=i/100)\n",
    "    lasso.fit(X, y)\n",
    "    ls_res = cross_val_score(estimator = lasso, X=X, y=y, cv=4, n_jobs=-1, scoring=\"r2\")\n",
    "    df_res.loc[i/100, \"r2_mean\"] = np.mean(ls_res)\n",
    "    df_res.loc[i/100, \"r2_std\"] = np.std(ls_res)\n",
    "    print(i, \"{:,.2%}\".format(np.mean(ls_res)), \"{:,.2f}\".format(np.std(ls_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:25.159176Z",
     "start_time": "2024-10-05T13:47:25.128691Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:48:22.999009Z",
     "iopub.status.busy": "2024-02-23T01:48:22.998217Z",
     "iopub.status.idle": "2024-02-23T01:48:23.157649Z",
     "shell.execute_reply": "2024-02-23T01:48:23.155561Z",
     "shell.execute_reply.started": "2024-02-23T01:48:22.998945Z"
    },
    "id": "smHZDSXzSSdt",
    "outputId": "cb3a471a-cacf-4b2a-c80e-738b8bf3cf2c",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(255, 153, 51, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "r2_mean",
         "text": "",
         "type": "scatter",
         "x": [
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          1,
          1.1,
          1.2,
          1.3,
          1.4,
          1.5,
          1.6,
          1.7,
          1.8,
          1.9,
          2,
          2.1,
          2.2,
          2.3,
          2.4,
          2.5,
          2.6,
          2.7,
          2.8,
          2.9,
          3,
          3.1,
          3.2,
          3.3,
          3.4,
          3.5,
          3.6,
          3.7,
          3.8,
          3.9,
          4,
          4.1,
          4.2,
          4.3,
          4.4,
          4.5,
          4.6,
          4.7,
          4.8,
          4.9,
          5,
          5.1,
          5.2,
          5.3,
          5.4,
          5.5,
          5.6,
          5.7,
          5.8,
          5.9,
          6,
          6.1,
          6.2,
          6.3,
          6.4,
          6.5,
          6.6,
          6.7,
          6.8,
          6.9,
          7,
          7.1,
          7.2,
          7.3,
          7.4,
          7.5,
          7.6,
          7.7,
          7.8,
          7.9,
          8,
          8.1,
          8.2,
          8.3,
          8.4,
          8.5,
          8.6,
          8.7,
          8.8,
          8.9,
          9,
          9.1,
          9.2,
          9.3,
          9.4,
          9.5,
          9.6,
          9.7,
          9.8,
          9.9,
          10
         ],
         "y": [
          0.19194960906326702,
          0.21234122312360332,
          0.20972186506969387,
          0.2034963442838214,
          0.21956054923034524,
          0.2363824678355262,
          0.2525636293755302,
          0.2661485241343596,
          0.27708190794727605,
          0.285369408199368,
          0.29112498301831896,
          0.2957641478867824,
          0.29798731470420103,
          0.3008683942288434,
          0.30345367646926596,
          0.3055921587913344,
          0.3060600729140215,
          0.3028270908965788,
          0.2987227622052142,
          0.29490020415366375,
          0.2914515980703921,
          0.28757524790121447,
          0.2833275204602861,
          0.2803268958890183,
          0.2775980718724375,
          0.27463633826220124,
          0.2714408261935604,
          0.2679994503682084,
          0.2643668613230596,
          0.26048788496983355,
          0.2575448066600805,
          0.25445157174935384,
          0.25113083002161457,
          0.24757384720467368,
          0.24436806489626786,
          0.24168082418602685,
          0.24074235823692544,
          0.24110662173202133,
          0.24147287977890725,
          0.24173242176763765,
          0.24189243879576783,
          0.24194818642582996,
          0.24209292328753315,
          0.2421949259102208,
          0.24220354334468508,
          0.2421434215681451,
          0.24241625447585027,
          0.24280002646077778,
          0.24280061203000677,
          0.24228519776183277,
          0.241741085234185,
          0.2411786559526511,
          0.24057039338480826,
          0.23993027735144856,
          0.23925844532525725,
          0.23855487732915318,
          0.23781961344563324,
          0.2370525754025238,
          0.2362538223008521,
          0.23542336457154195,
          0.23455537974820037,
          0.23366155626460003,
          0.23273603991437578,
          0.23177882904003505,
          0.23078992250734814,
          0.22976932306140807,
          0.22871703070221436,
          0.22763323448610165,
          0.2265181024195889,
          0.22537129668290698,
          0.22419280968845737,
          0.2229826351493228,
          0.2217407749240012,
          0.2204672289507431,
          0.21916199706088552,
          0.21782507925442796,
          0.21645547234610513,
          0.21505518631848358,
          0.21362321443933602,
          0.2121595567086619,
          0.21066421312646214,
          0.20911886368309537,
          0.20748768426178263,
          0.2059643643629549,
          0.20441128990932067,
          0.20282839409507752,
          0.20121571553656428,
          0.19957326014117044,
          0.19790100250991177,
          0.1961989269510535,
          0.194467065023126,
          0.19270541495914564,
          0.1909139751757503,
          0.18909274567293963,
          0.18724172643461343,
          0.18536091717307254,
          0.1834503178076171,
          0.18150992833824744,
          0.17953974876496342,
          0.17753977908776553
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "r2_std",
         "text": "",
         "type": "scatter",
         "x": [
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          1,
          1.1,
          1.2,
          1.3,
          1.4,
          1.5,
          1.6,
          1.7,
          1.8,
          1.9,
          2,
          2.1,
          2.2,
          2.3,
          2.4,
          2.5,
          2.6,
          2.7,
          2.8,
          2.9,
          3,
          3.1,
          3.2,
          3.3,
          3.4,
          3.5,
          3.6,
          3.7,
          3.8,
          3.9,
          4,
          4.1,
          4.2,
          4.3,
          4.4,
          4.5,
          4.6,
          4.7,
          4.8,
          4.9,
          5,
          5.1,
          5.2,
          5.3,
          5.4,
          5.5,
          5.6,
          5.7,
          5.8,
          5.9,
          6,
          6.1,
          6.2,
          6.3,
          6.4,
          6.5,
          6.6,
          6.7,
          6.8,
          6.9,
          7,
          7.1,
          7.2,
          7.3,
          7.4,
          7.5,
          7.6,
          7.7,
          7.8,
          7.9,
          8,
          8.1,
          8.2,
          8.3,
          8.4,
          8.5,
          8.6,
          8.7,
          8.8,
          8.9,
          9,
          9.1,
          9.2,
          9.3,
          9.4,
          9.5,
          9.6,
          9.7,
          9.8,
          9.9,
          10
         ],
         "y": [
          0.6102867695079046,
          0.5793796186914828,
          0.5744393589695822,
          0.5709811753403057,
          0.526186714114679,
          0.4853166061662182,
          0.44747098675548097,
          0.4114902300604951,
          0.37737383854407763,
          0.3451753067035689,
          0.3150089674962065,
          0.2872697304004067,
          0.261688337125054,
          0.24011477427980557,
          0.2221427513510887,
          0.20656685455568122,
          0.19318747453416638,
          0.18500592187127887,
          0.17777013064018712,
          0.17116067677716928,
          0.1644896366333482,
          0.15788375948154051,
          0.15137908898918653,
          0.1456908216756428,
          0.14036699073381637,
          0.13515188302118275,
          0.1300529700533394,
          0.12510492525478312,
          0.12026436407320162,
          0.1156287955601795,
          0.11089652653309442,
          0.10638036945100701,
          0.10217343064304851,
          0.09832234150263734,
          0.0958409464330757,
          0.09510136913551867,
          0.09402972511609756,
          0.09247796428024699,
          0.0911557485083644,
          0.08995232022735124,
          0.08886362420390245,
          0.08784142195498613,
          0.08678938094672879,
          0.08579731073797543,
          0.08488176903503292,
          0.08402972981569466,
          0.08295617933855358,
          0.08184232754215243,
          0.08100265732287613,
          0.08048439647928472,
          0.07997936396334143,
          0.07947879088725159,
          0.07900291211883066,
          0.07854069542953433,
          0.07809154879350638,
          0.07765503770181667,
          0.07723065012765613,
          0.07681799009557173,
          0.07641659086375707,
          0.07602603361782796,
          0.07564863822464751,
          0.07527850226920231,
          0.07491807155511147,
          0.07456701448061068,
          0.07422502251123575,
          0.07389180819989148,
          0.07356711174899867,
          0.07325053354391803,
          0.07294171498946214,
          0.0726407718902846,
          0.07234756101253412,
          0.07206196758616384,
          0.07178390035942116,
          0.07151329993233706,
          0.07125013827121345,
          0.0709944198052859,
          0.07074655160599845,
          0.07050585686308998,
          0.07027281697310156,
          0.0700475706105006,
          0.06983029117538456,
          0.0696272909913141,
          0.06955596201151072,
          0.06972804434743189,
          0.06991116477044429,
          0.07010540340053809,
          0.07031104818673418,
          0.07052836173354358,
          0.07075762575153942,
          0.07099916131572209,
          0.07125327934249347,
          0.0715203395856423,
          0.0718007269977964,
          0.07209485291890858,
          0.07240315115631085,
          0.0727260762666104,
          0.07306410301643637,
          0.07341772477099118,
          0.07378745190847402,
          0.07417381032332207
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#151516",
         "font": {
          "color": "#D9D9D9"
         }
        },
        "paper_bgcolor": "#151516",
        "plot_bgcolor": "#151516",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "#D9D9D9"
         }
        },
        "xaxis": {
         "gridcolor": "#434343",
         "showgrid": true,
         "tickfont": {
          "color": "#C2C2C2"
         },
         "title": {
          "font": {
           "color": "#D9D9D9"
          },
          "text": ""
         },
         "zerolinecolor": "#666570"
        },
        "yaxis": {
         "gridcolor": "#434343",
         "showgrid": true,
         "tickfont": {
          "color": "#C2C2C2"
         },
         "title": {
          "font": {
           "color": "#D9D9D9"
          },
          "text": ""
         },
         "zerolinecolor": "#666570"
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"0d0aba8e-ea64-4d01-86fe-d8b8cbb80e42\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';                                    if (document.getElementById(\"0d0aba8e-ea64-4d01-86fe-d8b8cbb80e42\")) {                    Plotly.newPlot(                        \"0d0aba8e-ea64-4d01-86fe-d8b8cbb80e42\",                        [{\"line\":{\"color\":\"rgba(255, 153, 51, 1.0)\",\"dash\":\"solid\",\"shape\":\"linear\",\"width\":1.3},\"mode\":\"lines\",\"name\":\"r2_mean\",\"text\":\"\",\"type\":\"scatter\",\"x\":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3.0,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4.0,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9,5.0,5.1,5.2,5.3,5.4,5.5,5.6,5.7,5.8,5.9,6.0,6.1,6.2,6.3,6.4,6.5,6.6,6.7,6.8,6.9,7.0,7.1,7.2,7.3,7.4,7.5,7.6,7.7,7.8,7.9,8.0,8.1,8.2,8.3,8.4,8.5,8.6,8.7,8.8,8.9,9.0,9.1,9.2,9.3,9.4,9.5,9.6,9.7,9.8,9.9,10.0],\"y\":[0.19194960906326702,0.21234122312360332,0.20972186506969387,0.2034963442838214,0.21956054923034524,0.2363824678355262,0.2525636293755302,0.2661485241343596,0.27708190794727605,0.285369408199368,0.29112498301831896,0.2957641478867824,0.29798731470420103,0.3008683942288434,0.30345367646926596,0.3055921587913344,0.3060600729140215,0.3028270908965788,0.2987227622052142,0.29490020415366375,0.2914515980703921,0.28757524790121447,0.2833275204602861,0.2803268958890183,0.2775980718724375,0.27463633826220124,0.2714408261935604,0.2679994503682084,0.2643668613230596,0.26048788496983355,0.2575448066600805,0.25445157174935384,0.25113083002161457,0.24757384720467368,0.24436806489626786,0.24168082418602685,0.24074235823692544,0.24110662173202133,0.24147287977890725,0.24173242176763765,0.24189243879576783,0.24194818642582996,0.24209292328753315,0.2421949259102208,0.24220354334468508,0.2421434215681451,0.24241625447585027,0.24280002646077778,0.24280061203000677,0.24228519776183277,0.241741085234185,0.2411786559526511,0.24057039338480826,0.23993027735144856,0.23925844532525725,0.23855487732915318,0.23781961344563324,0.2370525754025238,0.2362538223008521,0.23542336457154195,0.23455537974820037,0.23366155626460003,0.23273603991437578,0.23177882904003505,0.23078992250734814,0.22976932306140807,0.22871703070221436,0.22763323448610165,0.2265181024195889,0.22537129668290698,0.22419280968845737,0.2229826351493228,0.2217407749240012,0.2204672289507431,0.21916199706088552,0.21782507925442796,0.21645547234610513,0.21505518631848358,0.21362321443933602,0.2121595567086619,0.21066421312646214,0.20911886368309537,0.20748768426178263,0.2059643643629549,0.20441128990932067,0.20282839409507752,0.20121571553656428,0.19957326014117044,0.19790100250991177,0.1961989269510535,0.194467065023126,0.19270541495914564,0.1909139751757503,0.18909274567293963,0.18724172643461343,0.18536091717307254,0.1834503178076171,0.18150992833824744,0.17953974876496342,0.17753977908776553]},{\"line\":{\"color\":\"rgba(55, 128, 191, 1.0)\",\"dash\":\"solid\",\"shape\":\"linear\",\"width\":1.3},\"mode\":\"lines\",\"name\":\"r2_std\",\"text\":\"\",\"type\":\"scatter\",\"x\":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3.0,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4.0,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9,5.0,5.1,5.2,5.3,5.4,5.5,5.6,5.7,5.8,5.9,6.0,6.1,6.2,6.3,6.4,6.5,6.6,6.7,6.8,6.9,7.0,7.1,7.2,7.3,7.4,7.5,7.6,7.7,7.8,7.9,8.0,8.1,8.2,8.3,8.4,8.5,8.6,8.7,8.8,8.9,9.0,9.1,9.2,9.3,9.4,9.5,9.6,9.7,9.8,9.9,10.0],\"y\":[0.6102867695079046,0.5793796186914828,0.5744393589695822,0.5709811753403057,0.526186714114679,0.4853166061662182,0.44747098675548097,0.4114902300604951,0.37737383854407763,0.3451753067035689,0.3150089674962065,0.2872697304004067,0.261688337125054,0.24011477427980557,0.2221427513510887,0.20656685455568122,0.19318747453416638,0.18500592187127887,0.17777013064018712,0.17116067677716928,0.1644896366333482,0.15788375948154051,0.15137908898918653,0.1456908216756428,0.14036699073381637,0.13515188302118275,0.1300529700533394,0.12510492525478312,0.12026436407320162,0.1156287955601795,0.11089652653309442,0.10638036945100701,0.10217343064304851,0.09832234150263734,0.0958409464330757,0.09510136913551867,0.09402972511609756,0.09247796428024699,0.0911557485083644,0.08995232022735124,0.08886362420390245,0.08784142195498613,0.08678938094672879,0.08579731073797543,0.08488176903503292,0.08402972981569466,0.08295617933855358,0.08184232754215243,0.08100265732287613,0.08048439647928472,0.07997936396334143,0.07947879088725159,0.07900291211883066,0.07854069542953433,0.07809154879350638,0.07765503770181667,0.07723065012765613,0.07681799009557173,0.07641659086375707,0.07602603361782796,0.07564863822464751,0.07527850226920231,0.07491807155511147,0.07456701448061068,0.07422502251123575,0.07389180819989148,0.07356711174899867,0.07325053354391803,0.07294171498946214,0.0726407718902846,0.07234756101253412,0.07206196758616384,0.07178390035942116,0.07151329993233706,0.07125013827121345,0.0709944198052859,0.07074655160599845,0.07050585686308998,0.07027281697310156,0.0700475706105006,0.06983029117538456,0.0696272909913141,0.06955596201151072,0.06972804434743189,0.06991116477044429,0.07010540340053809,0.07031104818673418,0.07052836173354358,0.07075762575153942,0.07099916131572209,0.07125327934249347,0.0715203395856423,0.0718007269977964,0.07209485291890858,0.07240315115631085,0.0727260762666104,0.07306410301643637,0.07341772477099118,0.07378745190847402,0.07417381032332207]}],                        {\"legend\":{\"bgcolor\":\"#151516\",\"font\":{\"color\":\"#D9D9D9\"}},\"paper_bgcolor\":\"#151516\",\"plot_bgcolor\":\"#151516\",\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"color\":\"#D9D9D9\"}},\"xaxis\":{\"gridcolor\":\"#434343\",\"showgrid\":true,\"tickfont\":{\"color\":\"#C2C2C2\"},\"title\":{\"font\":{\"color\":\"#D9D9D9\"},\"text\":\"\"},\"zerolinecolor\":\"#666570\"},\"yaxis\":{\"gridcolor\":\"#434343\",\"showgrid\":true,\"tickfont\":{\"color\":\"#C2C2C2\"},\"title\":{\"font\":{\"color\":\"#D9D9D9\"},\"text\":\"\"},\"zerolinecolor\":\"#666570\"}},                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('0d0aba8e-ea64-4d01-86fe-d8b8cbb80e42');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_res.iplot(theme=\"solar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:25.178645Z",
     "start_time": "2024-10-05T13:47:25.176847Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:48:39.715097Z",
     "iopub.status.busy": "2024-02-23T01:48:39.713956Z",
     "iopub.status.idle": "2024-02-23T01:48:39.730466Z",
     "shell.execute_reply": "2024-02-23T01:48:39.726125Z",
     "shell.execute_reply.started": "2024-02-23T01:48:39.714990Z"
    },
    "id": "Xhoz5hzRSSdt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=1.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:25.202324Z",
     "start_time": "2024-10-05T13:47:25.197811Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:49:40.191389Z",
     "iopub.status.busy": "2024-02-23T01:49:40.188540Z",
     "iopub.status.idle": "2024-02-23T01:49:40.225086Z",
     "shell.execute_reply": "2024-02-23T01:49:40.223168Z",
     "shell.execute_reply.started": "2024-02-23T01:49:40.191254Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.7)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:25.236594Z",
     "start_time": "2024-10-05T13:47:25.222772Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:48:41.749607Z",
     "iopub.status.busy": "2024-02-23T01:48:41.747416Z",
     "iopub.status.idle": "2024-02-23T01:48:41.830634Z",
     "shell.execute_reply": "2024-02-23T01:48:41.827653Z",
     "shell.execute_reply.started": "2024-02-23T01:48:41.749491Z"
    },
    "id": "4108EP5RSSdt",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls_res = cross_val_score(estimator = lasso, X=X, y=y, cv=4, n_jobs=-1, scoring=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:25.258857Z",
     "start_time": "2024-10-05T13:47:25.255596Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:48:49.580055Z",
     "iopub.status.busy": "2024-02-23T01:48:49.579031Z",
     "iopub.status.idle": "2024-02-23T01:48:49.594810Z",
     "shell.execute_reply": "2024-02-23T01:48:49.592291Z",
     "shell.execute_reply.started": "2024-02-23T01:48:49.579955Z"
    },
    "id": "7mRLnHPCSSdt",
    "outputId": "f658b12d-e7dc-4a1b-abbf-d688b6cc6b6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3060600729140215, 0.19318747453416638)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ls_res), np.std(ls_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:25.280190Z",
     "start_time": "2024-10-05T13:47:25.278061Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:48:56.916565Z",
     "iopub.status.busy": "2024-02-23T01:48:56.915744Z",
     "iopub.status.idle": "2024-02-23T01:48:56.930056Z",
     "shell.execute_reply": "2024-02-23T01:48:56.926886Z",
     "shell.execute_reply.started": "2024-02-23T01:48:56.916494Z"
    },
    "id": "6Q4yhyErSSdt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dc_scores.update({str(lasso).split(\"(\")[0]: np.mean(ls_res)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:25.377581Z",
     "start_time": "2024-10-05T13:47:25.373912Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:49:43.601867Z",
     "iopub.status.busy": "2024-02-23T01:49:43.600767Z",
     "iopub.status.idle": "2024-02-23T01:49:43.618136Z",
     "shell.execute_reply": "2024-02-23T01:49:43.615520Z",
     "shell.execute_reply.started": "2024-02-23T01:49:43.601770Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03442211,  0.04128167, -0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.0383725 , -0.25813687,  0.2086137 , -0.01309635,\n",
       "       -0.61915531,  0.00724909, -0.82303498])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:25.621095Z",
     "start_time": "2024-10-05T13:47:25.617041Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:48:57.307153Z",
     "iopub.status.busy": "2024-02-23T01:48:57.305562Z",
     "iopub.status.idle": "2024-02-23T01:48:57.325351Z",
     "shell.execute_reply": "2024-02-23T01:48:57.322086Z",
     "shell.execute_reply.started": "2024-02-23T01:48:57.307021Z"
    },
    "id": "CVCZwioYSSdu",
    "outputId": "f88516b3-50f4-4453-89ba-a2b4ecb45f43",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression': 0.11405301290101522,\n",
       " 'Lars': 0.11388643958845451,\n",
       " 'Ridge': 0.2873317855328939,\n",
       " 'Lasso': 0.3060600729140215}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKOplPxZSSdu"
   },
   "source": [
    "### Red elástica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1b3CF40SSdu"
   },
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T14:45:13.851815Z",
     "start_time": "2024-10-05T14:45:13.847843Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:50:25.363915Z",
     "iopub.status.busy": "2024-02-23T01:50:25.362656Z",
     "iopub.status.idle": "2024-02-23T01:50:25.381115Z",
     "shell.execute_reply": "2024-02-23T01:50:25.378362Z",
     "shell.execute_reply.started": "2024-02-23T01:50:25.363813Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `elasnet` not found.\n"
     ]
    }
   ],
   "source": [
    "elasnet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:26.540637Z",
     "start_time": "2024-10-05T13:47:26.537928Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:50:21.965213Z",
     "iopub.status.busy": "2024-02-23T01:50:21.964104Z",
     "iopub.status.idle": "2024-02-23T01:50:21.978738Z",
     "shell.execute_reply": "2024-02-23T01:50:21.974995Z",
     "shell.execute_reply.started": "2024-02-23T01:50:21.965114Z"
    },
    "id": "-HDoXxxASSdu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "elasnet = ElasticNet(alpha=0.5, l1_ratio=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:26.777739Z",
     "start_time": "2024-10-05T13:47:26.770391Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:50:42.693288Z",
     "iopub.status.busy": "2024-02-23T01:50:42.692130Z",
     "iopub.status.idle": "2024-02-23T01:50:42.729086Z",
     "shell.execute_reply": "2024-02-23T01:50:42.725951Z",
     "shell.execute_reply.started": "2024-02-23T01:50:42.693192Z"
    },
    "id": "ZnkvPayDSSdu",
    "outputId": "0f4f8df0-4d02-4297-f3f1-e8f1318dd213",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.5, l1_ratio=0.99)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasnet.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:27.025544Z",
     "start_time": "2024-10-05T13:47:27.019270Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:50:42.946059Z",
     "iopub.status.busy": "2024-02-23T01:50:42.945679Z",
     "iopub.status.idle": "2024-02-23T01:50:42.952576Z",
     "shell.execute_reply": "2024-02-23T01:50:42.951860Z",
     "shell.execute_reply.started": "2024-02-23T01:50:42.946042Z"
    },
    "id": "NxbGWDbmSSdu",
    "outputId": "ae6319da-6351-424a-accc-18da28620095",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7137510399466247"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasnet.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Is1l71P8SSdu"
   },
   "source": [
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:27.477275Z",
     "start_time": "2024-10-05T13:47:27.455896Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:50:49.459500Z",
     "iopub.status.busy": "2024-02-23T01:50:49.458680Z",
     "iopub.status.idle": "2024-02-23T01:50:49.536085Z",
     "shell.execute_reply": "2024-02-23T01:50:49.533333Z",
     "shell.execute_reply.started": "2024-02-23T01:50:49.459430Z"
    },
    "id": "R1eVdRKNSSdu",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls_res = cross_val_score(estimator = elasnet, X=X, y=y, cv=4, n_jobs=-1, scoring=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:27.696444Z",
     "start_time": "2024-10-05T13:47:27.692221Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:50:56.430060Z",
     "iopub.status.busy": "2024-02-23T01:50:56.428387Z",
     "iopub.status.idle": "2024-02-23T01:50:56.445063Z",
     "shell.execute_reply": "2024-02-23T01:50:56.441543Z",
     "shell.execute_reply.started": "2024-02-23T01:50:56.429975Z"
    },
    "id": "U0ktP4Z7SSdu",
    "outputId": "fae2ae53-66b1-45b9-a938-57e49ca03a9e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.61565046,  0.54238742,  0.40550095, -0.66940779])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:27.920109Z",
     "start_time": "2024-10-05T13:47:27.915950Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:51:02.072206Z",
     "iopub.status.busy": "2024-02-23T01:51:02.070214Z",
     "iopub.status.idle": "2024-02-23T01:51:02.089037Z",
     "shell.execute_reply": "2024-02-23T01:51:02.086842Z",
     "shell.execute_reply.started": "2024-02-23T01:51:02.072105Z"
    },
    "id": "8RhjyXdQSSdu",
    "outputId": "6ac7d6b2-f3ec-4e8e-c9f0-415fdbc8dc97",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.223532759438005, 0.5210277908378571)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ls_res), np.std(ls_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T21:51:21.760825Z",
     "iopub.status.busy": "2021-12-01T21:51:21.760547Z",
     "iopub.status.idle": "2021-12-01T21:51:21.764871Z",
     "shell.execute_reply": "2021-12-01T21:51:21.764160Z",
     "shell.execute_reply.started": "2021-12-01T21:51:21.760791Z"
    },
    "id": "pOcAV-YuSSdu"
   },
   "source": [
    "#### Búsqueda de la mejor $\\alpha$ ($\\lambda$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:45.823213Z",
     "start_time": "2024-10-05T13:47:28.376934Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:51:07.086233Z",
     "iopub.status.busy": "2024-02-23T01:51:07.084188Z"
    },
    "id": "krEVEzrnSSdu",
    "outputId": "6ac9f04a-bd89-43d3-dbd0-4c3770da27bb",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.199e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.488e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.143e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.429e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.609e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.456e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.892e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.723e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.677e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.251e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.642e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.818e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.914e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.093e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.332e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.791e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.053e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.401e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.932e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.249e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.916e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.030e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.377e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.462e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.160e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.024e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.248e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.486e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.116e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.517e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.121e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.569e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.193e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.582e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.322e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.209e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.617e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.263e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.386e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.669e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.290e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.663e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.747e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.328e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.443e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.365e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.388e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.706e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.494e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.820e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.435e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.747e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.540e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.887e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.444e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.501e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.583e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.496e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.951e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.787e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.563e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.010e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.824e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.546e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.622e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.623e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.659e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.067e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.594e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.860e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.679e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.121e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.693e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.895e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.639e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.734e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.726e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.929e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.173e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.682e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.786e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.723e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.961e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.757e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.223e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.836e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.271e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.763e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.992e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.786e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.885e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.801e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.023e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.317e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.814e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.932e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.052e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.362e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.838e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.841e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.977e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.874e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.867e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.081e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.406e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.021e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.891e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.909e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.448e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.108e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.064e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.135e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.915e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.942e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.489e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.105e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.975e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.938e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.162e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.529e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.146e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.961e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.007e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.188e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.568e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.185e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.982e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.213e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.038e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.605e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.224e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.642e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.068e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.237e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.003e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.262e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.261e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.024e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.098e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.679e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.298e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.126e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.044e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.285e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.714e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.334e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.154e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.749e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.063e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.307e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.369e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.182e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.330e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.082e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.783e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.404e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.352e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.816e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.209e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.100e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.438e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.374e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.849e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.235e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.118e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.471e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.261e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.395e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.136e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.881e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.503e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.286e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.416e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.153e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.912e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.535e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.170e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.943e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.311e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.436e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.567e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.456e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.336e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.974e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.187e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.597e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.003e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.476e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.360e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.203e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.628e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.383e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.219e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.495e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.033e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.657e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.406e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.514e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.235e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.062e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.687e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.533e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.429e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.250e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.090e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.715e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.452e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.551e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.265e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.118e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.744e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.280e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.146e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.474e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.570e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.772e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.496e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.173e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.587e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.295e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.799e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.605e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.309e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.517e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.200e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.826e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.538e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.323e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.623e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.227e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.853e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.640e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.337e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.559e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.253e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.880e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.579e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.657e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.351e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.279e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.906e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.673e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.365e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.600e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.304e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.931e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.620e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.329e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.690e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.378e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.957e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.706e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.354e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.639e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.391e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.982e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.659e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.404e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.379e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.722e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.006e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.403e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.738e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.678e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.417e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.031e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.697e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.753e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.430e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.427e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.055e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.716e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.450e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.769e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.442e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.079e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.734e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.784e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.455e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.474e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.102e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.753e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.497e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.467e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.799e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.126e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.771e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.814e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.479e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.520e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.149e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.491e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.789e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.828e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.542e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.171e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.843e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.806e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.503e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.564e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.194e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.857e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.514e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.824e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.587e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.216e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.526e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.871e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.841e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.608e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.238e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.858e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.630e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.885e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.537e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.260e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.875e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.651e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.899e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.548e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.281e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.892e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.913e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.560e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.672e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.303e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.909e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.927e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.571e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.693e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.324e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.925e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.714e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.582e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.940e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.344e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.941e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.953e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.592e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.735e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.365e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.603e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.966e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.958e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.755e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.386e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.775e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.973e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.614e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.979e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.406e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.992e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.624e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.989e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.795e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.426e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.005e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.005e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.635e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.815e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.446e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.645e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.834e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.020e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.018e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.465e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.853e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.036e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.030e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.655e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.485e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.873e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.051e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.043e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.665e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.504e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.892e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.675e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.066e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.055e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.523e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.067e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.910e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.081e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.685e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.542e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.079e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.929e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.096e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.695e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.561e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.091e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.705e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.111e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.948e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.580e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.125e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.103e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.714e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.966e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.598e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.140e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.984e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.724e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.115e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.617e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.002e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.733e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.126e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.154e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.635e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.168e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.743e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.138e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.020e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.653e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.182e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.752e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.038e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.149e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.671e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.196e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.160e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.761e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.055e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.688e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.210e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.172e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.771e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.073e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.706e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.090e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.224e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.183e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.780e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.723e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.789e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.238e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.194e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.107e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.740e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.251e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.205e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.798e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.124e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.758e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.265e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.215e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.806e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.141e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.775e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.226e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.278e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.157e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.815e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.791e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.291e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.237e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.174e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.824e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.808e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.304e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.190e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.247e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.833e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.825e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.841e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.318e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.258e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.207e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.841e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.330e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.268e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.223e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.850e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.858e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.858e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.279e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.239e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.343e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.874e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.867e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.289e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.356e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.255e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.890e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.369e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.299e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.875e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.271e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.906e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.309e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.286e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.884e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.381e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "df_res = pd.DataFrame(columns=[\"alpha\", \"l1_ratio\", \"score\", \"std\"])\n",
    "contador = 0\n",
    "for i in range(10, 1000, 10):\n",
    "    for j in range(10):\n",
    "        elasnet = ElasticNet(alpha=i/100, l1_ratio=j/10, max_iter=2500)\n",
    "        elasnet.fit(X, y)\n",
    "        ls_res = cross_val_score(estimator = elasnet, X=X, y=y, cv=4, n_jobs=-1, scoring=\"r2\")\n",
    "        df_res.loc[contador, \"alpha\"] = i/100\n",
    "        df_res.loc[contador, \"l1_ratio\"] = j/10\n",
    "        df_res.loc[contador, \"score\"] = np.mean(ls_res)\n",
    "        df_res.loc[contador, \"std\"] = np.std(ls_res)\n",
    "        contador += 1\n",
    "#         print(i/100, j/10, \"{:,.2%}\".format(np.mean(ls_res)), \"{:,.2f}\".format(np.std(ls_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:45.855266Z",
     "start_time": "2024-10-05T13:47:45.852350Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:53:24.468887Z",
     "iopub.status.busy": "2024-02-23T01:53:24.468591Z",
     "iopub.status.idle": "2024-02-23T01:53:24.473408Z",
     "shell.execute_reply": "2024-02-23T01:53:24.472573Z",
     "shell.execute_reply.started": "2024-02-23T01:53:24.468864Z"
    },
    "id": "FCHoOr5RSSdv",
    "outputId": "cf0c5c87-f604-4e41-c88a-c8877d3d2553",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "990"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:45.933326Z",
     "start_time": "2024-10-05T13:47:45.883899Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:53:40.750533Z",
     "iopub.status.busy": "2024-02-23T01:53:40.750212Z",
     "iopub.status.idle": "2024-02-23T01:53:40.803133Z",
     "shell.execute_reply": "2024-02-23T01:53:40.802512Z",
     "shell.execute_reply.started": "2024-02-23T01:53:40.750506Z"
    },
    "id": "hZ-8QJl-SSdv",
    "outputId": "a52d6117-5746-4d80-ae4e-d754c4a3eb9c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "score",
         "text": "",
         "type": "scatter",
         "x": [
          "(0.1,0.0)",
          "(0.1,0.1)",
          "(0.1,0.2)",
          "(0.1,0.3)",
          "(0.1,0.4)",
          "(0.1,0.5)",
          "(0.1,0.6)",
          "(0.1,0.7)",
          "(0.1,0.8)",
          "(0.1,0.9)",
          "(0.2,0.0)",
          "(0.2,0.1)",
          "(0.2,0.2)",
          "(0.2,0.3)",
          "(0.2,0.4)",
          "(0.2,0.5)",
          "(0.2,0.6)",
          "(0.2,0.7)",
          "(0.2,0.8)",
          "(0.2,0.9)",
          "(0.3,0.0)",
          "(0.3,0.1)",
          "(0.3,0.2)",
          "(0.3,0.3)",
          "(0.3,0.4)",
          "(0.3,0.5)",
          "(0.3,0.6)",
          "(0.3,0.7)",
          "(0.3,0.8)",
          "(0.3,0.9)",
          "(0.4,0.0)",
          "(0.4,0.1)",
          "(0.4,0.2)",
          "(0.4,0.3)",
          "(0.4,0.4)",
          "(0.4,0.5)",
          "(0.4,0.6)",
          "(0.4,0.7)",
          "(0.4,0.8)",
          "(0.4,0.9)",
          "(0.5,0.0)",
          "(0.5,0.1)",
          "(0.5,0.2)",
          "(0.5,0.3)",
          "(0.5,0.4)",
          "(0.5,0.5)",
          "(0.5,0.6)",
          "(0.5,0.7)",
          "(0.5,0.8)",
          "(0.5,0.9)",
          "(0.6,0.0)",
          "(0.6,0.1)",
          "(0.6,0.2)",
          "(0.6,0.3)",
          "(0.6,0.4)",
          "(0.6,0.5)",
          "(0.6,0.6)",
          "(0.6,0.7)",
          "(0.6,0.8)",
          "(0.6,0.9)",
          "(0.7,0.0)",
          "(0.7,0.1)",
          "(0.7,0.2)",
          "(0.7,0.3)",
          "(0.7,0.4)",
          "(0.7,0.5)",
          "(0.7,0.6)",
          "(0.7,0.7)",
          "(0.7,0.8)",
          "(0.7,0.9)",
          "(0.8,0.0)",
          "(0.8,0.1)",
          "(0.8,0.2)",
          "(0.8,0.3)",
          "(0.8,0.4)",
          "(0.8,0.5)",
          "(0.8,0.6)",
          "(0.8,0.7)",
          "(0.8,0.8)",
          "(0.8,0.9)",
          "(0.9,0.0)",
          "(0.9,0.1)",
          "(0.9,0.2)",
          "(0.9,0.3)",
          "(0.9,0.4)",
          "(0.9,0.5)",
          "(0.9,0.6)",
          "(0.9,0.7)",
          "(0.9,0.8)",
          "(0.9,0.9)",
          "(1.0,0.0)",
          "(1.0,0.1)",
          "(1.0,0.2)",
          "(1.0,0.3)",
          "(1.0,0.4)",
          "(1.0,0.5)",
          "(1.0,0.6)",
          "(1.0,0.7)",
          "(1.0,0.8)",
          "(1.0,0.9)",
          "(1.1,0.0)",
          "(1.1,0.1)",
          "(1.1,0.2)",
          "(1.1,0.3)",
          "(1.1,0.4)",
          "(1.1,0.5)",
          "(1.1,0.6)",
          "(1.1,0.7)",
          "(1.1,0.8)",
          "(1.1,0.9)",
          "(1.2,0.0)",
          "(1.2,0.1)",
          "(1.2,0.2)",
          "(1.2,0.3)",
          "(1.2,0.4)",
          "(1.2,0.5)",
          "(1.2,0.6)",
          "(1.2,0.7)",
          "(1.2,0.8)",
          "(1.2,0.9)",
          "(1.3,0.0)",
          "(1.3,0.1)",
          "(1.3,0.2)",
          "(1.3,0.3)",
          "(1.3,0.4)",
          "(1.3,0.5)",
          "(1.3,0.6)",
          "(1.3,0.7)",
          "(1.3,0.8)",
          "(1.3,0.9)",
          "(1.4,0.0)",
          "(1.4,0.1)",
          "(1.4,0.2)",
          "(1.4,0.3)",
          "(1.4,0.4)",
          "(1.4,0.5)",
          "(1.4,0.6)",
          "(1.4,0.7)",
          "(1.4,0.8)",
          "(1.4,0.9)",
          "(1.5,0.0)",
          "(1.5,0.1)",
          "(1.5,0.2)",
          "(1.5,0.3)",
          "(1.5,0.4)",
          "(1.5,0.5)",
          "(1.5,0.6)",
          "(1.5,0.7)",
          "(1.5,0.8)",
          "(1.5,0.9)",
          "(1.6,0.0)",
          "(1.6,0.1)",
          "(1.6,0.2)",
          "(1.6,0.3)",
          "(1.6,0.4)",
          "(1.6,0.5)",
          "(1.6,0.6)",
          "(1.6,0.7)",
          "(1.6,0.8)",
          "(1.6,0.9)",
          "(1.7,0.0)",
          "(1.7,0.1)",
          "(1.7,0.2)",
          "(1.7,0.3)",
          "(1.7,0.4)",
          "(1.7,0.5)",
          "(1.7,0.6)",
          "(1.7,0.7)",
          "(1.7,0.8)",
          "(1.7,0.9)",
          "(1.8,0.0)",
          "(1.8,0.1)",
          "(1.8,0.2)",
          "(1.8,0.3)",
          "(1.8,0.4)",
          "(1.8,0.5)",
          "(1.8,0.6)",
          "(1.8,0.7)",
          "(1.8,0.8)",
          "(1.8,0.9)",
          "(1.9,0.0)",
          "(1.9,0.1)",
          "(1.9,0.2)",
          "(1.9,0.3)",
          "(1.9,0.4)",
          "(1.9,0.5)",
          "(1.9,0.6)",
          "(1.9,0.7)",
          "(1.9,0.8)",
          "(1.9,0.9)",
          "(2.0,0.0)",
          "(2.0,0.1)",
          "(2.0,0.2)",
          "(2.0,0.3)",
          "(2.0,0.4)",
          "(2.0,0.5)",
          "(2.0,0.6)",
          "(2.0,0.7)",
          "(2.0,0.8)",
          "(2.0,0.9)",
          "(2.1,0.0)",
          "(2.1,0.1)",
          "(2.1,0.2)",
          "(2.1,0.3)",
          "(2.1,0.4)",
          "(2.1,0.5)",
          "(2.1,0.6)",
          "(2.1,0.7)",
          "(2.1,0.8)",
          "(2.1,0.9)",
          "(2.2,0.0)",
          "(2.2,0.1)",
          "(2.2,0.2)",
          "(2.2,0.3)",
          "(2.2,0.4)",
          "(2.2,0.5)",
          "(2.2,0.6)",
          "(2.2,0.7)",
          "(2.2,0.8)",
          "(2.2,0.9)",
          "(2.3,0.0)",
          "(2.3,0.1)",
          "(2.3,0.2)",
          "(2.3,0.3)",
          "(2.3,0.4)",
          "(2.3,0.5)",
          "(2.3,0.6)",
          "(2.3,0.7)",
          "(2.3,0.8)",
          "(2.3,0.9)",
          "(2.4,0.0)",
          "(2.4,0.1)",
          "(2.4,0.2)",
          "(2.4,0.3)",
          "(2.4,0.4)",
          "(2.4,0.5)",
          "(2.4,0.6)",
          "(2.4,0.7)",
          "(2.4,0.8)",
          "(2.4,0.9)",
          "(2.5,0.0)",
          "(2.5,0.1)",
          "(2.5,0.2)",
          "(2.5,0.3)",
          "(2.5,0.4)",
          "(2.5,0.5)",
          "(2.5,0.6)",
          "(2.5,0.7)",
          "(2.5,0.8)",
          "(2.5,0.9)",
          "(2.6,0.0)",
          "(2.6,0.1)",
          "(2.6,0.2)",
          "(2.6,0.3)",
          "(2.6,0.4)",
          "(2.6,0.5)",
          "(2.6,0.6)",
          "(2.6,0.7)",
          "(2.6,0.8)",
          "(2.6,0.9)",
          "(2.7,0.0)",
          "(2.7,0.1)",
          "(2.7,0.2)",
          "(2.7,0.3)",
          "(2.7,0.4)",
          "(2.7,0.5)",
          "(2.7,0.6)",
          "(2.7,0.7)",
          "(2.7,0.8)",
          "(2.7,0.9)",
          "(2.8,0.0)",
          "(2.8,0.1)",
          "(2.8,0.2)",
          "(2.8,0.3)",
          "(2.8,0.4)",
          "(2.8,0.5)",
          "(2.8,0.6)",
          "(2.8,0.7)",
          "(2.8,0.8)",
          "(2.8,0.9)",
          "(2.9,0.0)",
          "(2.9,0.1)",
          "(2.9,0.2)",
          "(2.9,0.3)",
          "(2.9,0.4)",
          "(2.9,0.5)",
          "(2.9,0.6)",
          "(2.9,0.7)",
          "(2.9,0.8)",
          "(2.9,0.9)",
          "(3.0,0.0)",
          "(3.0,0.1)",
          "(3.0,0.2)",
          "(3.0,0.3)",
          "(3.0,0.4)",
          "(3.0,0.5)",
          "(3.0,0.6)",
          "(3.0,0.7)",
          "(3.0,0.8)",
          "(3.0,0.9)",
          "(3.1,0.0)",
          "(3.1,0.1)",
          "(3.1,0.2)",
          "(3.1,0.3)",
          "(3.1,0.4)",
          "(3.1,0.5)",
          "(3.1,0.6)",
          "(3.1,0.7)",
          "(3.1,0.8)",
          "(3.1,0.9)",
          "(3.2,0.0)",
          "(3.2,0.1)",
          "(3.2,0.2)",
          "(3.2,0.3)",
          "(3.2,0.4)",
          "(3.2,0.5)",
          "(3.2,0.6)",
          "(3.2,0.7)",
          "(3.2,0.8)",
          "(3.2,0.9)",
          "(3.3,0.0)",
          "(3.3,0.1)",
          "(3.3,0.2)",
          "(3.3,0.3)",
          "(3.3,0.4)",
          "(3.3,0.5)",
          "(3.3,0.6)",
          "(3.3,0.7)",
          "(3.3,0.8)",
          "(3.3,0.9)",
          "(3.4,0.0)",
          "(3.4,0.1)",
          "(3.4,0.2)",
          "(3.4,0.3)",
          "(3.4,0.4)",
          "(3.4,0.5)",
          "(3.4,0.6)",
          "(3.4,0.7)",
          "(3.4,0.8)",
          "(3.4,0.9)",
          "(3.5,0.0)",
          "(3.5,0.1)",
          "(3.5,0.2)",
          "(3.5,0.3)",
          "(3.5,0.4)",
          "(3.5,0.5)",
          "(3.5,0.6)",
          "(3.5,0.7)",
          "(3.5,0.8)",
          "(3.5,0.9)",
          "(3.6,0.0)",
          "(3.6,0.1)",
          "(3.6,0.2)",
          "(3.6,0.3)",
          "(3.6,0.4)",
          "(3.6,0.5)",
          "(3.6,0.6)",
          "(3.6,0.7)",
          "(3.6,0.8)",
          "(3.6,0.9)",
          "(3.7,0.0)",
          "(3.7,0.1)",
          "(3.7,0.2)",
          "(3.7,0.3)",
          "(3.7,0.4)",
          "(3.7,0.5)",
          "(3.7,0.6)",
          "(3.7,0.7)",
          "(3.7,0.8)",
          "(3.7,0.9)",
          "(3.8,0.0)",
          "(3.8,0.1)",
          "(3.8,0.2)",
          "(3.8,0.3)",
          "(3.8,0.4)",
          "(3.8,0.5)",
          "(3.8,0.6)",
          "(3.8,0.7)",
          "(3.8,0.8)",
          "(3.8,0.9)",
          "(3.9,0.0)",
          "(3.9,0.1)",
          "(3.9,0.2)",
          "(3.9,0.3)",
          "(3.9,0.4)",
          "(3.9,0.5)",
          "(3.9,0.6)",
          "(3.9,0.7)",
          "(3.9,0.8)",
          "(3.9,0.9)",
          "(4.0,0.0)",
          "(4.0,0.1)",
          "(4.0,0.2)",
          "(4.0,0.3)",
          "(4.0,0.4)",
          "(4.0,0.5)",
          "(4.0,0.6)",
          "(4.0,0.7)",
          "(4.0,0.8)",
          "(4.0,0.9)",
          "(4.1,0.0)",
          "(4.1,0.1)",
          "(4.1,0.2)",
          "(4.1,0.3)",
          "(4.1,0.4)",
          "(4.1,0.5)",
          "(4.1,0.6)",
          "(4.1,0.7)",
          "(4.1,0.8)",
          "(4.1,0.9)",
          "(4.2,0.0)",
          "(4.2,0.1)",
          "(4.2,0.2)",
          "(4.2,0.3)",
          "(4.2,0.4)",
          "(4.2,0.5)",
          "(4.2,0.6)",
          "(4.2,0.7)",
          "(4.2,0.8)",
          "(4.2,0.9)",
          "(4.3,0.0)",
          "(4.3,0.1)",
          "(4.3,0.2)",
          "(4.3,0.3)",
          "(4.3,0.4)",
          "(4.3,0.5)",
          "(4.3,0.6)",
          "(4.3,0.7)",
          "(4.3,0.8)",
          "(4.3,0.9)",
          "(4.4,0.0)",
          "(4.4,0.1)",
          "(4.4,0.2)",
          "(4.4,0.3)",
          "(4.4,0.4)",
          "(4.4,0.5)",
          "(4.4,0.6)",
          "(4.4,0.7)",
          "(4.4,0.8)",
          "(4.4,0.9)",
          "(4.5,0.0)",
          "(4.5,0.1)",
          "(4.5,0.2)",
          "(4.5,0.3)",
          "(4.5,0.4)",
          "(4.5,0.5)",
          "(4.5,0.6)",
          "(4.5,0.7)",
          "(4.5,0.8)",
          "(4.5,0.9)",
          "(4.6,0.0)",
          "(4.6,0.1)",
          "(4.6,0.2)",
          "(4.6,0.3)",
          "(4.6,0.4)",
          "(4.6,0.5)",
          "(4.6,0.6)",
          "(4.6,0.7)",
          "(4.6,0.8)",
          "(4.6,0.9)",
          "(4.7,0.0)",
          "(4.7,0.1)",
          "(4.7,0.2)",
          "(4.7,0.3)",
          "(4.7,0.4)",
          "(4.7,0.5)",
          "(4.7,0.6)",
          "(4.7,0.7)",
          "(4.7,0.8)",
          "(4.7,0.9)",
          "(4.8,0.0)",
          "(4.8,0.1)",
          "(4.8,0.2)",
          "(4.8,0.3)",
          "(4.8,0.4)",
          "(4.8,0.5)",
          "(4.8,0.6)",
          "(4.8,0.7)",
          "(4.8,0.8)",
          "(4.8,0.9)",
          "(4.9,0.0)",
          "(4.9,0.1)",
          "(4.9,0.2)",
          "(4.9,0.3)",
          "(4.9,0.4)",
          "(4.9,0.5)",
          "(4.9,0.6)",
          "(4.9,0.7)",
          "(4.9,0.8)",
          "(4.9,0.9)",
          "(5.0,0.0)",
          "(5.0,0.1)",
          "(5.0,0.2)",
          "(5.0,0.3)",
          "(5.0,0.4)",
          "(5.0,0.5)",
          "(5.0,0.6)",
          "(5.0,0.7)",
          "(5.0,0.8)",
          "(5.0,0.9)",
          "(5.1,0.0)",
          "(5.1,0.1)",
          "(5.1,0.2)",
          "(5.1,0.3)",
          "(5.1,0.4)",
          "(5.1,0.5)",
          "(5.1,0.6)",
          "(5.1,0.7)",
          "(5.1,0.8)",
          "(5.1,0.9)",
          "(5.2,0.0)",
          "(5.2,0.1)",
          "(5.2,0.2)",
          "(5.2,0.3)",
          "(5.2,0.4)",
          "(5.2,0.5)",
          "(5.2,0.6)",
          "(5.2,0.7)",
          "(5.2,0.8)",
          "(5.2,0.9)",
          "(5.3,0.0)",
          "(5.3,0.1)",
          "(5.3,0.2)",
          "(5.3,0.3)",
          "(5.3,0.4)",
          "(5.3,0.5)",
          "(5.3,0.6)",
          "(5.3,0.7)",
          "(5.3,0.8)",
          "(5.3,0.9)",
          "(5.4,0.0)",
          "(5.4,0.1)",
          "(5.4,0.2)",
          "(5.4,0.3)",
          "(5.4,0.4)",
          "(5.4,0.5)",
          "(5.4,0.6)",
          "(5.4,0.7)",
          "(5.4,0.8)",
          "(5.4,0.9)",
          "(5.5,0.0)",
          "(5.5,0.1)",
          "(5.5,0.2)",
          "(5.5,0.3)",
          "(5.5,0.4)",
          "(5.5,0.5)",
          "(5.5,0.6)",
          "(5.5,0.7)",
          "(5.5,0.8)",
          "(5.5,0.9)",
          "(5.6,0.0)",
          "(5.6,0.1)",
          "(5.6,0.2)",
          "(5.6,0.3)",
          "(5.6,0.4)",
          "(5.6,0.5)",
          "(5.6,0.6)",
          "(5.6,0.7)",
          "(5.6,0.8)",
          "(5.6,0.9)",
          "(5.7,0.0)",
          "(5.7,0.1)",
          "(5.7,0.2)",
          "(5.7,0.3)",
          "(5.7,0.4)",
          "(5.7,0.5)",
          "(5.7,0.6)",
          "(5.7,0.7)",
          "(5.7,0.8)",
          "(5.7,0.9)",
          "(5.8,0.0)",
          "(5.8,0.1)",
          "(5.8,0.2)",
          "(5.8,0.3)",
          "(5.8,0.4)",
          "(5.8,0.5)",
          "(5.8,0.6)",
          "(5.8,0.7)",
          "(5.8,0.8)",
          "(5.8,0.9)",
          "(5.9,0.0)",
          "(5.9,0.1)",
          "(5.9,0.2)",
          "(5.9,0.3)",
          "(5.9,0.4)",
          "(5.9,0.5)",
          "(5.9,0.6)",
          "(5.9,0.7)",
          "(5.9,0.8)",
          "(5.9,0.9)",
          "(6.0,0.0)",
          "(6.0,0.1)",
          "(6.0,0.2)",
          "(6.0,0.3)",
          "(6.0,0.4)",
          "(6.0,0.5)",
          "(6.0,0.6)",
          "(6.0,0.7)",
          "(6.0,0.8)",
          "(6.0,0.9)",
          "(6.1,0.0)",
          "(6.1,0.1)",
          "(6.1,0.2)",
          "(6.1,0.3)",
          "(6.1,0.4)",
          "(6.1,0.5)",
          "(6.1,0.6)",
          "(6.1,0.7)",
          "(6.1,0.8)",
          "(6.1,0.9)",
          "(6.2,0.0)",
          "(6.2,0.1)",
          "(6.2,0.2)",
          "(6.2,0.3)",
          "(6.2,0.4)",
          "(6.2,0.5)",
          "(6.2,0.6)",
          "(6.2,0.7)",
          "(6.2,0.8)",
          "(6.2,0.9)",
          "(6.3,0.0)",
          "(6.3,0.1)",
          "(6.3,0.2)",
          "(6.3,0.3)",
          "(6.3,0.4)",
          "(6.3,0.5)",
          "(6.3,0.6)",
          "(6.3,0.7)",
          "(6.3,0.8)",
          "(6.3,0.9)",
          "(6.4,0.0)",
          "(6.4,0.1)",
          "(6.4,0.2)",
          "(6.4,0.3)",
          "(6.4,0.4)",
          "(6.4,0.5)",
          "(6.4,0.6)",
          "(6.4,0.7)",
          "(6.4,0.8)",
          "(6.4,0.9)",
          "(6.5,0.0)",
          "(6.5,0.1)",
          "(6.5,0.2)",
          "(6.5,0.3)",
          "(6.5,0.4)",
          "(6.5,0.5)",
          "(6.5,0.6)",
          "(6.5,0.7)",
          "(6.5,0.8)",
          "(6.5,0.9)",
          "(6.6,0.0)",
          "(6.6,0.1)",
          "(6.6,0.2)",
          "(6.6,0.3)",
          "(6.6,0.4)",
          "(6.6,0.5)",
          "(6.6,0.6)",
          "(6.6,0.7)",
          "(6.6,0.8)",
          "(6.6,0.9)",
          "(6.7,0.0)",
          "(6.7,0.1)",
          "(6.7,0.2)",
          "(6.7,0.3)",
          "(6.7,0.4)",
          "(6.7,0.5)",
          "(6.7,0.6)",
          "(6.7,0.7)",
          "(6.7,0.8)",
          "(6.7,0.9)",
          "(6.8,0.0)",
          "(6.8,0.1)",
          "(6.8,0.2)",
          "(6.8,0.3)",
          "(6.8,0.4)",
          "(6.8,0.5)",
          "(6.8,0.6)",
          "(6.8,0.7)",
          "(6.8,0.8)",
          "(6.8,0.9)",
          "(6.9,0.0)",
          "(6.9,0.1)",
          "(6.9,0.2)",
          "(6.9,0.3)",
          "(6.9,0.4)",
          "(6.9,0.5)",
          "(6.9,0.6)",
          "(6.9,0.7)",
          "(6.9,0.8)",
          "(6.9,0.9)",
          "(7.0,0.0)",
          "(7.0,0.1)",
          "(7.0,0.2)",
          "(7.0,0.3)",
          "(7.0,0.4)",
          "(7.0,0.5)",
          "(7.0,0.6)",
          "(7.0,0.7)",
          "(7.0,0.8)",
          "(7.0,0.9)",
          "(7.1,0.0)",
          "(7.1,0.1)",
          "(7.1,0.2)",
          "(7.1,0.3)",
          "(7.1,0.4)",
          "(7.1,0.5)",
          "(7.1,0.6)",
          "(7.1,0.7)",
          "(7.1,0.8)",
          "(7.1,0.9)",
          "(7.2,0.0)",
          "(7.2,0.1)",
          "(7.2,0.2)",
          "(7.2,0.3)",
          "(7.2,0.4)",
          "(7.2,0.5)",
          "(7.2,0.6)",
          "(7.2,0.7)",
          "(7.2,0.8)",
          "(7.2,0.9)",
          "(7.3,0.0)",
          "(7.3,0.1)",
          "(7.3,0.2)",
          "(7.3,0.3)",
          "(7.3,0.4)",
          "(7.3,0.5)",
          "(7.3,0.6)",
          "(7.3,0.7)",
          "(7.3,0.8)",
          "(7.3,0.9)",
          "(7.4,0.0)",
          "(7.4,0.1)",
          "(7.4,0.2)",
          "(7.4,0.3)",
          "(7.4,0.4)",
          "(7.4,0.5)",
          "(7.4,0.6)",
          "(7.4,0.7)",
          "(7.4,0.8)",
          "(7.4,0.9)",
          "(7.5,0.0)",
          "(7.5,0.1)",
          "(7.5,0.2)",
          "(7.5,0.3)",
          "(7.5,0.4)",
          "(7.5,0.5)",
          "(7.5,0.6)",
          "(7.5,0.7)",
          "(7.5,0.8)",
          "(7.5,0.9)",
          "(7.6,0.0)",
          "(7.6,0.1)",
          "(7.6,0.2)",
          "(7.6,0.3)",
          "(7.6,0.4)",
          "(7.6,0.5)",
          "(7.6,0.6)",
          "(7.6,0.7)",
          "(7.6,0.8)",
          "(7.6,0.9)",
          "(7.7,0.0)",
          "(7.7,0.1)",
          "(7.7,0.2)",
          "(7.7,0.3)",
          "(7.7,0.4)",
          "(7.7,0.5)",
          "(7.7,0.6)",
          "(7.7,0.7)",
          "(7.7,0.8)",
          "(7.7,0.9)",
          "(7.8,0.0)",
          "(7.8,0.1)",
          "(7.8,0.2)",
          "(7.8,0.3)",
          "(7.8,0.4)",
          "(7.8,0.5)",
          "(7.8,0.6)",
          "(7.8,0.7)",
          "(7.8,0.8)",
          "(7.8,0.9)",
          "(7.9,0.0)",
          "(7.9,0.1)",
          "(7.9,0.2)",
          "(7.9,0.3)",
          "(7.9,0.4)",
          "(7.9,0.5)",
          "(7.9,0.6)",
          "(7.9,0.7)",
          "(7.9,0.8)",
          "(7.9,0.9)",
          "(8.0,0.0)",
          "(8.0,0.1)",
          "(8.0,0.2)",
          "(8.0,0.3)",
          "(8.0,0.4)",
          "(8.0,0.5)",
          "(8.0,0.6)",
          "(8.0,0.7)",
          "(8.0,0.8)",
          "(8.0,0.9)",
          "(8.1,0.0)",
          "(8.1,0.1)",
          "(8.1,0.2)",
          "(8.1,0.3)",
          "(8.1,0.4)",
          "(8.1,0.5)",
          "(8.1,0.6)",
          "(8.1,0.7)",
          "(8.1,0.8)",
          "(8.1,0.9)",
          "(8.2,0.0)",
          "(8.2,0.1)",
          "(8.2,0.2)",
          "(8.2,0.3)",
          "(8.2,0.4)",
          "(8.2,0.5)",
          "(8.2,0.6)",
          "(8.2,0.7)",
          "(8.2,0.8)",
          "(8.2,0.9)",
          "(8.3,0.0)",
          "(8.3,0.1)",
          "(8.3,0.2)",
          "(8.3,0.3)",
          "(8.3,0.4)",
          "(8.3,0.5)",
          "(8.3,0.6)",
          "(8.3,0.7)",
          "(8.3,0.8)",
          "(8.3,0.9)",
          "(8.4,0.0)",
          "(8.4,0.1)",
          "(8.4,0.2)",
          "(8.4,0.3)",
          "(8.4,0.4)",
          "(8.4,0.5)",
          "(8.4,0.6)",
          "(8.4,0.7)",
          "(8.4,0.8)",
          "(8.4,0.9)",
          "(8.5,0.0)",
          "(8.5,0.1)",
          "(8.5,0.2)",
          "(8.5,0.3)",
          "(8.5,0.4)",
          "(8.5,0.5)",
          "(8.5,0.6)",
          "(8.5,0.7)",
          "(8.5,0.8)",
          "(8.5,0.9)",
          "(8.6,0.0)",
          "(8.6,0.1)",
          "(8.6,0.2)",
          "(8.6,0.3)",
          "(8.6,0.4)",
          "(8.6,0.5)",
          "(8.6,0.6)",
          "(8.6,0.7)",
          "(8.6,0.8)",
          "(8.6,0.9)",
          "(8.7,0.0)",
          "(8.7,0.1)",
          "(8.7,0.2)",
          "(8.7,0.3)",
          "(8.7,0.4)",
          "(8.7,0.5)",
          "(8.7,0.6)",
          "(8.7,0.7)",
          "(8.7,0.8)",
          "(8.7,0.9)",
          "(8.8,0.0)",
          "(8.8,0.1)",
          "(8.8,0.2)",
          "(8.8,0.3)",
          "(8.8,0.4)",
          "(8.8,0.5)",
          "(8.8,0.6)",
          "(8.8,0.7)",
          "(8.8,0.8)",
          "(8.8,0.9)",
          "(8.9,0.0)",
          "(8.9,0.1)",
          "(8.9,0.2)",
          "(8.9,0.3)",
          "(8.9,0.4)",
          "(8.9,0.5)",
          "(8.9,0.6)",
          "(8.9,0.7)",
          "(8.9,0.8)",
          "(8.9,0.9)",
          "(9.0,0.0)",
          "(9.0,0.1)",
          "(9.0,0.2)",
          "(9.0,0.3)",
          "(9.0,0.4)",
          "(9.0,0.5)",
          "(9.0,0.6)",
          "(9.0,0.7)",
          "(9.0,0.8)",
          "(9.0,0.9)",
          "(9.1,0.0)",
          "(9.1,0.1)",
          "(9.1,0.2)",
          "(9.1,0.3)",
          "(9.1,0.4)",
          "(9.1,0.5)",
          "(9.1,0.6)",
          "(9.1,0.7)",
          "(9.1,0.8)",
          "(9.1,0.9)",
          "(9.2,0.0)",
          "(9.2,0.1)",
          "(9.2,0.2)",
          "(9.2,0.3)",
          "(9.2,0.4)",
          "(9.2,0.5)",
          "(9.2,0.6)",
          "(9.2,0.7)",
          "(9.2,0.8)",
          "(9.2,0.9)",
          "(9.3,0.0)",
          "(9.3,0.1)",
          "(9.3,0.2)",
          "(9.3,0.3)",
          "(9.3,0.4)",
          "(9.3,0.5)",
          "(9.3,0.6)",
          "(9.3,0.7)",
          "(9.3,0.8)",
          "(9.3,0.9)",
          "(9.4,0.0)",
          "(9.4,0.1)",
          "(9.4,0.2)",
          "(9.4,0.3)",
          "(9.4,0.4)",
          "(9.4,0.5)",
          "(9.4,0.6)",
          "(9.4,0.7)",
          "(9.4,0.8)",
          "(9.4,0.9)",
          "(9.5,0.0)",
          "(9.5,0.1)",
          "(9.5,0.2)",
          "(9.5,0.3)",
          "(9.5,0.4)",
          "(9.5,0.5)",
          "(9.5,0.6)",
          "(9.5,0.7)",
          "(9.5,0.8)",
          "(9.5,0.9)",
          "(9.6,0.0)",
          "(9.6,0.1)",
          "(9.6,0.2)",
          "(9.6,0.3)",
          "(9.6,0.4)",
          "(9.6,0.5)",
          "(9.6,0.6)",
          "(9.6,0.7)",
          "(9.6,0.8)",
          "(9.6,0.9)",
          "(9.7,0.0)",
          "(9.7,0.1)",
          "(9.7,0.2)",
          "(9.7,0.3)",
          "(9.7,0.4)",
          "(9.7,0.5)",
          "(9.7,0.6)",
          "(9.7,0.7)",
          "(9.7,0.8)",
          "(9.7,0.9)",
          "(9.8,0.0)",
          "(9.8,0.1)",
          "(9.8,0.2)",
          "(9.8,0.3)",
          "(9.8,0.4)",
          "(9.8,0.5)",
          "(9.8,0.6)",
          "(9.8,0.7)",
          "(9.8,0.8)",
          "(9.8,0.9)",
          "(9.9,0.0)",
          "(9.9,0.1)",
          "(9.9,0.2)",
          "(9.9,0.3)",
          "(9.9,0.4)",
          "(9.9,0.5)",
          "(9.9,0.6)",
          "(9.9,0.7)",
          "(9.9,0.8)",
          "(9.9,0.9)"
         ],
         "y": [
          0.29289590910141733,
          0.28673566103515646,
          0.2799391918735423,
          0.2723063707258394,
          0.26401996261741306,
          0.2549564741577474,
          0.24455339811080723,
          0.23267903223865122,
          0.21892606634616762,
          0.2063968386625814,
          0.32895610899178473,
          0.32258204761290765,
          0.3153202757471999,
          0.307229918702398,
          0.2978188333131305,
          0.28695730729046537,
          0.27671268689990086,
          0.26461386927543235,
          0.2508574766712583,
          0.23353648792333437,
          0.34234327883568794,
          0.3355457015521946,
          0.3278780093138807,
          0.31910476195075116,
          0.3094067485183694,
          0.29966706064120574,
          0.2881867172887829,
          0.27437948031897735,
          0.25762080614890703,
          0.23652034197854416,
          0.3466224831596823,
          0.33875603521801384,
          0.32986638508412525,
          0.3195530016004402,
          0.3092692026374486,
          0.29733838315267375,
          0.2835565518272535,
          0.26981122055141915,
          0.25500425615215216,
          0.23427902105822895,
          0.346716648734065,
          0.33723284780517987,
          0.3264218000471719,
          0.31434297876910755,
          0.3066752397375098,
          0.3014409941507938,
          0.2944610955228993,
          0.2848517752528723,
          0.2713949791034217,
          0.2513936607735131,
          0.3447524312784082,
          0.3333453697261683,
          0.32091607825182955,
          0.3176025352017648,
          0.3142208558868139,
          0.3098466927481525,
          0.30382886456053393,
          0.2954351391810256,
          0.2832856785751213,
          0.2645592810826197,
          0.341756407801572,
          0.3282005428072222,
          0.32428330021212404,
          0.32198702139370466,
          0.319214243002381,
          0.3154551324383144,
          0.3101683635871944,
          0.30273187175557503,
          0.29181396052439423,
          0.2776434715938957,
          0.3382627860744525,
          0.32988502180877266,
          0.3267996220134552,
          0.32488616461235365,
          0.32246435515377053,
          0.3190599385963839,
          0.31431199588964764,
          0.30755617403399693,
          0.29978675457387527,
          0.2882120287997718,
          0.3345638222316132,
          0.330961529104724,
          0.32835560845912565,
          0.3266869366782597,
          0.3244661079352515,
          0.32126920243685214,
          0.31682931738545417,
          0.3115559108264551,
          0.30571022262724873,
          0.29601907781682313,
          0.33082426835344314,
          0.3314764250989874,
          0.32921849799368724,
          0.3276900647967462,
          0.32551513704270096,
          0.3224290833531881,
          0.3181586282284115,
          0.3146206489244992,
          0.3096576590956711,
          0.30140031766741454,
          0.3271380351934931,
          0.33158585598309565,
          0.32957868940548124,
          0.3281108084570235,
          0.3259031918768156,
          0.32279791324923407,
          0.31935101007095845,
          0.3164030532556386,
          0.3119498672600335,
          0.3044602217659622,
          0.3235580782467914,
          0.33139711434034413,
          0.32959294468819467,
          0.3280773224170277,
          0.32577456831130586,
          0.32260749154099777,
          0.3199471370335079,
          0.3168660350030552,
          0.3124081317844279,
          0.3054414258439203,
          0.3201129804462904,
          0.33097668362298294,
          0.3293045960135347,
          0.32767897649910516,
          0.3252536112449536,
          0.32191723527095567,
          0.31956592871049094,
          0.31631319332663865,
          0.31166152643418127,
          0.30525449126406756,
          0.31681653675276567,
          0.3303825242723408,
          0.32878849028182994,
          0.3270203793371518,
          0.3243818181414225,
          0.32114819513150084,
          0.31860445044023117,
          0.3150329526183592,
          0.31014191486755377,
          0.30559970344209747,
          0.3136734787746756,
          0.32816094786827926,
          0.32809900230762273,
          0.3261525087180203,
          0.3231031502631901,
          0.3200742093935684,
          0.3171808700879282,
          0.3132676478740431,
          0.3085979023096487,
          0.30469635474246287,
          0.31068298431094477,
          0.325913321516219,
          0.3272618505675485,
          0.32495842912003436,
          0.3216455589405619,
          0.31869216003449274,
          0.3153999461893993,
          0.31112169101377307,
          0.3073312327454192,
          0.3047342006589979,
          0.3078408728170687,
          0.3237638057386548,
          0.3262446627181515,
          0.3236304256381,
          0.32003337719576874,
          0.3170597950738428,
          0.31347032942314634,
          0.3086531669622719,
          0.3054383995934127,
          0.3043011758666102,
          0.3051409992805277,
          0.321728398759659,
          0.32506232359583703,
          0.3222009606014086,
          0.3183584718980742,
          0.3152939004395206,
          0.311250709347652,
          0.306950955080973,
          0.30389422633218693,
          0.30378983528529063,
          0.3025761476121836,
          0.31975747790880377,
          0.3238102893628852,
          0.32070159594082304,
          0.3167873581958139,
          0.3134209374379551,
          0.30878638296030436,
          0.3049241668134782,
          0.30251808389551205,
          0.3024344105288957,
          0.30013860548490623,
          0.31783021058783667,
          0.32251273163329425,
          0.319149473859303,
          0.3151450905093707,
          0.3113898573511747,
          0.30616083662790033,
          0.302592647242145,
          0.3010868661095844,
          0.2995397371160008,
          0.2978205332300234,
          0.3159889455574569,
          0.32117984565849667,
          0.31753001694860883,
          0.31346510084865287,
          0.30923579517965294,
          0.3042511901784264,
          0.3006028581060229,
          0.2992766848812355,
          0.2956759769032974,
          0.2956141979614886,
          0.3142298198499327,
          0.3198099796531624,
          0.3158676804545077,
          0.31169596797531973,
          0.3069515326145426,
          0.30217359465893734,
          0.29875082708496764,
          0.2970885417941632,
          0.292051321661414,
          0.29351211871795413,
          0.31257059473664217,
          0.31841291934487176,
          0.3141897577900268,
          0.3098548914927679,
          0.3045664368362325,
          0.29996179522326505,
          0.29689443465263277,
          0.29397011989229405,
          0.2889647985912211,
          0.29150715253536236,
          0.31101633273093887,
          0.3170180109102749,
          0.3125275904368905,
          0.30796075572029347,
          0.302093459999427,
          0.29759780387354884,
          0.2948536035249632,
          0.2903924642120254,
          0.28564021916708415,
          0.289592541242329,
          0.3095278858248474,
          0.3156217532523618,
          0.310818071360884,
          0.3059974160971035,
          0.3000354149520907,
          0.29543597406467326,
          0.2925998495441922,
          0.2873093216666177,
          0.2822110888639928,
          0.287761932211404,
          0.308093697081197,
          0.31421961586046,
          0.30908460889794726,
          0.30398289139091444,
          0.29807072799627254,
          0.2934509324046151,
          0.2901522516981083,
          0.28459534169663825,
          0.2785420014661718,
          0.2860093819872322,
          0.3067139023588778,
          0.3127941491939178,
          0.30737899177970607,
          0.3019270736766524,
          0.2960385231276214,
          0.2914780253288274,
          0.2871152498123458,
          0.2818082758085047,
          0.27612394103157334,
          0.28432934884152217,
          0.3053796628329503,
          0.3113554081265459,
          0.3057420146569753,
          0.2998350689590293,
          0.29394153973920906,
          0.28943418293218226,
          0.2840478617230856,
          0.2788805276858521,
          0.2736462021349405,
          0.28271667837187575,
          0.3040944643702193,
          0.30991058360978396,
          0.3040794708552241,
          0.2977127375078196,
          0.2918046399731007,
          0.2872843910400192,
          0.2817803510522542,
          0.2758017157817998,
          0.2710090515575164,
          0.28116658494884184,
          0.3028480600595321,
          0.3084684433051841,
          0.30240221064933037,
          0.2955645910488038,
          0.28960771044879097,
          0.2850390015927875,
          0.2794475149610348,
          0.27310066974408986,
          0.2682298089447206,
          0.2796746309166043,
          0.3016421451791639,
          0.30701219383570816,
          0.30070907272202535,
          0.2934952424844376,
          0.2875623049928724,
          0.28281737552304365,
          0.27702479125755886,
          0.27097257238288575,
          0.2652861154610845,
          0.2782367048342475,
          0.3004675752693577,
          0.3055531256168732,
          0.2990140915216606,
          0.2917323774366566,
          0.2856377599328414,
          0.28046974235023314,
          0.27452833138549854,
          0.26875000305484675,
          0.2622128695379658,
          0.276848999615958,
          0.2993294549801913,
          0.3040886903043385,
          0.29729632770306413,
          0.2899369872428491,
          0.28373572007196757,
          0.27809051569493887,
          0.2719548504763816,
          0.26643362296397904,
          0.2589931548588706,
          0.27550799113208246,
          0.29822179920245817,
          0.30262677417650874,
          0.2955669187694328,
          0.2881234988332343,
          0.2818165452119449,
          0.27613900625175103,
          0.26930898354541866,
          0.26402383274170294,
          0.25613796352992974,
          0.27421041762693715,
          0.29713903176955986,
          0.3011643860602405,
          0.29383369672615156,
          0.2862874045020839,
          0.2800456824765084,
          0.2741432669871393,
          0.2674286245099408,
          0.2615363815670974,
          0.25365600898417195,
          0.27295326016648025,
          0.29608479025985507,
          0.2997071968356643,
          0.292090856349159,
          0.28443874123565693,
          0.278261459782271,
          0.27211073892649523,
          0.2655524289451141,
          0.2589454908241966,
          0.25101049672884745,
          0.27173372423089664,
          0.2950537140919557,
          0.2982639889456567,
          0.2903442511293763,
          0.28258033527108195,
          0.27644425316799925,
          0.2700390652402738,
          0.26362721812746226,
          0.25627971518945136,
          0.24823745101915573,
          0.27054922249969227,
          0.29404062064659886,
          0.29680698963765045,
          0.28859442910781885,
          0.28071224734955846,
          0.27459032217118173,
          0.26792937568372693,
          0.2616533292839143,
          0.25370343054082534,
          0.24531998780354722,
          0.2693973588318117,
          0.2930513558020491,
          0.2953551353794907,
          0.28684608777580467,
          0.27896663510737857,
          0.2727107649722281,
          0.26578156134874376,
          0.2596305565523015,
          0.25168804875295103,
          0.2427871433038309,
          0.2682759134132334,
          0.2920782763819981,
          0.2939054786508548,
          0.2850920696388013,
          0.27720499911509955,
          0.27091717885949973,
          0.26360770894098795,
          0.25755778379845484,
          0.2495675984974049,
          0.2406210007082448,
          0.26718282902559004,
          0.2911252292518705,
          0.29248958141376474,
          0.28333831799730913,
          0.2756384409839392,
          0.2692429065070928,
          0.26198422736678467,
          0.25544177337955654,
          0.24737007376804085,
          0.23925549192702236,
          0.26611619837784617,
          0.29018735957456615,
          0.2910797313994391,
          0.2816642593727401,
          0.27411869192319327,
          0.2675783470050572,
          0.2604063498990626,
          0.2532871269652666,
          0.24509536007107116,
          0.23954144376607617,
          0.26507425243689997,
          0.289264494457515,
          0.289674314029917,
          0.2801523675655529,
          0.2726360561663813,
          0.2659012607246961,
          0.25881225899350446,
          0.25107289506648334,
          0.24273921062988343,
          0.23978804410789062,
          0.2640553496905188,
          0.2883514849128836,
          0.2882786967735239,
          0.27876736496334653,
          0.27114285914129455,
          0.26420841482934354,
          0.2571806565740306,
          0.24922536599170944,
          0.2407373784154055,
          0.23997727214413025,
          0.2630579662759889,
          0.28745317922477615,
          0.2868894170997762,
          0.27738863276582315,
          0.26963498613235976,
          0.2624951462805673,
          0.2555268345865507,
          0.2475348979603506,
          0.23900248041376973,
          0.24009271789065886,
          0.2620806869093794,
          0.28656713819760127,
          0.28550756501174057,
          0.2760092775669127,
          0.2681180161695912,
          0.2607755512167264,
          0.2538479335086233,
          0.24579639263086783,
          0.2372233260413836,
          0.24014660268438587,
          0.26112219655310814,
          0.28571712929585963,
          0.28413013008649923,
          0.2746413890990974,
          0.2665922846727291,
          0.2590439465038126,
          0.2521487442610707,
          0.24401567378143157,
          0.2374150442585942,
          0.24012756769320137,
          0.26018127276278913,
          0.2848901576429072,
          0.2827732689631147,
          0.2732623128091912,
          0.26505478070600963,
          0.2573005894830439,
          0.25042840412965367,
          0.2421944706335359,
          0.23754203333345023,
          0.24021376384437995,
          0.25925677865784813,
          0.284073244003456,
          0.28146204754174686,
          0.27188096806543843,
          0.26353604515511536,
          0.2557495932484397,
          0.24868777535853623,
          0.24033658954967085,
          0.23765491872872155,
          0.24024619073178938,
          0.2583476564643672,
          0.2832669286487876,
          0.2801533821002904,
          0.2705045166654655,
          0.2621732988389821,
          0.2544402521360274,
          0.24692651649542763,
          0.23852302159968222,
          0.2377000111921171,
          0.24021215380562996,
          0.25745292158228555,
          0.28246981156766604,
          0.2788528172416958,
          0.2691341863224083,
          0.2608047599724897,
          0.2531177204238531,
          0.24522072966186015,
          0.23714772748746007,
          0.23769760524252156,
          0.24013146943999863,
          0.2565716571327042,
          0.28167778484601086,
          0.2775583677854948,
          0.26776340018714184,
          0.2595108806732881,
          0.2517857226396959,
          0.243851974956409,
          0.23573175704015634,
          0.23764403194033482,
          0.24007626519161868,
          0.25570300894480436,
          0.280897115160905,
          0.27626940891764706,
          0.2663816853537976,
          0.2581520922068315,
          0.2504519636807333,
          0.2424566482706013,
          0.23439691927858314,
          0.2375392614922677,
          0.24034874879873427,
          0.2548461809449697,
          0.2801238039832656,
          0.27498316595970207,
          0.26500334034335515,
          0.25678921373704733,
          0.2490982019599679,
          0.24103767716664806,
          0.23443111551213983,
          0.2375182826754282,
          0.24057081862118906,
          0.2540004309140314,
          0.27935652380193227,
          0.27370464312659204,
          0.26362610558020905,
          0.2554176533225424,
          0.24773317033000852,
          0.23959672904620014,
          0.2344172100967371,
          0.23748695145332757,
          0.24031963521280403,
          0.25316506658128285,
          0.2785962305380959,
          0.2724287720095464,
          0.26224986075888035,
          0.25404721864535684,
          0.24636033418249095,
          0.23813607235973674,
          0.234442919992138,
          0.23741190053917946,
          0.2397258835018143,
          0.25233944202679026,
          0.27783898647152383,
          0.27115159416136647,
          0.2608772674188802,
          0.2526732190309514,
          0.24497843573229777,
          0.23665164852051349,
          0.23438956161655358,
          0.2372889439701884,
          0.23910429059780186,
          0.25152295436590855,
          0.27709092249139816,
          0.2698820879479411,
          0.2595815185380185,
          0.2512962051922632,
          0.2435860801578002,
          0.23514900273074985,
          0.23428063769303617,
          0.23711121812642286,
          0.23845515006983115,
          0.2507150406922104,
          0.27634672446857383,
          0.26862841212868704,
          0.2583597358863471,
          0.24991601547620923,
          0.2421873467697457,
          0.2338517067754975,
          0.23413627559464664,
          0.23697174644452706,
          0.23777831307779268,
          0.24991517525711587,
          0.2756070652027483,
          0.2673656156297818,
          0.25713625320557365,
          0.2485318869429736,
          0.24078141651416238,
          0.23271344774626324,
          0.23395892833253928,
          0.23708370848480406,
          0.2370739291669965,
          0.24912286686641444,
          0.2748707930508215,
          0.2661108854144937,
          0.2559111441251971,
          0.24714639249152603,
          0.23935847405934316,
          0.23155910366542934,
          0.23375430105194453,
          0.2371656168067039,
          0.23634212484897463,
          0.24833765647569145,
          0.274136534389931,
          0.2648581980615375,
          0.2546812346412056,
          0.24598867756724968,
          0.23811541479146509,
          0.23037663621856674,
          0.23360957502179067,
          0.23707367260240722,
          0.23557742116899708,
          0.24755911496810568,
          0.27340868096172144,
          0.263765624257447,
          0.25345362950939615,
          0.24489408444983984,
          0.2369708370658392,
          0.22995898200782106,
          0.233467030645677,
          0.23640634005833672,
          0.23479109699054027,
          0.2467868410995977,
          0.27268407189855143,
          0.2626843754716899,
          0.25222502319696427,
          0.24379465366496045,
          0.23582334631462698,
          0.2298155756042545,
          0.23329638764984462,
          0.23571731801599272,
          0.2339774713908084,
          0.24602045959775948,
          0.2719615765722503,
          0.26160206075243364,
          0.25099566779454946,
          0.24268959253663502,
          0.2346517826119582,
          0.22964655651202825,
          0.23311191154508384,
          0.23500493144996085,
          0.23313654105039297,
          0.24525961940188296,
          0.27124273320486547,
          0.260524133124968,
          0.24983310315956164,
          0.24158979480656884,
          0.2334735112236942,
          0.2295022834057782,
          0.2328801611770176,
          0.2342635069310654,
          0.2322684519321252,
          0.24450399203279044,
          0.27052372154537263,
          0.2594452872824339,
          0.2487237403967847,
          0.24047681886714065,
          0.23228416466421625,
          0.22932455395311588,
          0.2326210779219924,
          0.2335047211313725,
          0.23137325396598896,
          0.24375327008201397,
          0.2698090031082441,
          0.25837027162816595,
          0.2476119533282478,
          0.23935996423233058,
          0.23108207548165147,
          0.2291199428213735,
          0.2323376780692718,
          0.2327228951847132,
          0.23045099076106373,
          0.24300716581078485,
          0.26909735646043786,
          0.2572971474673519,
          0.2465015773646173,
          0.23823894686311284,
          0.22987160208435875,
          0.22887643339380115,
          0.2322824216396421,
          0.23191808610751194,
          0.22950169662197115,
          0.24226540985013945,
          0.2682501402506884,
          0.2562233117683984,
          0.24539278002657716,
          0.2371127701986306,
          0.22864890081938877,
          0.22858454112149207,
          0.23220626138189232,
          0.2310903413443238,
          0.22852543339870365,
          0.24152774999418075,
          0.267246133306323,
          0.2551530696143166,
          0.24434457153489453,
          0.23598406267615266,
          0.22753238303250387,
          0.228270546874152,
          0.23210789829518097,
          0.23023963617701365,
          0.22752224299891383,
          0.24079395007921517,
          0.26623990242925466,
          0.25408250687003137,
          0.24329025267035967,
          0.2348519748540457,
          0.2265622104079917,
          0.22793301394476811,
          0.23163841637970273,
          0.22936614867179597,
          0.22649217409778039,
          0.24006378894210278,
          0.2652356065125817,
          0.2530159861206287,
          0.24223804802690435,
          0.23371660695827925,
          0.22558239110516204,
          0.2276732309496187,
          0.23088021257125335,
          0.22846990094716593,
          0.2254352721784397,
          0.239337059451652,
          0.2642037833702381,
          0.2519489550180636,
          0.24118370252785937,
          0.23257676962810658,
          0.2245892514159109,
          0.22740106894890205,
          0.2301029489460705,
          0.22755105112543508,
          0.2243515824130055,
          0.23861356760755392,
          0.26316306924945343,
          0.2508835179203307,
          0.24010861245352375,
          0.2314344599563052,
          0.22358533943163375,
          0.2270997309759111,
          0.2293016767493223,
          0.22660968394507183,
          0.2232412758494557,
          0.2378931317016632,
          0.2621252555121326,
          0.24981909867067378,
          0.23900541428921301,
          0.23028911192756402,
          0.2228773869426554,
          0.22679860711657998,
          0.22848681508973126,
          0.2256458736334698,
          0.22210460783799885,
          0.23717558153692925,
          0.26109027013943187,
          0.2487562993278893,
          0.23790172932417794,
          0.22914033901619185,
          0.22257762691762725,
          0.22646110334487077,
          0.22765311985879724,
          0.2246596937614626,
          0.22094130978795776,
          0.23646075769961977,
          0.26005705525168143,
          0.24769964572767877,
          0.23679746184077052,
          0.2280916796541693,
          0.22225271751634873,
          0.2261049374851403,
          0.22680076818939693,
          0.2236512124038704,
          0.21975150639340632,
          0.23574851088096233,
          0.25902750542308617,
          0.2466442735057487,
          0.23569196444452797,
          0.22711240310195954,
          0.2219388456978817,
          0.22573015562037127,
          0.2259299183042539,
          0.22262062952356243,
          0.21853411214980112,
          0.235038701244422,
          0.25800065332310973,
          0.24558997600016674,
          0.23458669655244632,
          0.226127307255798,
          0.22162845833861097,
          0.22534037062166862,
          0.22503982910027803,
          0.22156791351012595,
          0.21729001616704186,
          0.23433119783538114,
          0.2569736235384691,
          0.24446402343426496,
          0.2334810909123537,
          0.22513403718174232,
          0.22129446581559942,
          0.22506036728725845,
          0.22413214892891878,
          0.22049113076924795,
          0.2160204978340471,
          0.2336258780300164,
          0.25595214743461236,
          0.24332937506479055,
          0.23237493532668074,
          0.22414459957064967,
          0.2209408795592535,
          0.2248309453246207,
          0.22320620252851492,
          0.21939418742212796,
          0.21472454988674547,
          0.2329226270206584,
          0.2549332936107202,
          0.24219333328678286,
          0.231342204731542,
          0.2231404126431985,
          0.22057279539323218,
          0.2245892906931705,
          0.22226104443294364,
          0.21827532565213514,
          0.21339313769837523,
          0.232221337334869,
          0.2539160383440263,
          0.24106515981607246,
          0.23033912117236188,
          0.2221321590353157,
          0.22018776179498478,
          0.22431713382368776,
          0.22129867719877364,
          0.2171199303367233,
          0.21192715071741222,
          0.23152190838595738,
          0.2529064168026858,
          0.23992859105601588,
          0.22934898298031517,
          0.22111811944306645,
          0.21978932510285773,
          0.2237742468970932,
          0.22028275356139324,
          0.21584702011721185,
          0.21043394599615753,
          0.23082424605260343,
          0.2518947963916527,
          0.23879593867457896,
          0.22834204276675832,
          0.22009753750461505,
          0.21935140996902658,
          0.22286221660913658,
          0.2191791150691505,
          0.21455182358551173,
          0.20891435027773755,
          0.23012826228562128,
          0.2508827175197498,
          0.23766114005309044,
          0.22733339637893143,
          0.21899511280954106,
          0.21882020448477552,
          0.22190227693827758,
          0.21805766412062652,
          0.2132350004079584,
          0.20736840822955138,
          0.22943387473985805,
          0.24987599951978456,
          0.23653042937013585,
          0.22632297257329334,
          0.2178737779264929,
          0.21830154546557456,
          0.22093254120824202,
          0.21691862316376623,
          0.21189662352251423,
          0.2057979229766531,
          0.2287410064296117,
          0.24887161425853907,
          0.23540099704561876,
          0.2253104977487856,
          0.2167449370228377,
          0.2177906680291173,
          0.21994851252579195,
          0.21576207565606403,
          0.21053676912461286,
          0.2041995116868092,
          0.22804958540580572,
          0.24786952504155635,
          0.23427276178586726,
          0.2242962629572279,
          0.21578118632547125,
          0.21726872259939423,
          0.21895029192307988,
          0.2145881182590051,
          0.20915550998172072,
          0.2027192108967354,
          0.22735954445354228,
          0.2468689053763061,
          0.2331456136407709,
          0.22327906997786198,
          0.21481340741796928,
          0.2167422431854911,
          0.21793807753440325,
          0.21339684338009346,
          0.20775291855845243,
          0.20124192050716297,
          0.2266708208085602,
          0.24587135895379375,
          0.23201612575266622,
          0.22226106170288418,
          0.21383720217140603,
          0.21619270824302872,
          0.2169119752343499,
          0.2121883397956713,
          0.20632906701799575,
          0.19974004088946104,
          0.22598335589136465,
          0.2448760189844276,
          0.2308912022478183,
          0.2212413348619404,
          0.21285751429820582,
          0.21563205005654776,
          0.21587208168035166,
          0.21096269574051632,
          0.20488402587766957,
          0.19821347117884255,
          0.22529709505783901,
          0.24388017554539956,
          0.22977346119142103,
          0.2202119145747786,
          0.211870816831303,
          0.2150591755034237,
          0.2148184572193179,
          0.20972001867158085,
          0.2034178677373325,
          0.1966627374322525,
          0.22461198736518823,
          0.24288934174711063,
          0.2286658870648056,
          0.21918890797736376,
          0.21087969588050598,
          0.21447473408937226,
          0.2137511909979565,
          0.20846049961855795,
          0.20193066412438448,
          0.19508775961610525,
          0.22392798535225233,
          0.24190061435141635,
          0.22755940129194138,
          0.2181643015348554,
          0.20988913783917595,
          0.21387817186483543,
          0.2126704076696847,
          0.2071842707844332,
          0.20042248601100351,
          0.19348826582179426,
          0.22324504483320684,
          0.2409139668387773,
          0.2264635300264244,
          0.21713703804608406,
          0.20933644091660625,
          0.21327391486092595,
          0.2115761475401686,
          0.205891249612478,
          0.19892742129551913,
          0.1918644505168786,
          0.2225631247037847,
          0.23992863088170935,
          0.2253977052488984,
          0.21610883960294638,
          0.20875942141000545,
          0.2126535200454133,
          0.21046856387726767,
          0.20458152165909263,
          0.19752969838662368,
          0.19021634465177006,
          0.22188218675919438,
          0.23894609332211078,
          0.22437583793955537,
          0.21507932023812473,
          0.2081956113111417,
          0.21214720535766393,
          0.20934775369324557,
          0.20325516693955126,
          0.19611228188415636,
          0.18854401302375726
         ]
        },
        {
         "line": {
          "color": "rgba(255, 153, 51, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "std",
         "text": "",
         "type": "scatter",
         "x": [
          "(0.1,0.0)",
          "(0.1,0.1)",
          "(0.1,0.2)",
          "(0.1,0.3)",
          "(0.1,0.4)",
          "(0.1,0.5)",
          "(0.1,0.6)",
          "(0.1,0.7)",
          "(0.1,0.8)",
          "(0.1,0.9)",
          "(0.2,0.0)",
          "(0.2,0.1)",
          "(0.2,0.2)",
          "(0.2,0.3)",
          "(0.2,0.4)",
          "(0.2,0.5)",
          "(0.2,0.6)",
          "(0.2,0.7)",
          "(0.2,0.8)",
          "(0.2,0.9)",
          "(0.3,0.0)",
          "(0.3,0.1)",
          "(0.3,0.2)",
          "(0.3,0.3)",
          "(0.3,0.4)",
          "(0.3,0.5)",
          "(0.3,0.6)",
          "(0.3,0.7)",
          "(0.3,0.8)",
          "(0.3,0.9)",
          "(0.4,0.0)",
          "(0.4,0.1)",
          "(0.4,0.2)",
          "(0.4,0.3)",
          "(0.4,0.4)",
          "(0.4,0.5)",
          "(0.4,0.6)",
          "(0.4,0.7)",
          "(0.4,0.8)",
          "(0.4,0.9)",
          "(0.5,0.0)",
          "(0.5,0.1)",
          "(0.5,0.2)",
          "(0.5,0.3)",
          "(0.5,0.4)",
          "(0.5,0.5)",
          "(0.5,0.6)",
          "(0.5,0.7)",
          "(0.5,0.8)",
          "(0.5,0.9)",
          "(0.6,0.0)",
          "(0.6,0.1)",
          "(0.6,0.2)",
          "(0.6,0.3)",
          "(0.6,0.4)",
          "(0.6,0.5)",
          "(0.6,0.6)",
          "(0.6,0.7)",
          "(0.6,0.8)",
          "(0.6,0.9)",
          "(0.7,0.0)",
          "(0.7,0.1)",
          "(0.7,0.2)",
          "(0.7,0.3)",
          "(0.7,0.4)",
          "(0.7,0.5)",
          "(0.7,0.6)",
          "(0.7,0.7)",
          "(0.7,0.8)",
          "(0.7,0.9)",
          "(0.8,0.0)",
          "(0.8,0.1)",
          "(0.8,0.2)",
          "(0.8,0.3)",
          "(0.8,0.4)",
          "(0.8,0.5)",
          "(0.8,0.6)",
          "(0.8,0.7)",
          "(0.8,0.8)",
          "(0.8,0.9)",
          "(0.9,0.0)",
          "(0.9,0.1)",
          "(0.9,0.2)",
          "(0.9,0.3)",
          "(0.9,0.4)",
          "(0.9,0.5)",
          "(0.9,0.6)",
          "(0.9,0.7)",
          "(0.9,0.8)",
          "(0.9,0.9)",
          "(1.0,0.0)",
          "(1.0,0.1)",
          "(1.0,0.2)",
          "(1.0,0.3)",
          "(1.0,0.4)",
          "(1.0,0.5)",
          "(1.0,0.6)",
          "(1.0,0.7)",
          "(1.0,0.8)",
          "(1.0,0.9)",
          "(1.1,0.0)",
          "(1.1,0.1)",
          "(1.1,0.2)",
          "(1.1,0.3)",
          "(1.1,0.4)",
          "(1.1,0.5)",
          "(1.1,0.6)",
          "(1.1,0.7)",
          "(1.1,0.8)",
          "(1.1,0.9)",
          "(1.2,0.0)",
          "(1.2,0.1)",
          "(1.2,0.2)",
          "(1.2,0.3)",
          "(1.2,0.4)",
          "(1.2,0.5)",
          "(1.2,0.6)",
          "(1.2,0.7)",
          "(1.2,0.8)",
          "(1.2,0.9)",
          "(1.3,0.0)",
          "(1.3,0.1)",
          "(1.3,0.2)",
          "(1.3,0.3)",
          "(1.3,0.4)",
          "(1.3,0.5)",
          "(1.3,0.6)",
          "(1.3,0.7)",
          "(1.3,0.8)",
          "(1.3,0.9)",
          "(1.4,0.0)",
          "(1.4,0.1)",
          "(1.4,0.2)",
          "(1.4,0.3)",
          "(1.4,0.4)",
          "(1.4,0.5)",
          "(1.4,0.6)",
          "(1.4,0.7)",
          "(1.4,0.8)",
          "(1.4,0.9)",
          "(1.5,0.0)",
          "(1.5,0.1)",
          "(1.5,0.2)",
          "(1.5,0.3)",
          "(1.5,0.4)",
          "(1.5,0.5)",
          "(1.5,0.6)",
          "(1.5,0.7)",
          "(1.5,0.8)",
          "(1.5,0.9)",
          "(1.6,0.0)",
          "(1.6,0.1)",
          "(1.6,0.2)",
          "(1.6,0.3)",
          "(1.6,0.4)",
          "(1.6,0.5)",
          "(1.6,0.6)",
          "(1.6,0.7)",
          "(1.6,0.8)",
          "(1.6,0.9)",
          "(1.7,0.0)",
          "(1.7,0.1)",
          "(1.7,0.2)",
          "(1.7,0.3)",
          "(1.7,0.4)",
          "(1.7,0.5)",
          "(1.7,0.6)",
          "(1.7,0.7)",
          "(1.7,0.8)",
          "(1.7,0.9)",
          "(1.8,0.0)",
          "(1.8,0.1)",
          "(1.8,0.2)",
          "(1.8,0.3)",
          "(1.8,0.4)",
          "(1.8,0.5)",
          "(1.8,0.6)",
          "(1.8,0.7)",
          "(1.8,0.8)",
          "(1.8,0.9)",
          "(1.9,0.0)",
          "(1.9,0.1)",
          "(1.9,0.2)",
          "(1.9,0.3)",
          "(1.9,0.4)",
          "(1.9,0.5)",
          "(1.9,0.6)",
          "(1.9,0.7)",
          "(1.9,0.8)",
          "(1.9,0.9)",
          "(2.0,0.0)",
          "(2.0,0.1)",
          "(2.0,0.2)",
          "(2.0,0.3)",
          "(2.0,0.4)",
          "(2.0,0.5)",
          "(2.0,0.6)",
          "(2.0,0.7)",
          "(2.0,0.8)",
          "(2.0,0.9)",
          "(2.1,0.0)",
          "(2.1,0.1)",
          "(2.1,0.2)",
          "(2.1,0.3)",
          "(2.1,0.4)",
          "(2.1,0.5)",
          "(2.1,0.6)",
          "(2.1,0.7)",
          "(2.1,0.8)",
          "(2.1,0.9)",
          "(2.2,0.0)",
          "(2.2,0.1)",
          "(2.2,0.2)",
          "(2.2,0.3)",
          "(2.2,0.4)",
          "(2.2,0.5)",
          "(2.2,0.6)",
          "(2.2,0.7)",
          "(2.2,0.8)",
          "(2.2,0.9)",
          "(2.3,0.0)",
          "(2.3,0.1)",
          "(2.3,0.2)",
          "(2.3,0.3)",
          "(2.3,0.4)",
          "(2.3,0.5)",
          "(2.3,0.6)",
          "(2.3,0.7)",
          "(2.3,0.8)",
          "(2.3,0.9)",
          "(2.4,0.0)",
          "(2.4,0.1)",
          "(2.4,0.2)",
          "(2.4,0.3)",
          "(2.4,0.4)",
          "(2.4,0.5)",
          "(2.4,0.6)",
          "(2.4,0.7)",
          "(2.4,0.8)",
          "(2.4,0.9)",
          "(2.5,0.0)",
          "(2.5,0.1)",
          "(2.5,0.2)",
          "(2.5,0.3)",
          "(2.5,0.4)",
          "(2.5,0.5)",
          "(2.5,0.6)",
          "(2.5,0.7)",
          "(2.5,0.8)",
          "(2.5,0.9)",
          "(2.6,0.0)",
          "(2.6,0.1)",
          "(2.6,0.2)",
          "(2.6,0.3)",
          "(2.6,0.4)",
          "(2.6,0.5)",
          "(2.6,0.6)",
          "(2.6,0.7)",
          "(2.6,0.8)",
          "(2.6,0.9)",
          "(2.7,0.0)",
          "(2.7,0.1)",
          "(2.7,0.2)",
          "(2.7,0.3)",
          "(2.7,0.4)",
          "(2.7,0.5)",
          "(2.7,0.6)",
          "(2.7,0.7)",
          "(2.7,0.8)",
          "(2.7,0.9)",
          "(2.8,0.0)",
          "(2.8,0.1)",
          "(2.8,0.2)",
          "(2.8,0.3)",
          "(2.8,0.4)",
          "(2.8,0.5)",
          "(2.8,0.6)",
          "(2.8,0.7)",
          "(2.8,0.8)",
          "(2.8,0.9)",
          "(2.9,0.0)",
          "(2.9,0.1)",
          "(2.9,0.2)",
          "(2.9,0.3)",
          "(2.9,0.4)",
          "(2.9,0.5)",
          "(2.9,0.6)",
          "(2.9,0.7)",
          "(2.9,0.8)",
          "(2.9,0.9)",
          "(3.0,0.0)",
          "(3.0,0.1)",
          "(3.0,0.2)",
          "(3.0,0.3)",
          "(3.0,0.4)",
          "(3.0,0.5)",
          "(3.0,0.6)",
          "(3.0,0.7)",
          "(3.0,0.8)",
          "(3.0,0.9)",
          "(3.1,0.0)",
          "(3.1,0.1)",
          "(3.1,0.2)",
          "(3.1,0.3)",
          "(3.1,0.4)",
          "(3.1,0.5)",
          "(3.1,0.6)",
          "(3.1,0.7)",
          "(3.1,0.8)",
          "(3.1,0.9)",
          "(3.2,0.0)",
          "(3.2,0.1)",
          "(3.2,0.2)",
          "(3.2,0.3)",
          "(3.2,0.4)",
          "(3.2,0.5)",
          "(3.2,0.6)",
          "(3.2,0.7)",
          "(3.2,0.8)",
          "(3.2,0.9)",
          "(3.3,0.0)",
          "(3.3,0.1)",
          "(3.3,0.2)",
          "(3.3,0.3)",
          "(3.3,0.4)",
          "(3.3,0.5)",
          "(3.3,0.6)",
          "(3.3,0.7)",
          "(3.3,0.8)",
          "(3.3,0.9)",
          "(3.4,0.0)",
          "(3.4,0.1)",
          "(3.4,0.2)",
          "(3.4,0.3)",
          "(3.4,0.4)",
          "(3.4,0.5)",
          "(3.4,0.6)",
          "(3.4,0.7)",
          "(3.4,0.8)",
          "(3.4,0.9)",
          "(3.5,0.0)",
          "(3.5,0.1)",
          "(3.5,0.2)",
          "(3.5,0.3)",
          "(3.5,0.4)",
          "(3.5,0.5)",
          "(3.5,0.6)",
          "(3.5,0.7)",
          "(3.5,0.8)",
          "(3.5,0.9)",
          "(3.6,0.0)",
          "(3.6,0.1)",
          "(3.6,0.2)",
          "(3.6,0.3)",
          "(3.6,0.4)",
          "(3.6,0.5)",
          "(3.6,0.6)",
          "(3.6,0.7)",
          "(3.6,0.8)",
          "(3.6,0.9)",
          "(3.7,0.0)",
          "(3.7,0.1)",
          "(3.7,0.2)",
          "(3.7,0.3)",
          "(3.7,0.4)",
          "(3.7,0.5)",
          "(3.7,0.6)",
          "(3.7,0.7)",
          "(3.7,0.8)",
          "(3.7,0.9)",
          "(3.8,0.0)",
          "(3.8,0.1)",
          "(3.8,0.2)",
          "(3.8,0.3)",
          "(3.8,0.4)",
          "(3.8,0.5)",
          "(3.8,0.6)",
          "(3.8,0.7)",
          "(3.8,0.8)",
          "(3.8,0.9)",
          "(3.9,0.0)",
          "(3.9,0.1)",
          "(3.9,0.2)",
          "(3.9,0.3)",
          "(3.9,0.4)",
          "(3.9,0.5)",
          "(3.9,0.6)",
          "(3.9,0.7)",
          "(3.9,0.8)",
          "(3.9,0.9)",
          "(4.0,0.0)",
          "(4.0,0.1)",
          "(4.0,0.2)",
          "(4.0,0.3)",
          "(4.0,0.4)",
          "(4.0,0.5)",
          "(4.0,0.6)",
          "(4.0,0.7)",
          "(4.0,0.8)",
          "(4.0,0.9)",
          "(4.1,0.0)",
          "(4.1,0.1)",
          "(4.1,0.2)",
          "(4.1,0.3)",
          "(4.1,0.4)",
          "(4.1,0.5)",
          "(4.1,0.6)",
          "(4.1,0.7)",
          "(4.1,0.8)",
          "(4.1,0.9)",
          "(4.2,0.0)",
          "(4.2,0.1)",
          "(4.2,0.2)",
          "(4.2,0.3)",
          "(4.2,0.4)",
          "(4.2,0.5)",
          "(4.2,0.6)",
          "(4.2,0.7)",
          "(4.2,0.8)",
          "(4.2,0.9)",
          "(4.3,0.0)",
          "(4.3,0.1)",
          "(4.3,0.2)",
          "(4.3,0.3)",
          "(4.3,0.4)",
          "(4.3,0.5)",
          "(4.3,0.6)",
          "(4.3,0.7)",
          "(4.3,0.8)",
          "(4.3,0.9)",
          "(4.4,0.0)",
          "(4.4,0.1)",
          "(4.4,0.2)",
          "(4.4,0.3)",
          "(4.4,0.4)",
          "(4.4,0.5)",
          "(4.4,0.6)",
          "(4.4,0.7)",
          "(4.4,0.8)",
          "(4.4,0.9)",
          "(4.5,0.0)",
          "(4.5,0.1)",
          "(4.5,0.2)",
          "(4.5,0.3)",
          "(4.5,0.4)",
          "(4.5,0.5)",
          "(4.5,0.6)",
          "(4.5,0.7)",
          "(4.5,0.8)",
          "(4.5,0.9)",
          "(4.6,0.0)",
          "(4.6,0.1)",
          "(4.6,0.2)",
          "(4.6,0.3)",
          "(4.6,0.4)",
          "(4.6,0.5)",
          "(4.6,0.6)",
          "(4.6,0.7)",
          "(4.6,0.8)",
          "(4.6,0.9)",
          "(4.7,0.0)",
          "(4.7,0.1)",
          "(4.7,0.2)",
          "(4.7,0.3)",
          "(4.7,0.4)",
          "(4.7,0.5)",
          "(4.7,0.6)",
          "(4.7,0.7)",
          "(4.7,0.8)",
          "(4.7,0.9)",
          "(4.8,0.0)",
          "(4.8,0.1)",
          "(4.8,0.2)",
          "(4.8,0.3)",
          "(4.8,0.4)",
          "(4.8,0.5)",
          "(4.8,0.6)",
          "(4.8,0.7)",
          "(4.8,0.8)",
          "(4.8,0.9)",
          "(4.9,0.0)",
          "(4.9,0.1)",
          "(4.9,0.2)",
          "(4.9,0.3)",
          "(4.9,0.4)",
          "(4.9,0.5)",
          "(4.9,0.6)",
          "(4.9,0.7)",
          "(4.9,0.8)",
          "(4.9,0.9)",
          "(5.0,0.0)",
          "(5.0,0.1)",
          "(5.0,0.2)",
          "(5.0,0.3)",
          "(5.0,0.4)",
          "(5.0,0.5)",
          "(5.0,0.6)",
          "(5.0,0.7)",
          "(5.0,0.8)",
          "(5.0,0.9)",
          "(5.1,0.0)",
          "(5.1,0.1)",
          "(5.1,0.2)",
          "(5.1,0.3)",
          "(5.1,0.4)",
          "(5.1,0.5)",
          "(5.1,0.6)",
          "(5.1,0.7)",
          "(5.1,0.8)",
          "(5.1,0.9)",
          "(5.2,0.0)",
          "(5.2,0.1)",
          "(5.2,0.2)",
          "(5.2,0.3)",
          "(5.2,0.4)",
          "(5.2,0.5)",
          "(5.2,0.6)",
          "(5.2,0.7)",
          "(5.2,0.8)",
          "(5.2,0.9)",
          "(5.3,0.0)",
          "(5.3,0.1)",
          "(5.3,0.2)",
          "(5.3,0.3)",
          "(5.3,0.4)",
          "(5.3,0.5)",
          "(5.3,0.6)",
          "(5.3,0.7)",
          "(5.3,0.8)",
          "(5.3,0.9)",
          "(5.4,0.0)",
          "(5.4,0.1)",
          "(5.4,0.2)",
          "(5.4,0.3)",
          "(5.4,0.4)",
          "(5.4,0.5)",
          "(5.4,0.6)",
          "(5.4,0.7)",
          "(5.4,0.8)",
          "(5.4,0.9)",
          "(5.5,0.0)",
          "(5.5,0.1)",
          "(5.5,0.2)",
          "(5.5,0.3)",
          "(5.5,0.4)",
          "(5.5,0.5)",
          "(5.5,0.6)",
          "(5.5,0.7)",
          "(5.5,0.8)",
          "(5.5,0.9)",
          "(5.6,0.0)",
          "(5.6,0.1)",
          "(5.6,0.2)",
          "(5.6,0.3)",
          "(5.6,0.4)",
          "(5.6,0.5)",
          "(5.6,0.6)",
          "(5.6,0.7)",
          "(5.6,0.8)",
          "(5.6,0.9)",
          "(5.7,0.0)",
          "(5.7,0.1)",
          "(5.7,0.2)",
          "(5.7,0.3)",
          "(5.7,0.4)",
          "(5.7,0.5)",
          "(5.7,0.6)",
          "(5.7,0.7)",
          "(5.7,0.8)",
          "(5.7,0.9)",
          "(5.8,0.0)",
          "(5.8,0.1)",
          "(5.8,0.2)",
          "(5.8,0.3)",
          "(5.8,0.4)",
          "(5.8,0.5)",
          "(5.8,0.6)",
          "(5.8,0.7)",
          "(5.8,0.8)",
          "(5.8,0.9)",
          "(5.9,0.0)",
          "(5.9,0.1)",
          "(5.9,0.2)",
          "(5.9,0.3)",
          "(5.9,0.4)",
          "(5.9,0.5)",
          "(5.9,0.6)",
          "(5.9,0.7)",
          "(5.9,0.8)",
          "(5.9,0.9)",
          "(6.0,0.0)",
          "(6.0,0.1)",
          "(6.0,0.2)",
          "(6.0,0.3)",
          "(6.0,0.4)",
          "(6.0,0.5)",
          "(6.0,0.6)",
          "(6.0,0.7)",
          "(6.0,0.8)",
          "(6.0,0.9)",
          "(6.1,0.0)",
          "(6.1,0.1)",
          "(6.1,0.2)",
          "(6.1,0.3)",
          "(6.1,0.4)",
          "(6.1,0.5)",
          "(6.1,0.6)",
          "(6.1,0.7)",
          "(6.1,0.8)",
          "(6.1,0.9)",
          "(6.2,0.0)",
          "(6.2,0.1)",
          "(6.2,0.2)",
          "(6.2,0.3)",
          "(6.2,0.4)",
          "(6.2,0.5)",
          "(6.2,0.6)",
          "(6.2,0.7)",
          "(6.2,0.8)",
          "(6.2,0.9)",
          "(6.3,0.0)",
          "(6.3,0.1)",
          "(6.3,0.2)",
          "(6.3,0.3)",
          "(6.3,0.4)",
          "(6.3,0.5)",
          "(6.3,0.6)",
          "(6.3,0.7)",
          "(6.3,0.8)",
          "(6.3,0.9)",
          "(6.4,0.0)",
          "(6.4,0.1)",
          "(6.4,0.2)",
          "(6.4,0.3)",
          "(6.4,0.4)",
          "(6.4,0.5)",
          "(6.4,0.6)",
          "(6.4,0.7)",
          "(6.4,0.8)",
          "(6.4,0.9)",
          "(6.5,0.0)",
          "(6.5,0.1)",
          "(6.5,0.2)",
          "(6.5,0.3)",
          "(6.5,0.4)",
          "(6.5,0.5)",
          "(6.5,0.6)",
          "(6.5,0.7)",
          "(6.5,0.8)",
          "(6.5,0.9)",
          "(6.6,0.0)",
          "(6.6,0.1)",
          "(6.6,0.2)",
          "(6.6,0.3)",
          "(6.6,0.4)",
          "(6.6,0.5)",
          "(6.6,0.6)",
          "(6.6,0.7)",
          "(6.6,0.8)",
          "(6.6,0.9)",
          "(6.7,0.0)",
          "(6.7,0.1)",
          "(6.7,0.2)",
          "(6.7,0.3)",
          "(6.7,0.4)",
          "(6.7,0.5)",
          "(6.7,0.6)",
          "(6.7,0.7)",
          "(6.7,0.8)",
          "(6.7,0.9)",
          "(6.8,0.0)",
          "(6.8,0.1)",
          "(6.8,0.2)",
          "(6.8,0.3)",
          "(6.8,0.4)",
          "(6.8,0.5)",
          "(6.8,0.6)",
          "(6.8,0.7)",
          "(6.8,0.8)",
          "(6.8,0.9)",
          "(6.9,0.0)",
          "(6.9,0.1)",
          "(6.9,0.2)",
          "(6.9,0.3)",
          "(6.9,0.4)",
          "(6.9,0.5)",
          "(6.9,0.6)",
          "(6.9,0.7)",
          "(6.9,0.8)",
          "(6.9,0.9)",
          "(7.0,0.0)",
          "(7.0,0.1)",
          "(7.0,0.2)",
          "(7.0,0.3)",
          "(7.0,0.4)",
          "(7.0,0.5)",
          "(7.0,0.6)",
          "(7.0,0.7)",
          "(7.0,0.8)",
          "(7.0,0.9)",
          "(7.1,0.0)",
          "(7.1,0.1)",
          "(7.1,0.2)",
          "(7.1,0.3)",
          "(7.1,0.4)",
          "(7.1,0.5)",
          "(7.1,0.6)",
          "(7.1,0.7)",
          "(7.1,0.8)",
          "(7.1,0.9)",
          "(7.2,0.0)",
          "(7.2,0.1)",
          "(7.2,0.2)",
          "(7.2,0.3)",
          "(7.2,0.4)",
          "(7.2,0.5)",
          "(7.2,0.6)",
          "(7.2,0.7)",
          "(7.2,0.8)",
          "(7.2,0.9)",
          "(7.3,0.0)",
          "(7.3,0.1)",
          "(7.3,0.2)",
          "(7.3,0.3)",
          "(7.3,0.4)",
          "(7.3,0.5)",
          "(7.3,0.6)",
          "(7.3,0.7)",
          "(7.3,0.8)",
          "(7.3,0.9)",
          "(7.4,0.0)",
          "(7.4,0.1)",
          "(7.4,0.2)",
          "(7.4,0.3)",
          "(7.4,0.4)",
          "(7.4,0.5)",
          "(7.4,0.6)",
          "(7.4,0.7)",
          "(7.4,0.8)",
          "(7.4,0.9)",
          "(7.5,0.0)",
          "(7.5,0.1)",
          "(7.5,0.2)",
          "(7.5,0.3)",
          "(7.5,0.4)",
          "(7.5,0.5)",
          "(7.5,0.6)",
          "(7.5,0.7)",
          "(7.5,0.8)",
          "(7.5,0.9)",
          "(7.6,0.0)",
          "(7.6,0.1)",
          "(7.6,0.2)",
          "(7.6,0.3)",
          "(7.6,0.4)",
          "(7.6,0.5)",
          "(7.6,0.6)",
          "(7.6,0.7)",
          "(7.6,0.8)",
          "(7.6,0.9)",
          "(7.7,0.0)",
          "(7.7,0.1)",
          "(7.7,0.2)",
          "(7.7,0.3)",
          "(7.7,0.4)",
          "(7.7,0.5)",
          "(7.7,0.6)",
          "(7.7,0.7)",
          "(7.7,0.8)",
          "(7.7,0.9)",
          "(7.8,0.0)",
          "(7.8,0.1)",
          "(7.8,0.2)",
          "(7.8,0.3)",
          "(7.8,0.4)",
          "(7.8,0.5)",
          "(7.8,0.6)",
          "(7.8,0.7)",
          "(7.8,0.8)",
          "(7.8,0.9)",
          "(7.9,0.0)",
          "(7.9,0.1)",
          "(7.9,0.2)",
          "(7.9,0.3)",
          "(7.9,0.4)",
          "(7.9,0.5)",
          "(7.9,0.6)",
          "(7.9,0.7)",
          "(7.9,0.8)",
          "(7.9,0.9)",
          "(8.0,0.0)",
          "(8.0,0.1)",
          "(8.0,0.2)",
          "(8.0,0.3)",
          "(8.0,0.4)",
          "(8.0,0.5)",
          "(8.0,0.6)",
          "(8.0,0.7)",
          "(8.0,0.8)",
          "(8.0,0.9)",
          "(8.1,0.0)",
          "(8.1,0.1)",
          "(8.1,0.2)",
          "(8.1,0.3)",
          "(8.1,0.4)",
          "(8.1,0.5)",
          "(8.1,0.6)",
          "(8.1,0.7)",
          "(8.1,0.8)",
          "(8.1,0.9)",
          "(8.2,0.0)",
          "(8.2,0.1)",
          "(8.2,0.2)",
          "(8.2,0.3)",
          "(8.2,0.4)",
          "(8.2,0.5)",
          "(8.2,0.6)",
          "(8.2,0.7)",
          "(8.2,0.8)",
          "(8.2,0.9)",
          "(8.3,0.0)",
          "(8.3,0.1)",
          "(8.3,0.2)",
          "(8.3,0.3)",
          "(8.3,0.4)",
          "(8.3,0.5)",
          "(8.3,0.6)",
          "(8.3,0.7)",
          "(8.3,0.8)",
          "(8.3,0.9)",
          "(8.4,0.0)",
          "(8.4,0.1)",
          "(8.4,0.2)",
          "(8.4,0.3)",
          "(8.4,0.4)",
          "(8.4,0.5)",
          "(8.4,0.6)",
          "(8.4,0.7)",
          "(8.4,0.8)",
          "(8.4,0.9)",
          "(8.5,0.0)",
          "(8.5,0.1)",
          "(8.5,0.2)",
          "(8.5,0.3)",
          "(8.5,0.4)",
          "(8.5,0.5)",
          "(8.5,0.6)",
          "(8.5,0.7)",
          "(8.5,0.8)",
          "(8.5,0.9)",
          "(8.6,0.0)",
          "(8.6,0.1)",
          "(8.6,0.2)",
          "(8.6,0.3)",
          "(8.6,0.4)",
          "(8.6,0.5)",
          "(8.6,0.6)",
          "(8.6,0.7)",
          "(8.6,0.8)",
          "(8.6,0.9)",
          "(8.7,0.0)",
          "(8.7,0.1)",
          "(8.7,0.2)",
          "(8.7,0.3)",
          "(8.7,0.4)",
          "(8.7,0.5)",
          "(8.7,0.6)",
          "(8.7,0.7)",
          "(8.7,0.8)",
          "(8.7,0.9)",
          "(8.8,0.0)",
          "(8.8,0.1)",
          "(8.8,0.2)",
          "(8.8,0.3)",
          "(8.8,0.4)",
          "(8.8,0.5)",
          "(8.8,0.6)",
          "(8.8,0.7)",
          "(8.8,0.8)",
          "(8.8,0.9)",
          "(8.9,0.0)",
          "(8.9,0.1)",
          "(8.9,0.2)",
          "(8.9,0.3)",
          "(8.9,0.4)",
          "(8.9,0.5)",
          "(8.9,0.6)",
          "(8.9,0.7)",
          "(8.9,0.8)",
          "(8.9,0.9)",
          "(9.0,0.0)",
          "(9.0,0.1)",
          "(9.0,0.2)",
          "(9.0,0.3)",
          "(9.0,0.4)",
          "(9.0,0.5)",
          "(9.0,0.6)",
          "(9.0,0.7)",
          "(9.0,0.8)",
          "(9.0,0.9)",
          "(9.1,0.0)",
          "(9.1,0.1)",
          "(9.1,0.2)",
          "(9.1,0.3)",
          "(9.1,0.4)",
          "(9.1,0.5)",
          "(9.1,0.6)",
          "(9.1,0.7)",
          "(9.1,0.8)",
          "(9.1,0.9)",
          "(9.2,0.0)",
          "(9.2,0.1)",
          "(9.2,0.2)",
          "(9.2,0.3)",
          "(9.2,0.4)",
          "(9.2,0.5)",
          "(9.2,0.6)",
          "(9.2,0.7)",
          "(9.2,0.8)",
          "(9.2,0.9)",
          "(9.3,0.0)",
          "(9.3,0.1)",
          "(9.3,0.2)",
          "(9.3,0.3)",
          "(9.3,0.4)",
          "(9.3,0.5)",
          "(9.3,0.6)",
          "(9.3,0.7)",
          "(9.3,0.8)",
          "(9.3,0.9)",
          "(9.4,0.0)",
          "(9.4,0.1)",
          "(9.4,0.2)",
          "(9.4,0.3)",
          "(9.4,0.4)",
          "(9.4,0.5)",
          "(9.4,0.6)",
          "(9.4,0.7)",
          "(9.4,0.8)",
          "(9.4,0.9)",
          "(9.5,0.0)",
          "(9.5,0.1)",
          "(9.5,0.2)",
          "(9.5,0.3)",
          "(9.5,0.4)",
          "(9.5,0.5)",
          "(9.5,0.6)",
          "(9.5,0.7)",
          "(9.5,0.8)",
          "(9.5,0.9)",
          "(9.6,0.0)",
          "(9.6,0.1)",
          "(9.6,0.2)",
          "(9.6,0.3)",
          "(9.6,0.4)",
          "(9.6,0.5)",
          "(9.6,0.6)",
          "(9.6,0.7)",
          "(9.6,0.8)",
          "(9.6,0.9)",
          "(9.7,0.0)",
          "(9.7,0.1)",
          "(9.7,0.2)",
          "(9.7,0.3)",
          "(9.7,0.4)",
          "(9.7,0.5)",
          "(9.7,0.6)",
          "(9.7,0.7)",
          "(9.7,0.8)",
          "(9.7,0.9)",
          "(9.8,0.0)",
          "(9.8,0.1)",
          "(9.8,0.2)",
          "(9.8,0.3)",
          "(9.8,0.4)",
          "(9.8,0.5)",
          "(9.8,0.6)",
          "(9.8,0.7)",
          "(9.8,0.8)",
          "(9.8,0.9)",
          "(9.9,0.0)",
          "(9.9,0.1)",
          "(9.9,0.2)",
          "(9.9,0.3)",
          "(9.9,0.4)",
          "(9.9,0.5)",
          "(9.9,0.6)",
          "(9.9,0.7)",
          "(9.9,0.8)",
          "(9.9,0.9)"
         ],
         "y": [
          0.4728801335387184,
          0.4817013661854827,
          0.49130631122243845,
          0.501960035718716,
          0.5134629445044958,
          0.5266456402171696,
          0.541715129587993,
          0.5587254576359675,
          0.5780724374864337,
          0.5937760142653865,
          0.4074131514110777,
          0.41698345925795494,
          0.4278142386198395,
          0.4406446445556819,
          0.45556509916103416,
          0.47251120836132093,
          0.48789593023103794,
          0.505766996763168,
          0.5255089015038684,
          0.5499682970645737,
          0.3759114894846676,
          0.38610406164214794,
          0.3980989654990603,
          0.4121933780588476,
          0.4275740673360826,
          0.44274442143852233,
          0.46035720595844576,
          0.48138027840632713,
          0.5065972781060857,
          0.5372115999300027,
          0.35931880860761956,
          0.3710302632826347,
          0.3850480243406514,
          0.4013994811703531,
          0.4174177292249497,
          0.43586189992260366,
          0.45749805414712813,
          0.47818103038765586,
          0.49942272745460675,
          0.5287132942033976,
          0.35007221054600424,
          0.36409145488982203,
          0.38099406737446134,
          0.3997874325588472,
          0.41064084354043656,
          0.41740195394443586,
          0.42659192715539335,
          0.43948037309675414,
          0.45759825915297214,
          0.48440266347101557,
          0.3447106686354988,
          0.3615694501044995,
          0.38058555445333075,
          0.38354914406520546,
          0.386531763166403,
          0.3909304896739723,
          0.39751239245055026,
          0.40720794036417757,
          0.421755319511681,
          0.4446166486183859,
          0.341486008430782,
          0.36150022927515907,
          0.36513104448558925,
          0.36552024647341247,
          0.3667603856557223,
          0.36907354481210936,
          0.37318169187327555,
          0.3797616682095927,
          0.39035133998508187,
          0.41060093276907333,
          0.3394518054293826,
          0.3499601288716105,
          0.3513899296766789,
          0.3504369876506036,
          0.35007856002464444,
          0.35061316617503213,
          0.35237249398104503,
          0.35600292235581243,
          0.3642989772970664,
          0.38008954087962477,
          0.33807023825551585,
          0.3397407989481586,
          0.339550091807832,
          0.3374275975767637,
          0.33567676006033803,
          0.3345807965280686,
          0.33422437780098024,
          0.3357941448687687,
          0.34127005384335884,
          0.3524961530341147,
          0.33702560865388637,
          0.33074044363551247,
          0.32913929989465573,
          0.32599320146772476,
          0.32306293721631,
          0.3204213652089897,
          0.3181540418854769,
          0.3182516444719985,
          0.3206681329107283,
          0.32746926824394473,
          0.33612908790239715,
          0.3226695438438544,
          0.31984922728110016,
          0.3157513484665927,
          0.3117400575849003,
          0.307715064272473,
          0.30427162662550755,
          0.30250016187343126,
          0.30196192240147585,
          0.30455967247381516,
          0.3352671059617416,
          0.31532507285367234,
          0.3114377545643648,
          0.3064749956348863,
          0.3014637954663352,
          0.2961875708577287,
          0.2918190667633584,
          0.2881261795010447,
          0.28499589536708037,
          0.2835559787606079,
          0.33437202767876567,
          0.3085765050073532,
          0.30373235880074434,
          0.2980017774929314,
          0.2920087686411077,
          0.28561865178063994,
          0.280304626939876,
          0.2749523967341846,
          0.26961880534305893,
          0.26468960779647355,
          0.333404838439939,
          0.3023135134683635,
          0.29659850504583,
          0.2901472828837048,
          0.2832513548194423,
          0.2761327349574763,
          0.2696699130459248,
          0.2628213962999806,
          0.25548221931131965,
          0.2477182938923026,
          0.33234459680722117,
          0.29901063987127885,
          0.2899306095955534,
          0.28280854002400185,
          0.2750301707198551,
          0.2672967535770442,
          0.2597727307348578,
          0.2516099113432252,
          0.24259933430208044,
          0.23217552000485694,
          0.33118184556594993,
          0.2959133584754912,
          0.28367961657455054,
          0.275843106637014,
          0.2673147011418287,
          0.2590144677026055,
          0.25051526611091074,
          0.24118030571898616,
          0.2307747257388411,
          0.219322976254482,
          0.3299144123809765,
          0.2928031541791328,
          0.2777548556932979,
          0.26927650478686266,
          0.260005762071577,
          0.25119808402288274,
          0.2418249876549058,
          0.2314491711447608,
          0.2197517457942704,
          0.20790380997723384,
          0.32854469183145,
          0.28963946691258297,
          0.27213531752693587,
          0.263043993406068,
          0.2531427583035185,
          0.24378749536621286,
          0.2336238491043161,
          0.22241340390426256,
          0.2100334278482492,
          0.197461336168777,
          0.3270778665544832,
          0.2863943334697499,
          0.2667901669775465,
          0.25711344643300543,
          0.24677470088786474,
          0.23676951039218486,
          0.22584721627495877,
          0.21383514376127816,
          0.20133131565105242,
          0.18782534164448678,
          0.3255207349786583,
          0.28312602502425094,
          0.2616789690805543,
          0.25142964944216706,
          0.24067438116909498,
          0.23006870953519953,
          0.21844146887587965,
          0.20569128312972149,
          0.19312265012904564,
          0.1801637768741747,
          0.32388093698288956,
          0.2798561100846484,
          0.25677052463188726,
          0.2460004047877978,
          0.23486422385910394,
          0.22363422537860195,
          0.21146694880085518,
          0.1983181915902571,
          0.18531762728038928,
          0.1735592852848735,
          0.322166443890135,
          0.27657889350563086,
          0.2520701643398048,
          0.2407848241225855,
          0.2292809952979453,
          0.2174874288731058,
          0.20477238311229332,
          0.19148834513849625,
          0.17786188193318694,
          0.16756021622428577,
          0.3203852257759628,
          0.2733086417655281,
          0.2475472707144828,
          0.2357697316202463,
          0.2239058055396223,
          0.21158508140600815,
          0.19831379687547665,
          0.18493892929853256,
          0.1716226880490956,
          0.1616541949778803,
          0.31854503855761096,
          0.27005962003477463,
          0.24319352150704912,
          0.23091742993348371,
          0.2186980756246856,
          0.20591043027591666,
          0.1921187163753747,
          0.1786226820139732,
          0.16587140388658542,
          0.15583065318685943,
          0.3166532923366081,
          0.2668134336940405,
          0.23899429039176842,
          0.22625170398478864,
          0.21369834895583512,
          0.2004763011886492,
          0.18634465966589422,
          0.17252374796523404,
          0.16066468838384082,
          0.15010238091129083,
          0.3147169749198814,
          0.26357462187392966,
          0.23491978242233247,
          0.22173799898579416,
          0.2088673450681807,
          0.19523217252312522,
          0.18094334661144876,
          0.16663029131078022,
          0.15553342733381953,
          0.144509240615076,
          0.3127426127161931,
          0.2603481073985881,
          0.23099034003542834,
          0.21741113778124954,
          0.2041961811545883,
          0.19015572360414124,
          0.1757082015974619,
          0.16157986139484953,
          0.1504983916085242,
          0.13971282459592657,
          0.3107362567683288,
          0.25714052167339957,
          0.2271819849841278,
          0.21329102743226946,
          0.19967626301999,
          0.1852395597422014,
          0.1706285275028778,
          0.1567770232721188,
          0.14556931189357902,
          0.1350651547468092,
          0.30870348546519194,
          0.2539485612421555,
          0.22348901885268607,
          0.20929444440805817,
          0.1953012330356211,
          0.18045535748390318,
          0.16569966028303443,
          0.1523586945746133,
          0.14080285246819113,
          0.13053266019655,
          0.3066494180742772,
          0.2507766799156004,
          0.2198839041088668,
          0.20541651088010432,
          0.19106479582363323,
          0.17584175029416121,
          0.16091797979445752,
          0.14803761289915987,
          0.13639500310367114,
          0.12611698320030446,
          0.304578735031577,
          0.24762889019099374,
          0.21640298426463145,
          0.20165099737186798,
          0.18696449047894234,
          0.17147923268051782,
          0.15626831893672863,
          0.14382587597523153,
          0.13236541531782764,
          0.12186199582018319,
          0.30249570217654037,
          0.24450962995711603,
          0.21301963371482646,
          0.19796952371047621,
          0.18299431737719468,
          0.16734216223439782,
          0.15200090646941455,
          0.13973405823912827,
          0.12844439445348133,
          0.11773252204724025,
          0.30040419699609733,
          0.24141582993509786,
          0.2097282909584795,
          0.1944164033507943,
          0.17913507193779063,
          0.1633180463632478,
          0.14799829570595105,
          0.13577289441995383,
          0.12463860544465982,
          0.11378432758835837,
          0.298307735556735,
          0.23835199031754153,
          0.20652624682723925,
          0.19096266148437674,
          0.17538395064158166,
          0.15940429459886418,
          0.14438411870124906,
          0.13195287524830573,
          0.12095590849680375,
          0.10988351291082861,
          0.29620949923717355,
          0.23531869676270695,
          0.20340871272733288,
          0.1876051982889947,
          0.17173747886634586,
          0.15558184958911775,
          0.14086434391989416,
          0.12851699367402966,
          0.11739319850316712,
          0.10605083767743316,
          0.2941123606799728,
          0.23231918463664883,
          0.200373230586777,
          0.18433955904707264,
          0.16819288538548513,
          0.1518592190496849,
          0.1374424942364811,
          0.1252206291166811,
          0.1139886101561503,
          0.10243228814525314,
          0.2920189085951862,
          0.22935357521997876,
          0.19739161791277943,
          0.18116391294787368,
          0.16472748197031334,
          0.14823690480933516,
          0.13412348460692328,
          0.12202149453003376,
          0.11072390591025516,
          0.09908220299538385,
          0.2899314712002887,
          0.22642571881156207,
          0.1945101755439721,
          0.17807509453161205,
          0.16137963741190892,
          0.14471397859356033,
          0.13091138155183604,
          0.11892618250371062,
          0.107577410763943,
          0.09602214586769685,
          0.2878521381855515,
          0.22353181536892394,
          0.19170148106526713,
          0.17507068536124606,
          0.1581173865512739,
          0.14129014738832515,
          0.12781305007243837,
          0.11593817275972255,
          0.10440267764058979,
          0.0941218647746585,
          0.2857827811666973,
          0.22067450612706166,
          0.1889628332728862,
          0.17214773838738132,
          0.15494569646844555,
          0.138120366424141,
          0.1248297939796328,
          0.11306137537580241,
          0.10140776329671544,
          0.09344976193158899,
          0.28372507263569946,
          0.2178554979199935,
          0.1862952498500306,
          0.16930509550712458,
          0.15195548321807828,
          0.13525252285689002,
          0.1221037960856738,
          0.11030073732568499,
          0.09861012811519307,
          0.09274512609344059,
          0.28168050345318374,
          0.2150743539151307,
          0.18369259101388716,
          0.16653889832224542,
          0.1490407589703431,
          0.13253315487212805,
          0.11947773584750843,
          0.10765315151636874,
          0.0960176407519554,
          0.09135549843077113,
          0.27965039894672944,
          0.2123321212193482,
          0.18115311915846202,
          0.16384197379690235,
          0.1461954077007174,
          0.129892840301607,
          0.11692015399533195,
          0.10515131248093225,
          0.09364442731629886,
          0.09011898688580994,
          0.2776359336914424,
          0.2096279025518525,
          0.17867521271735287,
          0.16120888812275605,
          0.1434224223933536,
          0.12733332846184275,
          0.11445984874191635,
          0.10265988621836071,
          0.09221860806620487,
          0.08902685052107548,
          0.27563814505572476,
          0.20696577631650293,
          0.17625639321526898,
          0.1586404650923522,
          0.14072165523504376,
          0.12485696969808,
          0.11208442402411115,
          0.100229130930397,
          0.09162543135161624,
          0.08802004123353956,
          0.2736579455976033,
          0.20434107409600918,
          0.1738951847817411,
          0.15613521715828685,
          0.13809106951828184,
          0.12246306854276566,
          0.1097948990659433,
          0.09793483671681487,
          0.09129698115810451,
          0.08708674806004542,
          0.27169613439616513,
          0.20176040739927437,
          0.17158960034033682,
          0.15367255551759823,
          0.13553084974723972,
          0.12015406973954847,
          0.10759268688208175,
          0.09578439464511332,
          0.09008386871907821,
          0.08623460775185739,
          0.26975340740055903,
          0.19922161597410817,
          0.169350135741366,
          0.1512901025582885,
          0.13304033522173228,
          0.11793064999162427,
          0.10547942589967217,
          0.09378121170293156,
          0.08894715149639151,
          0.08531175730313226,
          0.26783036687531797,
          0.1967217929119384,
          0.1672038761462732,
          0.14896676511359302,
          0.130613976484039,
          0.11582735059947534,
          0.10345686650334782,
          0.09192325798179428,
          0.08797094766848085,
          0.08442453563386926,
          0.265927530016485,
          0.19426153745692365,
          0.16510811968534306,
          0.14670073135949557,
          0.12822660113364243,
          0.11383336764715458,
          0.10152640637174162,
          0.09038076015865541,
          0.08706951259252596,
          0.08359468671153955,
          0.2640453368083088,
          0.19184031751584169,
          0.16306172692690035,
          0.14449092054994844,
          0.1259035668004179,
          0.11190048253401373,
          0.09968523586231928,
          0.08980566071832706,
          0.08622348460606105,
          0.08281129071095021,
          0.26218415718555527,
          0.18945711970265827,
          0.16106375576585372,
          0.14233663240425543,
          0.12377847612262174,
          0.11002950003743092,
          0.09782012955814945,
          0.08940514805495406,
          0.08544014766239107,
          0.08202171864350691,
          0.26034429756151656,
          0.1871136028489126,
          0.15911266373812527,
          0.14023792681456168,
          0.12187539792180278,
          0.10820765342070056,
          0.09604335890363276,
          0.08911000391976212,
          0.08471342169467387,
          0.08104419523418213,
          0.25852600677713966,
          0.1848081658515259,
          0.15720725247953785,
          0.1381922793964486,
          0.12002958156664152,
          0.10646015964914056,
          0.09436792508583246,
          0.08812211966072299,
          0.08394959862999661,
          0.08013296551330207,
          0.25672948152231445,
          0.182540341572718,
          0.1553461549412083,
          0.13619955605432854,
          0.11824118063117517,
          0.10477394889666311,
          0.09278942854047306,
          0.08718497485630393,
          0.08320965928096719,
          0.07951409335272949,
          0.2549548712760942,
          0.18031054172801925,
          0.15352727468151156,
          0.13425859882303837,
          0.11650869206772146,
          0.1031493785691459,
          0.091309402768235,
          0.08633766553769728,
          0.08249018609681483,
          0.07908599217970125,
          0.25320228280850177,
          0.17811766855383349,
          0.15174911378663714,
          0.13236812694575795,
          0.11483241303138056,
          0.10158649399049687,
          0.08992990987824787,
          0.08557693119271792,
          0.08178880430307976,
          0.07867024562658305,
          0.2514717842830289,
          0.1759589777072673,
          0.15001233508859765,
          0.1305470977943874,
          0.11321269174373695,
          0.10008506707632021,
          0.08865023047976223,
          0.08487227944811919,
          0.08113541185731697,
          0.07826623048217625,
          0.24976340899537242,
          0.17384013432439216,
          0.14829889406969854,
          0.12877840358520215,
          0.11164922134634021,
          0.09864575750441683,
          0.08785540736206232,
          0.08420901063790563,
          0.08046943056426915,
          0.07787361392593983,
          0.24807715878095513,
          0.17175746369629633,
          0.1466430297820542,
          0.1270539185634438,
          0.11014156209206487,
          0.09726978400277424,
          0.08746182118754528,
          0.08358490965002953,
          0.0796773443724085,
          0.07749189369261607,
          0.2464130071207922,
          0.1697101616443461,
          0.14502593465808322,
          0.12537299364811202,
          0.10869012322734604,
          0.09596556107452794,
          0.08716543256226032,
          0.08299760876470935,
          0.07893130146818117,
          0.07712064007340848,
          0.24477090197247914,
          0.16769826790862688,
          0.14344670414707802,
          0.12373523124544665,
          0.10730253018041187,
          0.09466745927117626,
          0.08697490016898954,
          0.0823782541419651,
          0.0782998636945087,
          0.07676207869028964,
          0.24315076835095997,
          0.16572161876109767,
          0.1418950760811856,
          0.12213950933228114,
          0.10596019167695746,
          0.09338926540245372,
          0.08638199663982626,
          0.08176900780204116,
          0.07795789382045733,
          0.0764105157024898,
          0.24155251068115727,
          0.16377968596319875,
          0.1403774281006151,
          0.12058536182953213,
          0.10465814005019401,
          0.09216622616462919,
          0.0856370922061294,
          0.08118438454708084,
          0.07762451437608953,
          0.07606835912587771,
          0.2399760149428216,
          0.16187139485152224,
          0.1388937205014929,
          0.11907235164704974,
          0.10339651297044244,
          0.09101425597804384,
          0.08493630197053438,
          0.08062062983007107,
          0.07730024576498337,
          0.07573529857014899,
          0.23842115062597188,
          0.1599971086148272,
          0.1374430836690669,
          0.1175755460698574,
          0.10216385621993684,
          0.08992178667023268,
          0.08430407021331932,
          0.080096836179604,
          0.07698734103944194,
          0.07541097794942961,
          0.23688777251366,
          0.15815578293677734,
          0.13602506127084338,
          0.11611943376961413,
          0.10098179136032767,
          0.08888964507135645,
          0.0837094403742949,
          0.07959068625654063,
          0.07668022624123716,
          0.07509509833511331,
          0.2353757223072481,
          0.1563470903362696,
          0.1346385031102175,
          0.11470188607944312,
          0.09983886371471973,
          0.08791833153218863,
          0.0831457314185172,
          0.0790783830507784,
          0.07638119765662012,
          0.07478737834071492,
          0.23388483010810737,
          0.15457110905010785,
          0.13328326392841888,
          0.11332150570788763,
          0.0987342944198904,
          0.08700636107230843,
          0.08261717915834947,
          0.0784631553825815,
          0.07609004576516189,
          0.07448757383344586,
          0.23241491576829368,
          0.15304691929243475,
          0.13195881110518715,
          0.1119846456459565,
          0.09766812578411545,
          0.08615432221543157,
          0.08213274183205024,
          0.07788076826099656,
          0.07580652038877418,
          0.07419544263583003,
          0.23096579012162274,
          0.15180613781793234,
          0.1306640101549461,
          0.11077368515182527,
          0.09663942382687232,
          0.08555347224074064,
          0.0816762135915288,
          0.07733102806908705,
          0.07553041577719116,
          0.07391077343804195,
          0.22953725610563053,
          0.1505984439624236,
          0.12939891740185808,
          0.10959994214116449,
          0.09564852567997238,
          0.08528067643261825,
          0.08124361204782711,
          0.07695576679857491,
          0.0752614572632721,
          0.07363337012653182,
          0.22812910978386106,
          0.14941614619628585,
          0.12816256053638325,
          0.108461032269582,
          0.09469504718453528,
          0.0850621531471898,
          0.08076109375936866,
          0.07670250497684472,
          0.07499945062324259,
          0.07336306097210378,
          0.22674114127716608,
          0.14825633206258496,
          0.12695477064532754,
          0.10735775317477925,
          0.09377902004471715,
          0.08489776717889111,
          0.0802927532488086,
          0.07645592220400332,
          0.07474416759823418,
          0.07309969655993794,
          0.2253731356118534,
          0.1471198292438729,
          0.1257748179401466,
          0.10631416435855869,
          0.09289812691495343,
          0.08478564338616122,
          0.07984713919649203,
          0.0762177870193198,
          0.07449541819241327,
          0.07284303577845287,
          0.22402487349187325,
          0.14600680025498403,
          0.12462210839938825,
          0.10533839448407929,
          0.09205353806329816,
          0.08451217414324237,
          0.07940992065583292,
          0.07598377670078489,
          0.07425303226001109,
          0.07259278084236308,
          0.22269613200153862,
          0.14491675037705304,
          0.12349639284814895,
          0.10439422777121324,
          0.0912441726958657,
          0.08397534495795309,
          0.07900326331036978,
          0.07575582976431365,
          0.07401686391840748,
          0.07234913351674689,
          0.22138668524486854,
          0.14384907700416938,
          0.12239646826848011,
          0.10348105833191602,
          0.09044007120406891,
          0.08346240610570814,
          0.07861344658969353,
          0.07553379027523835,
          0.07378678547278497,
          0.07211201703934139,
          0.22009630492677087,
          0.1428038130483568,
          0.12132242470856135,
          0.10259850286228091,
          0.0896516046707753,
          0.08297929402889115,
          0.07824020752624705,
          0.07531746358853814,
          0.07356263258677523,
          0.07188183635748027,
          0.21882476088127215,
          0.14178010668976151,
          0.12027374642890448,
          0.10174589501760187,
          0.08889778536286767,
          0.08253857248175359,
          0.0778815300353614,
          0.0751052200456418,
          0.07334435008037721,
          0.07165593081722843,
          0.21757182155110635,
          0.14077745849943704,
          0.11926004126668821,
          0.10092325252039033,
          0.08817834475984414,
          0.08212287668647296,
          0.07747825518022312,
          0.07489987598451216,
          0.07313060532009615,
          0.07143833616205848,
          0.21633725442296226,
          0.13979557348844499,
          0.11827282833135992,
          0.10012976373297389,
          0.08748474140863705,
          0.0817239920376628,
          0.07707042799619052,
          0.07469985834066681,
          0.07292379781461021,
          0.0712273171935761,
          0.21512082642203686,
          0.13883403467882716,
          0.11731103426601562,
          0.09936070389508551,
          0.08683149883773128,
          0.0813421569119993,
          0.07668308232139805,
          0.07450548152382191,
          0.07272267188624089,
          0.07102625421038147,
          0.21392230426943923,
          0.1378920192083805,
          0.11636202403573437,
          0.0986147356979747,
          0.0862102233550825,
          0.08097512959161415,
          0.07629625460903755,
          0.0743158682567452,
          0.07253280409058278,
          0.07087090888006158,
          0.21274145480554996,
          0.13696317257440052,
          0.11544967151620311,
          0.09788028468337438,
          0.0856205211487865,
          0.08062478068047708,
          0.07601780248377056,
          0.07414576016626771,
          0.07238545822236264,
          0.07072172985607579,
          0.21157804528222723,
          0.1360602706404401,
          0.11456054549157631,
          0.09717950742839859,
          0.0850630552514402,
          0.08029691688566092,
          0.07587549479356832,
          0.07400889143839891,
          0.0722434154756286,
          0.07057844151493323,
          0.210431843626469,
          0.13517607843000373,
          0.11369523197247272,
          0.09650026640260721,
          0.08455888687767066,
          0.08001253384493913,
          0.07575133905804722,
          0.07387665478976412,
          0.07210637551548983,
          0.07044107813510488,
          0.20930261867803845,
          0.13431021047118946,
          0.11285219385290028,
          0.0958427331245372,
          0.0840890755417675,
          0.0797254965900579,
          0.07562998607370512,
          0.07374889933524639,
          0.07197428290019513,
          0.07031265601396364,
          0.2081901404031209,
          0.13346231183191357,
          0.11203168728989218,
          0.09520607252415444,
          0.08364965344717357,
          0.07943356528083856,
          0.07551275577594396,
          0.07362552218479151,
          0.07184709653509865,
          0.0701874943202183,
          0.20709418008614586,
          0.13263203710929808,
          0.11123324518152805,
          0.09459038221240675,
          0.08352481119270429,
          0.07914899843032491,
          0.07539963871934942,
          0.07350642390533657,
          0.07172479598263753,
          0.0703111710418912,
          0.2060145105015843,
          0.13181883142558753,
          0.1104565075206111,
          0.09399516282011859,
          0.08342919838321039,
          0.07887451758159851,
          0.07529047024369488,
          0.07339152010629789,
          0.0716073784941984,
          0.07049021685970247,
          0.2049509060674013,
          0.1310227892082444,
          0.10970168985711469,
          0.09341983775728344,
          0.08335949842313896,
          0.07862118561882242,
          0.07518512492557602,
          0.07328074026460406,
          0.07149485896876467,
          0.07067832479294277,
          0.20390314298175882,
          0.13024336449906398,
          0.10896734628020162,
          0.09286436931117395,
          0.08331267357674504,
          0.07837852345371707,
          0.0750834947119523,
          0.07317402661670587,
          0.07138726763164659,
          0.07087544635661244,
          0.2028709993443136,
          0.12948030722976336,
          0.10825232811432021,
          0.09233059432732503,
          0.08328945313386273,
          0.07814726919741721,
          0.07498549202416523,
          0.07307131534167077,
          0.07128465622700567,
          0.07108260873523538,
          0.20185425526354295,
          0.12873307958030242,
          0.10755541963221356,
          0.09181359839004109,
          0.083288227276901,
          0.07792665623504029,
          0.07489102910657798,
          0.07297247525545311,
          0.07118709261635851,
          0.07129984000215905,
          0.20085269295117408,
          0.12800154478134973,
          0.10687832853392061,
          0.09131539308559511,
          0.08330406622411814,
          0.07771680430270127,
          0.07480001635091357,
          0.0728774426332866,
          0.07109466153613904,
          0.07152686468233366,
          0.19986609680485792,
          0.12728540544402686,
          0.10622064987971115,
          0.09083579131201493,
          0.08300149872782688,
          0.07751562159107778,
          0.07471240290737556,
          0.07278636990109985,
          0.07106464924795855,
          0.07176425087880592,
          0.19889425348012865,
          0.12658421349423762,
          0.10558151759662848,
          0.0903733086529484,
          0.08272084822110534,
          0.0773261641492128,
          0.0746281049969053,
          0.07269926185215035,
          0.07123867363598123,
          0.07201229582516887,
          0.1979369519525187,
          0.1258980092501154,
          0.10494994671884779,
          0.0899288328404282,
          0.0824332290078498,
          0.07709622662921607,
          0.0745470678013816,
          0.0726161402181659,
          0.07142003809222815,
          0.07227127843930486
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#151516",
         "font": {
          "color": "#D9D9D9"
         }
        },
        "paper_bgcolor": "#151516",
        "plot_bgcolor": "#151516",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "#D9D9D9"
         }
        },
        "xaxis": {
         "gridcolor": "#434343",
         "showgrid": true,
         "tickfont": {
          "color": "#C2C2C2"
         },
         "title": {
          "font": {
           "color": "#D9D9D9"
          },
          "text": ""
         },
         "zerolinecolor": "#666570"
        },
        "yaxis": {
         "gridcolor": "#434343",
         "showgrid": true,
         "tickfont": {
          "color": "#C2C2C2"
         },
         "title": {
          "font": {
           "color": "#D9D9D9"
          },
          "text": ""
         },
         "zerolinecolor": "#666570"
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"ba94a9a2-5a1a-4bf2-9dda-0aed90145765\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';                                    if (document.getElementById(\"ba94a9a2-5a1a-4bf2-9dda-0aed90145765\")) {                    Plotly.newPlot(                        \"ba94a9a2-5a1a-4bf2-9dda-0aed90145765\",                        [{\"line\":{\"color\":\"rgba(55, 128, 191, 1.0)\",\"dash\":\"solid\",\"shape\":\"linear\",\"width\":1.3},\"mode\":\"lines\",\"name\":\"score\",\"text\":\"\",\"type\":\"scatter\",\"x\":[\"(0.1,0.0)\",\"(0.1,0.1)\",\"(0.1,0.2)\",\"(0.1,0.3)\",\"(0.1,0.4)\",\"(0.1,0.5)\",\"(0.1,0.6)\",\"(0.1,0.7)\",\"(0.1,0.8)\",\"(0.1,0.9)\",\"(0.2,0.0)\",\"(0.2,0.1)\",\"(0.2,0.2)\",\"(0.2,0.3)\",\"(0.2,0.4)\",\"(0.2,0.5)\",\"(0.2,0.6)\",\"(0.2,0.7)\",\"(0.2,0.8)\",\"(0.2,0.9)\",\"(0.3,0.0)\",\"(0.3,0.1)\",\"(0.3,0.2)\",\"(0.3,0.3)\",\"(0.3,0.4)\",\"(0.3,0.5)\",\"(0.3,0.6)\",\"(0.3,0.7)\",\"(0.3,0.8)\",\"(0.3,0.9)\",\"(0.4,0.0)\",\"(0.4,0.1)\",\"(0.4,0.2)\",\"(0.4,0.3)\",\"(0.4,0.4)\",\"(0.4,0.5)\",\"(0.4,0.6)\",\"(0.4,0.7)\",\"(0.4,0.8)\",\"(0.4,0.9)\",\"(0.5,0.0)\",\"(0.5,0.1)\",\"(0.5,0.2)\",\"(0.5,0.3)\",\"(0.5,0.4)\",\"(0.5,0.5)\",\"(0.5,0.6)\",\"(0.5,0.7)\",\"(0.5,0.8)\",\"(0.5,0.9)\",\"(0.6,0.0)\",\"(0.6,0.1)\",\"(0.6,0.2)\",\"(0.6,0.3)\",\"(0.6,0.4)\",\"(0.6,0.5)\",\"(0.6,0.6)\",\"(0.6,0.7)\",\"(0.6,0.8)\",\"(0.6,0.9)\",\"(0.7,0.0)\",\"(0.7,0.1)\",\"(0.7,0.2)\",\"(0.7,0.3)\",\"(0.7,0.4)\",\"(0.7,0.5)\",\"(0.7,0.6)\",\"(0.7,0.7)\",\"(0.7,0.8)\",\"(0.7,0.9)\",\"(0.8,0.0)\",\"(0.8,0.1)\",\"(0.8,0.2)\",\"(0.8,0.3)\",\"(0.8,0.4)\",\"(0.8,0.5)\",\"(0.8,0.6)\",\"(0.8,0.7)\",\"(0.8,0.8)\",\"(0.8,0.9)\",\"(0.9,0.0)\",\"(0.9,0.1)\",\"(0.9,0.2)\",\"(0.9,0.3)\",\"(0.9,0.4)\",\"(0.9,0.5)\",\"(0.9,0.6)\",\"(0.9,0.7)\",\"(0.9,0.8)\",\"(0.9,0.9)\",\"(1.0,0.0)\",\"(1.0,0.1)\",\"(1.0,0.2)\",\"(1.0,0.3)\",\"(1.0,0.4)\",\"(1.0,0.5)\",\"(1.0,0.6)\",\"(1.0,0.7)\",\"(1.0,0.8)\",\"(1.0,0.9)\",\"(1.1,0.0)\",\"(1.1,0.1)\",\"(1.1,0.2)\",\"(1.1,0.3)\",\"(1.1,0.4)\",\"(1.1,0.5)\",\"(1.1,0.6)\",\"(1.1,0.7)\",\"(1.1,0.8)\",\"(1.1,0.9)\",\"(1.2,0.0)\",\"(1.2,0.1)\",\"(1.2,0.2)\",\"(1.2,0.3)\",\"(1.2,0.4)\",\"(1.2,0.5)\",\"(1.2,0.6)\",\"(1.2,0.7)\",\"(1.2,0.8)\",\"(1.2,0.9)\",\"(1.3,0.0)\",\"(1.3,0.1)\",\"(1.3,0.2)\",\"(1.3,0.3)\",\"(1.3,0.4)\",\"(1.3,0.5)\",\"(1.3,0.6)\",\"(1.3,0.7)\",\"(1.3,0.8)\",\"(1.3,0.9)\",\"(1.4,0.0)\",\"(1.4,0.1)\",\"(1.4,0.2)\",\"(1.4,0.3)\",\"(1.4,0.4)\",\"(1.4,0.5)\",\"(1.4,0.6)\",\"(1.4,0.7)\",\"(1.4,0.8)\",\"(1.4,0.9)\",\"(1.5,0.0)\",\"(1.5,0.1)\",\"(1.5,0.2)\",\"(1.5,0.3)\",\"(1.5,0.4)\",\"(1.5,0.5)\",\"(1.5,0.6)\",\"(1.5,0.7)\",\"(1.5,0.8)\",\"(1.5,0.9)\",\"(1.6,0.0)\",\"(1.6,0.1)\",\"(1.6,0.2)\",\"(1.6,0.3)\",\"(1.6,0.4)\",\"(1.6,0.5)\",\"(1.6,0.6)\",\"(1.6,0.7)\",\"(1.6,0.8)\",\"(1.6,0.9)\",\"(1.7,0.0)\",\"(1.7,0.1)\",\"(1.7,0.2)\",\"(1.7,0.3)\",\"(1.7,0.4)\",\"(1.7,0.5)\",\"(1.7,0.6)\",\"(1.7,0.7)\",\"(1.7,0.8)\",\"(1.7,0.9)\",\"(1.8,0.0)\",\"(1.8,0.1)\",\"(1.8,0.2)\",\"(1.8,0.3)\",\"(1.8,0.4)\",\"(1.8,0.5)\",\"(1.8,0.6)\",\"(1.8,0.7)\",\"(1.8,0.8)\",\"(1.8,0.9)\",\"(1.9,0.0)\",\"(1.9,0.1)\",\"(1.9,0.2)\",\"(1.9,0.3)\",\"(1.9,0.4)\",\"(1.9,0.5)\",\"(1.9,0.6)\",\"(1.9,0.7)\",\"(1.9,0.8)\",\"(1.9,0.9)\",\"(2.0,0.0)\",\"(2.0,0.1)\",\"(2.0,0.2)\",\"(2.0,0.3)\",\"(2.0,0.4)\",\"(2.0,0.5)\",\"(2.0,0.6)\",\"(2.0,0.7)\",\"(2.0,0.8)\",\"(2.0,0.9)\",\"(2.1,0.0)\",\"(2.1,0.1)\",\"(2.1,0.2)\",\"(2.1,0.3)\",\"(2.1,0.4)\",\"(2.1,0.5)\",\"(2.1,0.6)\",\"(2.1,0.7)\",\"(2.1,0.8)\",\"(2.1,0.9)\",\"(2.2,0.0)\",\"(2.2,0.1)\",\"(2.2,0.2)\",\"(2.2,0.3)\",\"(2.2,0.4)\",\"(2.2,0.5)\",\"(2.2,0.6)\",\"(2.2,0.7)\",\"(2.2,0.8)\",\"(2.2,0.9)\",\"(2.3,0.0)\",\"(2.3,0.1)\",\"(2.3,0.2)\",\"(2.3,0.3)\",\"(2.3,0.4)\",\"(2.3,0.5)\",\"(2.3,0.6)\",\"(2.3,0.7)\",\"(2.3,0.8)\",\"(2.3,0.9)\",\"(2.4,0.0)\",\"(2.4,0.1)\",\"(2.4,0.2)\",\"(2.4,0.3)\",\"(2.4,0.4)\",\"(2.4,0.5)\",\"(2.4,0.6)\",\"(2.4,0.7)\",\"(2.4,0.8)\",\"(2.4,0.9)\",\"(2.5,0.0)\",\"(2.5,0.1)\",\"(2.5,0.2)\",\"(2.5,0.3)\",\"(2.5,0.4)\",\"(2.5,0.5)\",\"(2.5,0.6)\",\"(2.5,0.7)\",\"(2.5,0.8)\",\"(2.5,0.9)\",\"(2.6,0.0)\",\"(2.6,0.1)\",\"(2.6,0.2)\",\"(2.6,0.3)\",\"(2.6,0.4)\",\"(2.6,0.5)\",\"(2.6,0.6)\",\"(2.6,0.7)\",\"(2.6,0.8)\",\"(2.6,0.9)\",\"(2.7,0.0)\",\"(2.7,0.1)\",\"(2.7,0.2)\",\"(2.7,0.3)\",\"(2.7,0.4)\",\"(2.7,0.5)\",\"(2.7,0.6)\",\"(2.7,0.7)\",\"(2.7,0.8)\",\"(2.7,0.9)\",\"(2.8,0.0)\",\"(2.8,0.1)\",\"(2.8,0.2)\",\"(2.8,0.3)\",\"(2.8,0.4)\",\"(2.8,0.5)\",\"(2.8,0.6)\",\"(2.8,0.7)\",\"(2.8,0.8)\",\"(2.8,0.9)\",\"(2.9,0.0)\",\"(2.9,0.1)\",\"(2.9,0.2)\",\"(2.9,0.3)\",\"(2.9,0.4)\",\"(2.9,0.5)\",\"(2.9,0.6)\",\"(2.9,0.7)\",\"(2.9,0.8)\",\"(2.9,0.9)\",\"(3.0,0.0)\",\"(3.0,0.1)\",\"(3.0,0.2)\",\"(3.0,0.3)\",\"(3.0,0.4)\",\"(3.0,0.5)\",\"(3.0,0.6)\",\"(3.0,0.7)\",\"(3.0,0.8)\",\"(3.0,0.9)\",\"(3.1,0.0)\",\"(3.1,0.1)\",\"(3.1,0.2)\",\"(3.1,0.3)\",\"(3.1,0.4)\",\"(3.1,0.5)\",\"(3.1,0.6)\",\"(3.1,0.7)\",\"(3.1,0.8)\",\"(3.1,0.9)\",\"(3.2,0.0)\",\"(3.2,0.1)\",\"(3.2,0.2)\",\"(3.2,0.3)\",\"(3.2,0.4)\",\"(3.2,0.5)\",\"(3.2,0.6)\",\"(3.2,0.7)\",\"(3.2,0.8)\",\"(3.2,0.9)\",\"(3.3,0.0)\",\"(3.3,0.1)\",\"(3.3,0.2)\",\"(3.3,0.3)\",\"(3.3,0.4)\",\"(3.3,0.5)\",\"(3.3,0.6)\",\"(3.3,0.7)\",\"(3.3,0.8)\",\"(3.3,0.9)\",\"(3.4,0.0)\",\"(3.4,0.1)\",\"(3.4,0.2)\",\"(3.4,0.3)\",\"(3.4,0.4)\",\"(3.4,0.5)\",\"(3.4,0.6)\",\"(3.4,0.7)\",\"(3.4,0.8)\",\"(3.4,0.9)\",\"(3.5,0.0)\",\"(3.5,0.1)\",\"(3.5,0.2)\",\"(3.5,0.3)\",\"(3.5,0.4)\",\"(3.5,0.5)\",\"(3.5,0.6)\",\"(3.5,0.7)\",\"(3.5,0.8)\",\"(3.5,0.9)\",\"(3.6,0.0)\",\"(3.6,0.1)\",\"(3.6,0.2)\",\"(3.6,0.3)\",\"(3.6,0.4)\",\"(3.6,0.5)\",\"(3.6,0.6)\",\"(3.6,0.7)\",\"(3.6,0.8)\",\"(3.6,0.9)\",\"(3.7,0.0)\",\"(3.7,0.1)\",\"(3.7,0.2)\",\"(3.7,0.3)\",\"(3.7,0.4)\",\"(3.7,0.5)\",\"(3.7,0.6)\",\"(3.7,0.7)\",\"(3.7,0.8)\",\"(3.7,0.9)\",\"(3.8,0.0)\",\"(3.8,0.1)\",\"(3.8,0.2)\",\"(3.8,0.3)\",\"(3.8,0.4)\",\"(3.8,0.5)\",\"(3.8,0.6)\",\"(3.8,0.7)\",\"(3.8,0.8)\",\"(3.8,0.9)\",\"(3.9,0.0)\",\"(3.9,0.1)\",\"(3.9,0.2)\",\"(3.9,0.3)\",\"(3.9,0.4)\",\"(3.9,0.5)\",\"(3.9,0.6)\",\"(3.9,0.7)\",\"(3.9,0.8)\",\"(3.9,0.9)\",\"(4.0,0.0)\",\"(4.0,0.1)\",\"(4.0,0.2)\",\"(4.0,0.3)\",\"(4.0,0.4)\",\"(4.0,0.5)\",\"(4.0,0.6)\",\"(4.0,0.7)\",\"(4.0,0.8)\",\"(4.0,0.9)\",\"(4.1,0.0)\",\"(4.1,0.1)\",\"(4.1,0.2)\",\"(4.1,0.3)\",\"(4.1,0.4)\",\"(4.1,0.5)\",\"(4.1,0.6)\",\"(4.1,0.7)\",\"(4.1,0.8)\",\"(4.1,0.9)\",\"(4.2,0.0)\",\"(4.2,0.1)\",\"(4.2,0.2)\",\"(4.2,0.3)\",\"(4.2,0.4)\",\"(4.2,0.5)\",\"(4.2,0.6)\",\"(4.2,0.7)\",\"(4.2,0.8)\",\"(4.2,0.9)\",\"(4.3,0.0)\",\"(4.3,0.1)\",\"(4.3,0.2)\",\"(4.3,0.3)\",\"(4.3,0.4)\",\"(4.3,0.5)\",\"(4.3,0.6)\",\"(4.3,0.7)\",\"(4.3,0.8)\",\"(4.3,0.9)\",\"(4.4,0.0)\",\"(4.4,0.1)\",\"(4.4,0.2)\",\"(4.4,0.3)\",\"(4.4,0.4)\",\"(4.4,0.5)\",\"(4.4,0.6)\",\"(4.4,0.7)\",\"(4.4,0.8)\",\"(4.4,0.9)\",\"(4.5,0.0)\",\"(4.5,0.1)\",\"(4.5,0.2)\",\"(4.5,0.3)\",\"(4.5,0.4)\",\"(4.5,0.5)\",\"(4.5,0.6)\",\"(4.5,0.7)\",\"(4.5,0.8)\",\"(4.5,0.9)\",\"(4.6,0.0)\",\"(4.6,0.1)\",\"(4.6,0.2)\",\"(4.6,0.3)\",\"(4.6,0.4)\",\"(4.6,0.5)\",\"(4.6,0.6)\",\"(4.6,0.7)\",\"(4.6,0.8)\",\"(4.6,0.9)\",\"(4.7,0.0)\",\"(4.7,0.1)\",\"(4.7,0.2)\",\"(4.7,0.3)\",\"(4.7,0.4)\",\"(4.7,0.5)\",\"(4.7,0.6)\",\"(4.7,0.7)\",\"(4.7,0.8)\",\"(4.7,0.9)\",\"(4.8,0.0)\",\"(4.8,0.1)\",\"(4.8,0.2)\",\"(4.8,0.3)\",\"(4.8,0.4)\",\"(4.8,0.5)\",\"(4.8,0.6)\",\"(4.8,0.7)\",\"(4.8,0.8)\",\"(4.8,0.9)\",\"(4.9,0.0)\",\"(4.9,0.1)\",\"(4.9,0.2)\",\"(4.9,0.3)\",\"(4.9,0.4)\",\"(4.9,0.5)\",\"(4.9,0.6)\",\"(4.9,0.7)\",\"(4.9,0.8)\",\"(4.9,0.9)\",\"(5.0,0.0)\",\"(5.0,0.1)\",\"(5.0,0.2)\",\"(5.0,0.3)\",\"(5.0,0.4)\",\"(5.0,0.5)\",\"(5.0,0.6)\",\"(5.0,0.7)\",\"(5.0,0.8)\",\"(5.0,0.9)\",\"(5.1,0.0)\",\"(5.1,0.1)\",\"(5.1,0.2)\",\"(5.1,0.3)\",\"(5.1,0.4)\",\"(5.1,0.5)\",\"(5.1,0.6)\",\"(5.1,0.7)\",\"(5.1,0.8)\",\"(5.1,0.9)\",\"(5.2,0.0)\",\"(5.2,0.1)\",\"(5.2,0.2)\",\"(5.2,0.3)\",\"(5.2,0.4)\",\"(5.2,0.5)\",\"(5.2,0.6)\",\"(5.2,0.7)\",\"(5.2,0.8)\",\"(5.2,0.9)\",\"(5.3,0.0)\",\"(5.3,0.1)\",\"(5.3,0.2)\",\"(5.3,0.3)\",\"(5.3,0.4)\",\"(5.3,0.5)\",\"(5.3,0.6)\",\"(5.3,0.7)\",\"(5.3,0.8)\",\"(5.3,0.9)\",\"(5.4,0.0)\",\"(5.4,0.1)\",\"(5.4,0.2)\",\"(5.4,0.3)\",\"(5.4,0.4)\",\"(5.4,0.5)\",\"(5.4,0.6)\",\"(5.4,0.7)\",\"(5.4,0.8)\",\"(5.4,0.9)\",\"(5.5,0.0)\",\"(5.5,0.1)\",\"(5.5,0.2)\",\"(5.5,0.3)\",\"(5.5,0.4)\",\"(5.5,0.5)\",\"(5.5,0.6)\",\"(5.5,0.7)\",\"(5.5,0.8)\",\"(5.5,0.9)\",\"(5.6,0.0)\",\"(5.6,0.1)\",\"(5.6,0.2)\",\"(5.6,0.3)\",\"(5.6,0.4)\",\"(5.6,0.5)\",\"(5.6,0.6)\",\"(5.6,0.7)\",\"(5.6,0.8)\",\"(5.6,0.9)\",\"(5.7,0.0)\",\"(5.7,0.1)\",\"(5.7,0.2)\",\"(5.7,0.3)\",\"(5.7,0.4)\",\"(5.7,0.5)\",\"(5.7,0.6)\",\"(5.7,0.7)\",\"(5.7,0.8)\",\"(5.7,0.9)\",\"(5.8,0.0)\",\"(5.8,0.1)\",\"(5.8,0.2)\",\"(5.8,0.3)\",\"(5.8,0.4)\",\"(5.8,0.5)\",\"(5.8,0.6)\",\"(5.8,0.7)\",\"(5.8,0.8)\",\"(5.8,0.9)\",\"(5.9,0.0)\",\"(5.9,0.1)\",\"(5.9,0.2)\",\"(5.9,0.3)\",\"(5.9,0.4)\",\"(5.9,0.5)\",\"(5.9,0.6)\",\"(5.9,0.7)\",\"(5.9,0.8)\",\"(5.9,0.9)\",\"(6.0,0.0)\",\"(6.0,0.1)\",\"(6.0,0.2)\",\"(6.0,0.3)\",\"(6.0,0.4)\",\"(6.0,0.5)\",\"(6.0,0.6)\",\"(6.0,0.7)\",\"(6.0,0.8)\",\"(6.0,0.9)\",\"(6.1,0.0)\",\"(6.1,0.1)\",\"(6.1,0.2)\",\"(6.1,0.3)\",\"(6.1,0.4)\",\"(6.1,0.5)\",\"(6.1,0.6)\",\"(6.1,0.7)\",\"(6.1,0.8)\",\"(6.1,0.9)\",\"(6.2,0.0)\",\"(6.2,0.1)\",\"(6.2,0.2)\",\"(6.2,0.3)\",\"(6.2,0.4)\",\"(6.2,0.5)\",\"(6.2,0.6)\",\"(6.2,0.7)\",\"(6.2,0.8)\",\"(6.2,0.9)\",\"(6.3,0.0)\",\"(6.3,0.1)\",\"(6.3,0.2)\",\"(6.3,0.3)\",\"(6.3,0.4)\",\"(6.3,0.5)\",\"(6.3,0.6)\",\"(6.3,0.7)\",\"(6.3,0.8)\",\"(6.3,0.9)\",\"(6.4,0.0)\",\"(6.4,0.1)\",\"(6.4,0.2)\",\"(6.4,0.3)\",\"(6.4,0.4)\",\"(6.4,0.5)\",\"(6.4,0.6)\",\"(6.4,0.7)\",\"(6.4,0.8)\",\"(6.4,0.9)\",\"(6.5,0.0)\",\"(6.5,0.1)\",\"(6.5,0.2)\",\"(6.5,0.3)\",\"(6.5,0.4)\",\"(6.5,0.5)\",\"(6.5,0.6)\",\"(6.5,0.7)\",\"(6.5,0.8)\",\"(6.5,0.9)\",\"(6.6,0.0)\",\"(6.6,0.1)\",\"(6.6,0.2)\",\"(6.6,0.3)\",\"(6.6,0.4)\",\"(6.6,0.5)\",\"(6.6,0.6)\",\"(6.6,0.7)\",\"(6.6,0.8)\",\"(6.6,0.9)\",\"(6.7,0.0)\",\"(6.7,0.1)\",\"(6.7,0.2)\",\"(6.7,0.3)\",\"(6.7,0.4)\",\"(6.7,0.5)\",\"(6.7,0.6)\",\"(6.7,0.7)\",\"(6.7,0.8)\",\"(6.7,0.9)\",\"(6.8,0.0)\",\"(6.8,0.1)\",\"(6.8,0.2)\",\"(6.8,0.3)\",\"(6.8,0.4)\",\"(6.8,0.5)\",\"(6.8,0.6)\",\"(6.8,0.7)\",\"(6.8,0.8)\",\"(6.8,0.9)\",\"(6.9,0.0)\",\"(6.9,0.1)\",\"(6.9,0.2)\",\"(6.9,0.3)\",\"(6.9,0.4)\",\"(6.9,0.5)\",\"(6.9,0.6)\",\"(6.9,0.7)\",\"(6.9,0.8)\",\"(6.9,0.9)\",\"(7.0,0.0)\",\"(7.0,0.1)\",\"(7.0,0.2)\",\"(7.0,0.3)\",\"(7.0,0.4)\",\"(7.0,0.5)\",\"(7.0,0.6)\",\"(7.0,0.7)\",\"(7.0,0.8)\",\"(7.0,0.9)\",\"(7.1,0.0)\",\"(7.1,0.1)\",\"(7.1,0.2)\",\"(7.1,0.3)\",\"(7.1,0.4)\",\"(7.1,0.5)\",\"(7.1,0.6)\",\"(7.1,0.7)\",\"(7.1,0.8)\",\"(7.1,0.9)\",\"(7.2,0.0)\",\"(7.2,0.1)\",\"(7.2,0.2)\",\"(7.2,0.3)\",\"(7.2,0.4)\",\"(7.2,0.5)\",\"(7.2,0.6)\",\"(7.2,0.7)\",\"(7.2,0.8)\",\"(7.2,0.9)\",\"(7.3,0.0)\",\"(7.3,0.1)\",\"(7.3,0.2)\",\"(7.3,0.3)\",\"(7.3,0.4)\",\"(7.3,0.5)\",\"(7.3,0.6)\",\"(7.3,0.7)\",\"(7.3,0.8)\",\"(7.3,0.9)\",\"(7.4,0.0)\",\"(7.4,0.1)\",\"(7.4,0.2)\",\"(7.4,0.3)\",\"(7.4,0.4)\",\"(7.4,0.5)\",\"(7.4,0.6)\",\"(7.4,0.7)\",\"(7.4,0.8)\",\"(7.4,0.9)\",\"(7.5,0.0)\",\"(7.5,0.1)\",\"(7.5,0.2)\",\"(7.5,0.3)\",\"(7.5,0.4)\",\"(7.5,0.5)\",\"(7.5,0.6)\",\"(7.5,0.7)\",\"(7.5,0.8)\",\"(7.5,0.9)\",\"(7.6,0.0)\",\"(7.6,0.1)\",\"(7.6,0.2)\",\"(7.6,0.3)\",\"(7.6,0.4)\",\"(7.6,0.5)\",\"(7.6,0.6)\",\"(7.6,0.7)\",\"(7.6,0.8)\",\"(7.6,0.9)\",\"(7.7,0.0)\",\"(7.7,0.1)\",\"(7.7,0.2)\",\"(7.7,0.3)\",\"(7.7,0.4)\",\"(7.7,0.5)\",\"(7.7,0.6)\",\"(7.7,0.7)\",\"(7.7,0.8)\",\"(7.7,0.9)\",\"(7.8,0.0)\",\"(7.8,0.1)\",\"(7.8,0.2)\",\"(7.8,0.3)\",\"(7.8,0.4)\",\"(7.8,0.5)\",\"(7.8,0.6)\",\"(7.8,0.7)\",\"(7.8,0.8)\",\"(7.8,0.9)\",\"(7.9,0.0)\",\"(7.9,0.1)\",\"(7.9,0.2)\",\"(7.9,0.3)\",\"(7.9,0.4)\",\"(7.9,0.5)\",\"(7.9,0.6)\",\"(7.9,0.7)\",\"(7.9,0.8)\",\"(7.9,0.9)\",\"(8.0,0.0)\",\"(8.0,0.1)\",\"(8.0,0.2)\",\"(8.0,0.3)\",\"(8.0,0.4)\",\"(8.0,0.5)\",\"(8.0,0.6)\",\"(8.0,0.7)\",\"(8.0,0.8)\",\"(8.0,0.9)\",\"(8.1,0.0)\",\"(8.1,0.1)\",\"(8.1,0.2)\",\"(8.1,0.3)\",\"(8.1,0.4)\",\"(8.1,0.5)\",\"(8.1,0.6)\",\"(8.1,0.7)\",\"(8.1,0.8)\",\"(8.1,0.9)\",\"(8.2,0.0)\",\"(8.2,0.1)\",\"(8.2,0.2)\",\"(8.2,0.3)\",\"(8.2,0.4)\",\"(8.2,0.5)\",\"(8.2,0.6)\",\"(8.2,0.7)\",\"(8.2,0.8)\",\"(8.2,0.9)\",\"(8.3,0.0)\",\"(8.3,0.1)\",\"(8.3,0.2)\",\"(8.3,0.3)\",\"(8.3,0.4)\",\"(8.3,0.5)\",\"(8.3,0.6)\",\"(8.3,0.7)\",\"(8.3,0.8)\",\"(8.3,0.9)\",\"(8.4,0.0)\",\"(8.4,0.1)\",\"(8.4,0.2)\",\"(8.4,0.3)\",\"(8.4,0.4)\",\"(8.4,0.5)\",\"(8.4,0.6)\",\"(8.4,0.7)\",\"(8.4,0.8)\",\"(8.4,0.9)\",\"(8.5,0.0)\",\"(8.5,0.1)\",\"(8.5,0.2)\",\"(8.5,0.3)\",\"(8.5,0.4)\",\"(8.5,0.5)\",\"(8.5,0.6)\",\"(8.5,0.7)\",\"(8.5,0.8)\",\"(8.5,0.9)\",\"(8.6,0.0)\",\"(8.6,0.1)\",\"(8.6,0.2)\",\"(8.6,0.3)\",\"(8.6,0.4)\",\"(8.6,0.5)\",\"(8.6,0.6)\",\"(8.6,0.7)\",\"(8.6,0.8)\",\"(8.6,0.9)\",\"(8.7,0.0)\",\"(8.7,0.1)\",\"(8.7,0.2)\",\"(8.7,0.3)\",\"(8.7,0.4)\",\"(8.7,0.5)\",\"(8.7,0.6)\",\"(8.7,0.7)\",\"(8.7,0.8)\",\"(8.7,0.9)\",\"(8.8,0.0)\",\"(8.8,0.1)\",\"(8.8,0.2)\",\"(8.8,0.3)\",\"(8.8,0.4)\",\"(8.8,0.5)\",\"(8.8,0.6)\",\"(8.8,0.7)\",\"(8.8,0.8)\",\"(8.8,0.9)\",\"(8.9,0.0)\",\"(8.9,0.1)\",\"(8.9,0.2)\",\"(8.9,0.3)\",\"(8.9,0.4)\",\"(8.9,0.5)\",\"(8.9,0.6)\",\"(8.9,0.7)\",\"(8.9,0.8)\",\"(8.9,0.9)\",\"(9.0,0.0)\",\"(9.0,0.1)\",\"(9.0,0.2)\",\"(9.0,0.3)\",\"(9.0,0.4)\",\"(9.0,0.5)\",\"(9.0,0.6)\",\"(9.0,0.7)\",\"(9.0,0.8)\",\"(9.0,0.9)\",\"(9.1,0.0)\",\"(9.1,0.1)\",\"(9.1,0.2)\",\"(9.1,0.3)\",\"(9.1,0.4)\",\"(9.1,0.5)\",\"(9.1,0.6)\",\"(9.1,0.7)\",\"(9.1,0.8)\",\"(9.1,0.9)\",\"(9.2,0.0)\",\"(9.2,0.1)\",\"(9.2,0.2)\",\"(9.2,0.3)\",\"(9.2,0.4)\",\"(9.2,0.5)\",\"(9.2,0.6)\",\"(9.2,0.7)\",\"(9.2,0.8)\",\"(9.2,0.9)\",\"(9.3,0.0)\",\"(9.3,0.1)\",\"(9.3,0.2)\",\"(9.3,0.3)\",\"(9.3,0.4)\",\"(9.3,0.5)\",\"(9.3,0.6)\",\"(9.3,0.7)\",\"(9.3,0.8)\",\"(9.3,0.9)\",\"(9.4,0.0)\",\"(9.4,0.1)\",\"(9.4,0.2)\",\"(9.4,0.3)\",\"(9.4,0.4)\",\"(9.4,0.5)\",\"(9.4,0.6)\",\"(9.4,0.7)\",\"(9.4,0.8)\",\"(9.4,0.9)\",\"(9.5,0.0)\",\"(9.5,0.1)\",\"(9.5,0.2)\",\"(9.5,0.3)\",\"(9.5,0.4)\",\"(9.5,0.5)\",\"(9.5,0.6)\",\"(9.5,0.7)\",\"(9.5,0.8)\",\"(9.5,0.9)\",\"(9.6,0.0)\",\"(9.6,0.1)\",\"(9.6,0.2)\",\"(9.6,0.3)\",\"(9.6,0.4)\",\"(9.6,0.5)\",\"(9.6,0.6)\",\"(9.6,0.7)\",\"(9.6,0.8)\",\"(9.6,0.9)\",\"(9.7,0.0)\",\"(9.7,0.1)\",\"(9.7,0.2)\",\"(9.7,0.3)\",\"(9.7,0.4)\",\"(9.7,0.5)\",\"(9.7,0.6)\",\"(9.7,0.7)\",\"(9.7,0.8)\",\"(9.7,0.9)\",\"(9.8,0.0)\",\"(9.8,0.1)\",\"(9.8,0.2)\",\"(9.8,0.3)\",\"(9.8,0.4)\",\"(9.8,0.5)\",\"(9.8,0.6)\",\"(9.8,0.7)\",\"(9.8,0.8)\",\"(9.8,0.9)\",\"(9.9,0.0)\",\"(9.9,0.1)\",\"(9.9,0.2)\",\"(9.9,0.3)\",\"(9.9,0.4)\",\"(9.9,0.5)\",\"(9.9,0.6)\",\"(9.9,0.7)\",\"(9.9,0.8)\",\"(9.9,0.9)\"],\"y\":[0.29289590910141733,0.28673566103515646,0.2799391918735423,0.2723063707258394,0.26401996261741306,0.2549564741577474,0.24455339811080723,0.23267903223865122,0.21892606634616762,0.2063968386625814,0.32895610899178473,0.32258204761290765,0.3153202757471999,0.307229918702398,0.2978188333131305,0.28695730729046537,0.27671268689990086,0.26461386927543235,0.2508574766712583,0.23353648792333437,0.34234327883568794,0.3355457015521946,0.3278780093138807,0.31910476195075116,0.3094067485183694,0.29966706064120574,0.2881867172887829,0.27437948031897735,0.25762080614890703,0.23652034197854416,0.3466224831596823,0.33875603521801384,0.32986638508412525,0.3195530016004402,0.3092692026374486,0.29733838315267375,0.2835565518272535,0.26981122055141915,0.25500425615215216,0.23427902105822895,0.346716648734065,0.33723284780517987,0.3264218000471719,0.31434297876910755,0.3066752397375098,0.3014409941507938,0.2944610955228993,0.2848517752528723,0.2713949791034217,0.2513936607735131,0.3447524312784082,0.3333453697261683,0.32091607825182955,0.3176025352017648,0.3142208558868139,0.3098466927481525,0.30382886456053393,0.2954351391810256,0.2832856785751213,0.2645592810826197,0.341756407801572,0.3282005428072222,0.32428330021212404,0.32198702139370466,0.319214243002381,0.3154551324383144,0.3101683635871944,0.30273187175557503,0.29181396052439423,0.2776434715938957,0.3382627860744525,0.32988502180877266,0.3267996220134552,0.32488616461235365,0.32246435515377053,0.3190599385963839,0.31431199588964764,0.30755617403399693,0.29978675457387527,0.2882120287997718,0.3345638222316132,0.330961529104724,0.32835560845912565,0.3266869366782597,0.3244661079352515,0.32126920243685214,0.31682931738545417,0.3115559108264551,0.30571022262724873,0.29601907781682313,0.33082426835344314,0.3314764250989874,0.32921849799368724,0.3276900647967462,0.32551513704270096,0.3224290833531881,0.3181586282284115,0.3146206489244992,0.3096576590956711,0.30140031766741454,0.3271380351934931,0.33158585598309565,0.32957868940548124,0.3281108084570235,0.3259031918768156,0.32279791324923407,0.31935101007095845,0.3164030532556386,0.3119498672600335,0.3044602217659622,0.3235580782467914,0.33139711434034413,0.32959294468819467,0.3280773224170277,0.32577456831130586,0.32260749154099777,0.3199471370335079,0.3168660350030552,0.3124081317844279,0.3054414258439203,0.3201129804462904,0.33097668362298294,0.3293045960135347,0.32767897649910516,0.3252536112449536,0.32191723527095567,0.31956592871049094,0.31631319332663865,0.31166152643418127,0.30525449126406756,0.31681653675276567,0.3303825242723408,0.32878849028182994,0.3270203793371518,0.3243818181414225,0.32114819513150084,0.31860445044023117,0.3150329526183592,0.31014191486755377,0.30559970344209747,0.3136734787746756,0.32816094786827926,0.32809900230762273,0.3261525087180203,0.3231031502631901,0.3200742093935684,0.3171808700879282,0.3132676478740431,0.3085979023096487,0.30469635474246287,0.31068298431094477,0.325913321516219,0.3272618505675485,0.32495842912003436,0.3216455589405619,0.31869216003449274,0.3153999461893993,0.31112169101377307,0.3073312327454192,0.3047342006589979,0.3078408728170687,0.3237638057386548,0.3262446627181515,0.3236304256381,0.32003337719576874,0.3170597950738428,0.31347032942314634,0.3086531669622719,0.3054383995934127,0.3043011758666102,0.3051409992805277,0.321728398759659,0.32506232359583703,0.3222009606014086,0.3183584718980742,0.3152939004395206,0.311250709347652,0.306950955080973,0.30389422633218693,0.30378983528529063,0.3025761476121836,0.31975747790880377,0.3238102893628852,0.32070159594082304,0.3167873581958139,0.3134209374379551,0.30878638296030436,0.3049241668134782,0.30251808389551205,0.3024344105288957,0.30013860548490623,0.31783021058783667,0.32251273163329425,0.319149473859303,0.3151450905093707,0.3113898573511747,0.30616083662790033,0.302592647242145,0.3010868661095844,0.2995397371160008,0.2978205332300234,0.3159889455574569,0.32117984565849667,0.31753001694860883,0.31346510084865287,0.30923579517965294,0.3042511901784264,0.3006028581060229,0.2992766848812355,0.2956759769032974,0.2956141979614886,0.3142298198499327,0.3198099796531624,0.3158676804545077,0.31169596797531973,0.3069515326145426,0.30217359465893734,0.29875082708496764,0.2970885417941632,0.292051321661414,0.29351211871795413,0.31257059473664217,0.31841291934487176,0.3141897577900268,0.3098548914927679,0.3045664368362325,0.29996179522326505,0.29689443465263277,0.29397011989229405,0.2889647985912211,0.29150715253536236,0.31101633273093887,0.3170180109102749,0.3125275904368905,0.30796075572029347,0.302093459999427,0.29759780387354884,0.2948536035249632,0.2903924642120254,0.28564021916708415,0.289592541242329,0.3095278858248474,0.3156217532523618,0.310818071360884,0.3059974160971035,0.3000354149520907,0.29543597406467326,0.2925998495441922,0.2873093216666177,0.2822110888639928,0.287761932211404,0.308093697081197,0.31421961586046,0.30908460889794726,0.30398289139091444,0.29807072799627254,0.2934509324046151,0.2901522516981083,0.28459534169663825,0.2785420014661718,0.2860093819872322,0.3067139023588778,0.3127941491939178,0.30737899177970607,0.3019270736766524,0.2960385231276214,0.2914780253288274,0.2871152498123458,0.2818082758085047,0.27612394103157334,0.28432934884152217,0.3053796628329503,0.3113554081265459,0.3057420146569753,0.2998350689590293,0.29394153973920906,0.28943418293218226,0.2840478617230856,0.2788805276858521,0.2736462021349405,0.28271667837187575,0.3040944643702193,0.30991058360978396,0.3040794708552241,0.2977127375078196,0.2918046399731007,0.2872843910400192,0.2817803510522542,0.2758017157817998,0.2710090515575164,0.28116658494884184,0.3028480600595321,0.3084684433051841,0.30240221064933037,0.2955645910488038,0.28960771044879097,0.2850390015927875,0.2794475149610348,0.27310066974408986,0.2682298089447206,0.2796746309166043,0.3016421451791639,0.30701219383570816,0.30070907272202535,0.2934952424844376,0.2875623049928724,0.28281737552304365,0.27702479125755886,0.27097257238288575,0.2652861154610845,0.2782367048342475,0.3004675752693577,0.3055531256168732,0.2990140915216606,0.2917323774366566,0.2856377599328414,0.28046974235023314,0.27452833138549854,0.26875000305484675,0.2622128695379658,0.276848999615958,0.2993294549801913,0.3040886903043385,0.29729632770306413,0.2899369872428491,0.28373572007196757,0.27809051569493887,0.2719548504763816,0.26643362296397904,0.2589931548588706,0.27550799113208246,0.29822179920245817,0.30262677417650874,0.2955669187694328,0.2881234988332343,0.2818165452119449,0.27613900625175103,0.26930898354541866,0.26402383274170294,0.25613796352992974,0.27421041762693715,0.29713903176955986,0.3011643860602405,0.29383369672615156,0.2862874045020839,0.2800456824765084,0.2741432669871393,0.2674286245099408,0.2615363815670974,0.25365600898417195,0.27295326016648025,0.29608479025985507,0.2997071968356643,0.292090856349159,0.28443874123565693,0.278261459782271,0.27211073892649523,0.2655524289451141,0.2589454908241966,0.25101049672884745,0.27173372423089664,0.2950537140919557,0.2982639889456567,0.2903442511293763,0.28258033527108195,0.27644425316799925,0.2700390652402738,0.26362721812746226,0.25627971518945136,0.24823745101915573,0.27054922249969227,0.29404062064659886,0.29680698963765045,0.28859442910781885,0.28071224734955846,0.27459032217118173,0.26792937568372693,0.2616533292839143,0.25370343054082534,0.24531998780354722,0.2693973588318117,0.2930513558020491,0.2953551353794907,0.28684608777580467,0.27896663510737857,0.2727107649722281,0.26578156134874376,0.2596305565523015,0.25168804875295103,0.2427871433038309,0.2682759134132334,0.2920782763819981,0.2939054786508548,0.2850920696388013,0.27720499911509955,0.27091717885949973,0.26360770894098795,0.25755778379845484,0.2495675984974049,0.2406210007082448,0.26718282902559004,0.2911252292518705,0.29248958141376474,0.28333831799730913,0.2756384409839392,0.2692429065070928,0.26198422736678467,0.25544177337955654,0.24737007376804085,0.23925549192702236,0.26611619837784617,0.29018735957456615,0.2910797313994391,0.2816642593727401,0.27411869192319327,0.2675783470050572,0.2604063498990626,0.2532871269652666,0.24509536007107116,0.23954144376607617,0.26507425243689997,0.289264494457515,0.289674314029917,0.2801523675655529,0.2726360561663813,0.2659012607246961,0.25881225899350446,0.25107289506648334,0.24273921062988343,0.23978804410789062,0.2640553496905188,0.2883514849128836,0.2882786967735239,0.27876736496334653,0.27114285914129455,0.26420841482934354,0.2571806565740306,0.24922536599170944,0.2407373784154055,0.23997727214413025,0.2630579662759889,0.28745317922477615,0.2868894170997762,0.27738863276582315,0.26963498613235976,0.2624951462805673,0.2555268345865507,0.2475348979603506,0.23900248041376973,0.24009271789065886,0.2620806869093794,0.28656713819760127,0.28550756501174057,0.2760092775669127,0.2681180161695912,0.2607755512167264,0.2538479335086233,0.24579639263086783,0.2372233260413836,0.24014660268438587,0.26112219655310814,0.28571712929585963,0.28413013008649923,0.2746413890990974,0.2665922846727291,0.2590439465038126,0.2521487442610707,0.24401567378143157,0.2374150442585942,0.24012756769320137,0.26018127276278913,0.2848901576429072,0.2827732689631147,0.2732623128091912,0.26505478070600963,0.2573005894830439,0.25042840412965367,0.2421944706335359,0.23754203333345023,0.24021376384437995,0.25925677865784813,0.284073244003456,0.28146204754174686,0.27188096806543843,0.26353604515511536,0.2557495932484397,0.24868777535853623,0.24033658954967085,0.23765491872872155,0.24024619073178938,0.2583476564643672,0.2832669286487876,0.2801533821002904,0.2705045166654655,0.2621732988389821,0.2544402521360274,0.24692651649542763,0.23852302159968222,0.2377000111921171,0.24021215380562996,0.25745292158228555,0.28246981156766604,0.2788528172416958,0.2691341863224083,0.2608047599724897,0.2531177204238531,0.24522072966186015,0.23714772748746007,0.23769760524252156,0.24013146943999863,0.2565716571327042,0.28167778484601086,0.2775583677854948,0.26776340018714184,0.2595108806732881,0.2517857226396959,0.243851974956409,0.23573175704015634,0.23764403194033482,0.24007626519161868,0.25570300894480436,0.280897115160905,0.27626940891764706,0.2663816853537976,0.2581520922068315,0.2504519636807333,0.2424566482706013,0.23439691927858314,0.2375392614922677,0.24034874879873427,0.2548461809449697,0.2801238039832656,0.27498316595970207,0.26500334034335515,0.25678921373704733,0.2490982019599679,0.24103767716664806,0.23443111551213983,0.2375182826754282,0.24057081862118906,0.2540004309140314,0.27935652380193227,0.27370464312659204,0.26362610558020905,0.2554176533225424,0.24773317033000852,0.23959672904620014,0.2344172100967371,0.23748695145332757,0.24031963521280403,0.25316506658128285,0.2785962305380959,0.2724287720095464,0.26224986075888035,0.25404721864535684,0.24636033418249095,0.23813607235973674,0.234442919992138,0.23741190053917946,0.2397258835018143,0.25233944202679026,0.27783898647152383,0.27115159416136647,0.2608772674188802,0.2526732190309514,0.24497843573229777,0.23665164852051349,0.23438956161655358,0.2372889439701884,0.23910429059780186,0.25152295436590855,0.27709092249139816,0.2698820879479411,0.2595815185380185,0.2512962051922632,0.2435860801578002,0.23514900273074985,0.23428063769303617,0.23711121812642286,0.23845515006983115,0.2507150406922104,0.27634672446857383,0.26862841212868704,0.2583597358863471,0.24991601547620923,0.2421873467697457,0.2338517067754975,0.23413627559464664,0.23697174644452706,0.23777831307779268,0.24991517525711587,0.2756070652027483,0.2673656156297818,0.25713625320557365,0.2485318869429736,0.24078141651416238,0.23271344774626324,0.23395892833253928,0.23708370848480406,0.2370739291669965,0.24912286686641444,0.2748707930508215,0.2661108854144937,0.2559111441251971,0.24714639249152603,0.23935847405934316,0.23155910366542934,0.23375430105194453,0.2371656168067039,0.23634212484897463,0.24833765647569145,0.274136534389931,0.2648581980615375,0.2546812346412056,0.24598867756724968,0.23811541479146509,0.23037663621856674,0.23360957502179067,0.23707367260240722,0.23557742116899708,0.24755911496810568,0.27340868096172144,0.263765624257447,0.25345362950939615,0.24489408444983984,0.2369708370658392,0.22995898200782106,0.233467030645677,0.23640634005833672,0.23479109699054027,0.2467868410995977,0.27268407189855143,0.2626843754716899,0.25222502319696427,0.24379465366496045,0.23582334631462698,0.2298155756042545,0.23329638764984462,0.23571731801599272,0.2339774713908084,0.24602045959775948,0.2719615765722503,0.26160206075243364,0.25099566779454946,0.24268959253663502,0.2346517826119582,0.22964655651202825,0.23311191154508384,0.23500493144996085,0.23313654105039297,0.24525961940188296,0.27124273320486547,0.260524133124968,0.24983310315956164,0.24158979480656884,0.2334735112236942,0.2295022834057782,0.2328801611770176,0.2342635069310654,0.2322684519321252,0.24450399203279044,0.27052372154537263,0.2594452872824339,0.2487237403967847,0.24047681886714065,0.23228416466421625,0.22932455395311588,0.2326210779219924,0.2335047211313725,0.23137325396598896,0.24375327008201397,0.2698090031082441,0.25837027162816595,0.2476119533282478,0.23935996423233058,0.23108207548165147,0.2291199428213735,0.2323376780692718,0.2327228951847132,0.23045099076106373,0.24300716581078485,0.26909735646043786,0.2572971474673519,0.2465015773646173,0.23823894686311284,0.22987160208435875,0.22887643339380115,0.2322824216396421,0.23191808610751194,0.22950169662197115,0.24226540985013945,0.2682501402506884,0.2562233117683984,0.24539278002657716,0.2371127701986306,0.22864890081938877,0.22858454112149207,0.23220626138189232,0.2310903413443238,0.22852543339870365,0.24152774999418075,0.267246133306323,0.2551530696143166,0.24434457153489453,0.23598406267615266,0.22753238303250387,0.228270546874152,0.23210789829518097,0.23023963617701365,0.22752224299891383,0.24079395007921517,0.26623990242925466,0.25408250687003137,0.24329025267035967,0.2348519748540457,0.2265622104079917,0.22793301394476811,0.23163841637970273,0.22936614867179597,0.22649217409778039,0.24006378894210278,0.2652356065125817,0.2530159861206287,0.24223804802690435,0.23371660695827925,0.22558239110516204,0.2276732309496187,0.23088021257125335,0.22846990094716593,0.2254352721784397,0.239337059451652,0.2642037833702381,0.2519489550180636,0.24118370252785937,0.23257676962810658,0.2245892514159109,0.22740106894890205,0.2301029489460705,0.22755105112543508,0.2243515824130055,0.23861356760755392,0.26316306924945343,0.2508835179203307,0.24010861245352375,0.2314344599563052,0.22358533943163375,0.2270997309759111,0.2293016767493223,0.22660968394507183,0.2232412758494557,0.2378931317016632,0.2621252555121326,0.24981909867067378,0.23900541428921301,0.23028911192756402,0.2228773869426554,0.22679860711657998,0.22848681508973126,0.2256458736334698,0.22210460783799885,0.23717558153692925,0.26109027013943187,0.2487562993278893,0.23790172932417794,0.22914033901619185,0.22257762691762725,0.22646110334487077,0.22765311985879724,0.2246596937614626,0.22094130978795776,0.23646075769961977,0.26005705525168143,0.24769964572767877,0.23679746184077052,0.2280916796541693,0.22225271751634873,0.2261049374851403,0.22680076818939693,0.2236512124038704,0.21975150639340632,0.23574851088096233,0.25902750542308617,0.2466442735057487,0.23569196444452797,0.22711240310195954,0.2219388456978817,0.22573015562037127,0.2259299183042539,0.22262062952356243,0.21853411214980112,0.235038701244422,0.25800065332310973,0.24558997600016674,0.23458669655244632,0.226127307255798,0.22162845833861097,0.22534037062166862,0.22503982910027803,0.22156791351012595,0.21729001616704186,0.23433119783538114,0.2569736235384691,0.24446402343426496,0.2334810909123537,0.22513403718174232,0.22129446581559942,0.22506036728725845,0.22413214892891878,0.22049113076924795,0.2160204978340471,0.2336258780300164,0.25595214743461236,0.24332937506479055,0.23237493532668074,0.22414459957064967,0.2209408795592535,0.2248309453246207,0.22320620252851492,0.21939418742212796,0.21472454988674547,0.2329226270206584,0.2549332936107202,0.24219333328678286,0.231342204731542,0.2231404126431985,0.22057279539323218,0.2245892906931705,0.22226104443294364,0.21827532565213514,0.21339313769837523,0.232221337334869,0.2539160383440263,0.24106515981607246,0.23033912117236188,0.2221321590353157,0.22018776179498478,0.22431713382368776,0.22129867719877364,0.2171199303367233,0.21192715071741222,0.23152190838595738,0.2529064168026858,0.23992859105601588,0.22934898298031517,0.22111811944306645,0.21978932510285773,0.2237742468970932,0.22028275356139324,0.21584702011721185,0.21043394599615753,0.23082424605260343,0.2518947963916527,0.23879593867457896,0.22834204276675832,0.22009753750461505,0.21935140996902658,0.22286221660913658,0.2191791150691505,0.21455182358551173,0.20891435027773755,0.23012826228562128,0.2508827175197498,0.23766114005309044,0.22733339637893143,0.21899511280954106,0.21882020448477552,0.22190227693827758,0.21805766412062652,0.2132350004079584,0.20736840822955138,0.22943387473985805,0.24987599951978456,0.23653042937013585,0.22632297257329334,0.2178737779264929,0.21830154546557456,0.22093254120824202,0.21691862316376623,0.21189662352251423,0.2057979229766531,0.2287410064296117,0.24887161425853907,0.23540099704561876,0.2253104977487856,0.2167449370228377,0.2177906680291173,0.21994851252579195,0.21576207565606403,0.21053676912461286,0.2041995116868092,0.22804958540580572,0.24786952504155635,0.23427276178586726,0.2242962629572279,0.21578118632547125,0.21726872259939423,0.21895029192307988,0.2145881182590051,0.20915550998172072,0.2027192108967354,0.22735954445354228,0.2468689053763061,0.2331456136407709,0.22327906997786198,0.21481340741796928,0.2167422431854911,0.21793807753440325,0.21339684338009346,0.20775291855845243,0.20124192050716297,0.2266708208085602,0.24587135895379375,0.23201612575266622,0.22226106170288418,0.21383720217140603,0.21619270824302872,0.2169119752343499,0.2121883397956713,0.20632906701799575,0.19974004088946104,0.22598335589136465,0.2448760189844276,0.2308912022478183,0.2212413348619404,0.21285751429820582,0.21563205005654776,0.21587208168035166,0.21096269574051632,0.20488402587766957,0.19821347117884255,0.22529709505783901,0.24388017554539956,0.22977346119142103,0.2202119145747786,0.211870816831303,0.2150591755034237,0.2148184572193179,0.20972001867158085,0.2034178677373325,0.1966627374322525,0.22461198736518823,0.24288934174711063,0.2286658870648056,0.21918890797736376,0.21087969588050598,0.21447473408937226,0.2137511909979565,0.20846049961855795,0.20193066412438448,0.19508775961610525,0.22392798535225233,0.24190061435141635,0.22755940129194138,0.2181643015348554,0.20988913783917595,0.21387817186483543,0.2126704076696847,0.2071842707844332,0.20042248601100351,0.19348826582179426,0.22324504483320684,0.2409139668387773,0.2264635300264244,0.21713703804608406,0.20933644091660625,0.21327391486092595,0.2115761475401686,0.205891249612478,0.19892742129551913,0.1918644505168786,0.2225631247037847,0.23992863088170935,0.2253977052488984,0.21610883960294638,0.20875942141000545,0.2126535200454133,0.21046856387726767,0.20458152165909263,0.19752969838662368,0.19021634465177006,0.22188218675919438,0.23894609332211078,0.22437583793955537,0.21507932023812473,0.2081956113111417,0.21214720535766393,0.20934775369324557,0.20325516693955126,0.19611228188415636,0.18854401302375726]},{\"line\":{\"color\":\"rgba(255, 153, 51, 1.0)\",\"dash\":\"solid\",\"shape\":\"linear\",\"width\":1.3},\"mode\":\"lines\",\"name\":\"std\",\"text\":\"\",\"type\":\"scatter\",\"x\":[\"(0.1,0.0)\",\"(0.1,0.1)\",\"(0.1,0.2)\",\"(0.1,0.3)\",\"(0.1,0.4)\",\"(0.1,0.5)\",\"(0.1,0.6)\",\"(0.1,0.7)\",\"(0.1,0.8)\",\"(0.1,0.9)\",\"(0.2,0.0)\",\"(0.2,0.1)\",\"(0.2,0.2)\",\"(0.2,0.3)\",\"(0.2,0.4)\",\"(0.2,0.5)\",\"(0.2,0.6)\",\"(0.2,0.7)\",\"(0.2,0.8)\",\"(0.2,0.9)\",\"(0.3,0.0)\",\"(0.3,0.1)\",\"(0.3,0.2)\",\"(0.3,0.3)\",\"(0.3,0.4)\",\"(0.3,0.5)\",\"(0.3,0.6)\",\"(0.3,0.7)\",\"(0.3,0.8)\",\"(0.3,0.9)\",\"(0.4,0.0)\",\"(0.4,0.1)\",\"(0.4,0.2)\",\"(0.4,0.3)\",\"(0.4,0.4)\",\"(0.4,0.5)\",\"(0.4,0.6)\",\"(0.4,0.7)\",\"(0.4,0.8)\",\"(0.4,0.9)\",\"(0.5,0.0)\",\"(0.5,0.1)\",\"(0.5,0.2)\",\"(0.5,0.3)\",\"(0.5,0.4)\",\"(0.5,0.5)\",\"(0.5,0.6)\",\"(0.5,0.7)\",\"(0.5,0.8)\",\"(0.5,0.9)\",\"(0.6,0.0)\",\"(0.6,0.1)\",\"(0.6,0.2)\",\"(0.6,0.3)\",\"(0.6,0.4)\",\"(0.6,0.5)\",\"(0.6,0.6)\",\"(0.6,0.7)\",\"(0.6,0.8)\",\"(0.6,0.9)\",\"(0.7,0.0)\",\"(0.7,0.1)\",\"(0.7,0.2)\",\"(0.7,0.3)\",\"(0.7,0.4)\",\"(0.7,0.5)\",\"(0.7,0.6)\",\"(0.7,0.7)\",\"(0.7,0.8)\",\"(0.7,0.9)\",\"(0.8,0.0)\",\"(0.8,0.1)\",\"(0.8,0.2)\",\"(0.8,0.3)\",\"(0.8,0.4)\",\"(0.8,0.5)\",\"(0.8,0.6)\",\"(0.8,0.7)\",\"(0.8,0.8)\",\"(0.8,0.9)\",\"(0.9,0.0)\",\"(0.9,0.1)\",\"(0.9,0.2)\",\"(0.9,0.3)\",\"(0.9,0.4)\",\"(0.9,0.5)\",\"(0.9,0.6)\",\"(0.9,0.7)\",\"(0.9,0.8)\",\"(0.9,0.9)\",\"(1.0,0.0)\",\"(1.0,0.1)\",\"(1.0,0.2)\",\"(1.0,0.3)\",\"(1.0,0.4)\",\"(1.0,0.5)\",\"(1.0,0.6)\",\"(1.0,0.7)\",\"(1.0,0.8)\",\"(1.0,0.9)\",\"(1.1,0.0)\",\"(1.1,0.1)\",\"(1.1,0.2)\",\"(1.1,0.3)\",\"(1.1,0.4)\",\"(1.1,0.5)\",\"(1.1,0.6)\",\"(1.1,0.7)\",\"(1.1,0.8)\",\"(1.1,0.9)\",\"(1.2,0.0)\",\"(1.2,0.1)\",\"(1.2,0.2)\",\"(1.2,0.3)\",\"(1.2,0.4)\",\"(1.2,0.5)\",\"(1.2,0.6)\",\"(1.2,0.7)\",\"(1.2,0.8)\",\"(1.2,0.9)\",\"(1.3,0.0)\",\"(1.3,0.1)\",\"(1.3,0.2)\",\"(1.3,0.3)\",\"(1.3,0.4)\",\"(1.3,0.5)\",\"(1.3,0.6)\",\"(1.3,0.7)\",\"(1.3,0.8)\",\"(1.3,0.9)\",\"(1.4,0.0)\",\"(1.4,0.1)\",\"(1.4,0.2)\",\"(1.4,0.3)\",\"(1.4,0.4)\",\"(1.4,0.5)\",\"(1.4,0.6)\",\"(1.4,0.7)\",\"(1.4,0.8)\",\"(1.4,0.9)\",\"(1.5,0.0)\",\"(1.5,0.1)\",\"(1.5,0.2)\",\"(1.5,0.3)\",\"(1.5,0.4)\",\"(1.5,0.5)\",\"(1.5,0.6)\",\"(1.5,0.7)\",\"(1.5,0.8)\",\"(1.5,0.9)\",\"(1.6,0.0)\",\"(1.6,0.1)\",\"(1.6,0.2)\",\"(1.6,0.3)\",\"(1.6,0.4)\",\"(1.6,0.5)\",\"(1.6,0.6)\",\"(1.6,0.7)\",\"(1.6,0.8)\",\"(1.6,0.9)\",\"(1.7,0.0)\",\"(1.7,0.1)\",\"(1.7,0.2)\",\"(1.7,0.3)\",\"(1.7,0.4)\",\"(1.7,0.5)\",\"(1.7,0.6)\",\"(1.7,0.7)\",\"(1.7,0.8)\",\"(1.7,0.9)\",\"(1.8,0.0)\",\"(1.8,0.1)\",\"(1.8,0.2)\",\"(1.8,0.3)\",\"(1.8,0.4)\",\"(1.8,0.5)\",\"(1.8,0.6)\",\"(1.8,0.7)\",\"(1.8,0.8)\",\"(1.8,0.9)\",\"(1.9,0.0)\",\"(1.9,0.1)\",\"(1.9,0.2)\",\"(1.9,0.3)\",\"(1.9,0.4)\",\"(1.9,0.5)\",\"(1.9,0.6)\",\"(1.9,0.7)\",\"(1.9,0.8)\",\"(1.9,0.9)\",\"(2.0,0.0)\",\"(2.0,0.1)\",\"(2.0,0.2)\",\"(2.0,0.3)\",\"(2.0,0.4)\",\"(2.0,0.5)\",\"(2.0,0.6)\",\"(2.0,0.7)\",\"(2.0,0.8)\",\"(2.0,0.9)\",\"(2.1,0.0)\",\"(2.1,0.1)\",\"(2.1,0.2)\",\"(2.1,0.3)\",\"(2.1,0.4)\",\"(2.1,0.5)\",\"(2.1,0.6)\",\"(2.1,0.7)\",\"(2.1,0.8)\",\"(2.1,0.9)\",\"(2.2,0.0)\",\"(2.2,0.1)\",\"(2.2,0.2)\",\"(2.2,0.3)\",\"(2.2,0.4)\",\"(2.2,0.5)\",\"(2.2,0.6)\",\"(2.2,0.7)\",\"(2.2,0.8)\",\"(2.2,0.9)\",\"(2.3,0.0)\",\"(2.3,0.1)\",\"(2.3,0.2)\",\"(2.3,0.3)\",\"(2.3,0.4)\",\"(2.3,0.5)\",\"(2.3,0.6)\",\"(2.3,0.7)\",\"(2.3,0.8)\",\"(2.3,0.9)\",\"(2.4,0.0)\",\"(2.4,0.1)\",\"(2.4,0.2)\",\"(2.4,0.3)\",\"(2.4,0.4)\",\"(2.4,0.5)\",\"(2.4,0.6)\",\"(2.4,0.7)\",\"(2.4,0.8)\",\"(2.4,0.9)\",\"(2.5,0.0)\",\"(2.5,0.1)\",\"(2.5,0.2)\",\"(2.5,0.3)\",\"(2.5,0.4)\",\"(2.5,0.5)\",\"(2.5,0.6)\",\"(2.5,0.7)\",\"(2.5,0.8)\",\"(2.5,0.9)\",\"(2.6,0.0)\",\"(2.6,0.1)\",\"(2.6,0.2)\",\"(2.6,0.3)\",\"(2.6,0.4)\",\"(2.6,0.5)\",\"(2.6,0.6)\",\"(2.6,0.7)\",\"(2.6,0.8)\",\"(2.6,0.9)\",\"(2.7,0.0)\",\"(2.7,0.1)\",\"(2.7,0.2)\",\"(2.7,0.3)\",\"(2.7,0.4)\",\"(2.7,0.5)\",\"(2.7,0.6)\",\"(2.7,0.7)\",\"(2.7,0.8)\",\"(2.7,0.9)\",\"(2.8,0.0)\",\"(2.8,0.1)\",\"(2.8,0.2)\",\"(2.8,0.3)\",\"(2.8,0.4)\",\"(2.8,0.5)\",\"(2.8,0.6)\",\"(2.8,0.7)\",\"(2.8,0.8)\",\"(2.8,0.9)\",\"(2.9,0.0)\",\"(2.9,0.1)\",\"(2.9,0.2)\",\"(2.9,0.3)\",\"(2.9,0.4)\",\"(2.9,0.5)\",\"(2.9,0.6)\",\"(2.9,0.7)\",\"(2.9,0.8)\",\"(2.9,0.9)\",\"(3.0,0.0)\",\"(3.0,0.1)\",\"(3.0,0.2)\",\"(3.0,0.3)\",\"(3.0,0.4)\",\"(3.0,0.5)\",\"(3.0,0.6)\",\"(3.0,0.7)\",\"(3.0,0.8)\",\"(3.0,0.9)\",\"(3.1,0.0)\",\"(3.1,0.1)\",\"(3.1,0.2)\",\"(3.1,0.3)\",\"(3.1,0.4)\",\"(3.1,0.5)\",\"(3.1,0.6)\",\"(3.1,0.7)\",\"(3.1,0.8)\",\"(3.1,0.9)\",\"(3.2,0.0)\",\"(3.2,0.1)\",\"(3.2,0.2)\",\"(3.2,0.3)\",\"(3.2,0.4)\",\"(3.2,0.5)\",\"(3.2,0.6)\",\"(3.2,0.7)\",\"(3.2,0.8)\",\"(3.2,0.9)\",\"(3.3,0.0)\",\"(3.3,0.1)\",\"(3.3,0.2)\",\"(3.3,0.3)\",\"(3.3,0.4)\",\"(3.3,0.5)\",\"(3.3,0.6)\",\"(3.3,0.7)\",\"(3.3,0.8)\",\"(3.3,0.9)\",\"(3.4,0.0)\",\"(3.4,0.1)\",\"(3.4,0.2)\",\"(3.4,0.3)\",\"(3.4,0.4)\",\"(3.4,0.5)\",\"(3.4,0.6)\",\"(3.4,0.7)\",\"(3.4,0.8)\",\"(3.4,0.9)\",\"(3.5,0.0)\",\"(3.5,0.1)\",\"(3.5,0.2)\",\"(3.5,0.3)\",\"(3.5,0.4)\",\"(3.5,0.5)\",\"(3.5,0.6)\",\"(3.5,0.7)\",\"(3.5,0.8)\",\"(3.5,0.9)\",\"(3.6,0.0)\",\"(3.6,0.1)\",\"(3.6,0.2)\",\"(3.6,0.3)\",\"(3.6,0.4)\",\"(3.6,0.5)\",\"(3.6,0.6)\",\"(3.6,0.7)\",\"(3.6,0.8)\",\"(3.6,0.9)\",\"(3.7,0.0)\",\"(3.7,0.1)\",\"(3.7,0.2)\",\"(3.7,0.3)\",\"(3.7,0.4)\",\"(3.7,0.5)\",\"(3.7,0.6)\",\"(3.7,0.7)\",\"(3.7,0.8)\",\"(3.7,0.9)\",\"(3.8,0.0)\",\"(3.8,0.1)\",\"(3.8,0.2)\",\"(3.8,0.3)\",\"(3.8,0.4)\",\"(3.8,0.5)\",\"(3.8,0.6)\",\"(3.8,0.7)\",\"(3.8,0.8)\",\"(3.8,0.9)\",\"(3.9,0.0)\",\"(3.9,0.1)\",\"(3.9,0.2)\",\"(3.9,0.3)\",\"(3.9,0.4)\",\"(3.9,0.5)\",\"(3.9,0.6)\",\"(3.9,0.7)\",\"(3.9,0.8)\",\"(3.9,0.9)\",\"(4.0,0.0)\",\"(4.0,0.1)\",\"(4.0,0.2)\",\"(4.0,0.3)\",\"(4.0,0.4)\",\"(4.0,0.5)\",\"(4.0,0.6)\",\"(4.0,0.7)\",\"(4.0,0.8)\",\"(4.0,0.9)\",\"(4.1,0.0)\",\"(4.1,0.1)\",\"(4.1,0.2)\",\"(4.1,0.3)\",\"(4.1,0.4)\",\"(4.1,0.5)\",\"(4.1,0.6)\",\"(4.1,0.7)\",\"(4.1,0.8)\",\"(4.1,0.9)\",\"(4.2,0.0)\",\"(4.2,0.1)\",\"(4.2,0.2)\",\"(4.2,0.3)\",\"(4.2,0.4)\",\"(4.2,0.5)\",\"(4.2,0.6)\",\"(4.2,0.7)\",\"(4.2,0.8)\",\"(4.2,0.9)\",\"(4.3,0.0)\",\"(4.3,0.1)\",\"(4.3,0.2)\",\"(4.3,0.3)\",\"(4.3,0.4)\",\"(4.3,0.5)\",\"(4.3,0.6)\",\"(4.3,0.7)\",\"(4.3,0.8)\",\"(4.3,0.9)\",\"(4.4,0.0)\",\"(4.4,0.1)\",\"(4.4,0.2)\",\"(4.4,0.3)\",\"(4.4,0.4)\",\"(4.4,0.5)\",\"(4.4,0.6)\",\"(4.4,0.7)\",\"(4.4,0.8)\",\"(4.4,0.9)\",\"(4.5,0.0)\",\"(4.5,0.1)\",\"(4.5,0.2)\",\"(4.5,0.3)\",\"(4.5,0.4)\",\"(4.5,0.5)\",\"(4.5,0.6)\",\"(4.5,0.7)\",\"(4.5,0.8)\",\"(4.5,0.9)\",\"(4.6,0.0)\",\"(4.6,0.1)\",\"(4.6,0.2)\",\"(4.6,0.3)\",\"(4.6,0.4)\",\"(4.6,0.5)\",\"(4.6,0.6)\",\"(4.6,0.7)\",\"(4.6,0.8)\",\"(4.6,0.9)\",\"(4.7,0.0)\",\"(4.7,0.1)\",\"(4.7,0.2)\",\"(4.7,0.3)\",\"(4.7,0.4)\",\"(4.7,0.5)\",\"(4.7,0.6)\",\"(4.7,0.7)\",\"(4.7,0.8)\",\"(4.7,0.9)\",\"(4.8,0.0)\",\"(4.8,0.1)\",\"(4.8,0.2)\",\"(4.8,0.3)\",\"(4.8,0.4)\",\"(4.8,0.5)\",\"(4.8,0.6)\",\"(4.8,0.7)\",\"(4.8,0.8)\",\"(4.8,0.9)\",\"(4.9,0.0)\",\"(4.9,0.1)\",\"(4.9,0.2)\",\"(4.9,0.3)\",\"(4.9,0.4)\",\"(4.9,0.5)\",\"(4.9,0.6)\",\"(4.9,0.7)\",\"(4.9,0.8)\",\"(4.9,0.9)\",\"(5.0,0.0)\",\"(5.0,0.1)\",\"(5.0,0.2)\",\"(5.0,0.3)\",\"(5.0,0.4)\",\"(5.0,0.5)\",\"(5.0,0.6)\",\"(5.0,0.7)\",\"(5.0,0.8)\",\"(5.0,0.9)\",\"(5.1,0.0)\",\"(5.1,0.1)\",\"(5.1,0.2)\",\"(5.1,0.3)\",\"(5.1,0.4)\",\"(5.1,0.5)\",\"(5.1,0.6)\",\"(5.1,0.7)\",\"(5.1,0.8)\",\"(5.1,0.9)\",\"(5.2,0.0)\",\"(5.2,0.1)\",\"(5.2,0.2)\",\"(5.2,0.3)\",\"(5.2,0.4)\",\"(5.2,0.5)\",\"(5.2,0.6)\",\"(5.2,0.7)\",\"(5.2,0.8)\",\"(5.2,0.9)\",\"(5.3,0.0)\",\"(5.3,0.1)\",\"(5.3,0.2)\",\"(5.3,0.3)\",\"(5.3,0.4)\",\"(5.3,0.5)\",\"(5.3,0.6)\",\"(5.3,0.7)\",\"(5.3,0.8)\",\"(5.3,0.9)\",\"(5.4,0.0)\",\"(5.4,0.1)\",\"(5.4,0.2)\",\"(5.4,0.3)\",\"(5.4,0.4)\",\"(5.4,0.5)\",\"(5.4,0.6)\",\"(5.4,0.7)\",\"(5.4,0.8)\",\"(5.4,0.9)\",\"(5.5,0.0)\",\"(5.5,0.1)\",\"(5.5,0.2)\",\"(5.5,0.3)\",\"(5.5,0.4)\",\"(5.5,0.5)\",\"(5.5,0.6)\",\"(5.5,0.7)\",\"(5.5,0.8)\",\"(5.5,0.9)\",\"(5.6,0.0)\",\"(5.6,0.1)\",\"(5.6,0.2)\",\"(5.6,0.3)\",\"(5.6,0.4)\",\"(5.6,0.5)\",\"(5.6,0.6)\",\"(5.6,0.7)\",\"(5.6,0.8)\",\"(5.6,0.9)\",\"(5.7,0.0)\",\"(5.7,0.1)\",\"(5.7,0.2)\",\"(5.7,0.3)\",\"(5.7,0.4)\",\"(5.7,0.5)\",\"(5.7,0.6)\",\"(5.7,0.7)\",\"(5.7,0.8)\",\"(5.7,0.9)\",\"(5.8,0.0)\",\"(5.8,0.1)\",\"(5.8,0.2)\",\"(5.8,0.3)\",\"(5.8,0.4)\",\"(5.8,0.5)\",\"(5.8,0.6)\",\"(5.8,0.7)\",\"(5.8,0.8)\",\"(5.8,0.9)\",\"(5.9,0.0)\",\"(5.9,0.1)\",\"(5.9,0.2)\",\"(5.9,0.3)\",\"(5.9,0.4)\",\"(5.9,0.5)\",\"(5.9,0.6)\",\"(5.9,0.7)\",\"(5.9,0.8)\",\"(5.9,0.9)\",\"(6.0,0.0)\",\"(6.0,0.1)\",\"(6.0,0.2)\",\"(6.0,0.3)\",\"(6.0,0.4)\",\"(6.0,0.5)\",\"(6.0,0.6)\",\"(6.0,0.7)\",\"(6.0,0.8)\",\"(6.0,0.9)\",\"(6.1,0.0)\",\"(6.1,0.1)\",\"(6.1,0.2)\",\"(6.1,0.3)\",\"(6.1,0.4)\",\"(6.1,0.5)\",\"(6.1,0.6)\",\"(6.1,0.7)\",\"(6.1,0.8)\",\"(6.1,0.9)\",\"(6.2,0.0)\",\"(6.2,0.1)\",\"(6.2,0.2)\",\"(6.2,0.3)\",\"(6.2,0.4)\",\"(6.2,0.5)\",\"(6.2,0.6)\",\"(6.2,0.7)\",\"(6.2,0.8)\",\"(6.2,0.9)\",\"(6.3,0.0)\",\"(6.3,0.1)\",\"(6.3,0.2)\",\"(6.3,0.3)\",\"(6.3,0.4)\",\"(6.3,0.5)\",\"(6.3,0.6)\",\"(6.3,0.7)\",\"(6.3,0.8)\",\"(6.3,0.9)\",\"(6.4,0.0)\",\"(6.4,0.1)\",\"(6.4,0.2)\",\"(6.4,0.3)\",\"(6.4,0.4)\",\"(6.4,0.5)\",\"(6.4,0.6)\",\"(6.4,0.7)\",\"(6.4,0.8)\",\"(6.4,0.9)\",\"(6.5,0.0)\",\"(6.5,0.1)\",\"(6.5,0.2)\",\"(6.5,0.3)\",\"(6.5,0.4)\",\"(6.5,0.5)\",\"(6.5,0.6)\",\"(6.5,0.7)\",\"(6.5,0.8)\",\"(6.5,0.9)\",\"(6.6,0.0)\",\"(6.6,0.1)\",\"(6.6,0.2)\",\"(6.6,0.3)\",\"(6.6,0.4)\",\"(6.6,0.5)\",\"(6.6,0.6)\",\"(6.6,0.7)\",\"(6.6,0.8)\",\"(6.6,0.9)\",\"(6.7,0.0)\",\"(6.7,0.1)\",\"(6.7,0.2)\",\"(6.7,0.3)\",\"(6.7,0.4)\",\"(6.7,0.5)\",\"(6.7,0.6)\",\"(6.7,0.7)\",\"(6.7,0.8)\",\"(6.7,0.9)\",\"(6.8,0.0)\",\"(6.8,0.1)\",\"(6.8,0.2)\",\"(6.8,0.3)\",\"(6.8,0.4)\",\"(6.8,0.5)\",\"(6.8,0.6)\",\"(6.8,0.7)\",\"(6.8,0.8)\",\"(6.8,0.9)\",\"(6.9,0.0)\",\"(6.9,0.1)\",\"(6.9,0.2)\",\"(6.9,0.3)\",\"(6.9,0.4)\",\"(6.9,0.5)\",\"(6.9,0.6)\",\"(6.9,0.7)\",\"(6.9,0.8)\",\"(6.9,0.9)\",\"(7.0,0.0)\",\"(7.0,0.1)\",\"(7.0,0.2)\",\"(7.0,0.3)\",\"(7.0,0.4)\",\"(7.0,0.5)\",\"(7.0,0.6)\",\"(7.0,0.7)\",\"(7.0,0.8)\",\"(7.0,0.9)\",\"(7.1,0.0)\",\"(7.1,0.1)\",\"(7.1,0.2)\",\"(7.1,0.3)\",\"(7.1,0.4)\",\"(7.1,0.5)\",\"(7.1,0.6)\",\"(7.1,0.7)\",\"(7.1,0.8)\",\"(7.1,0.9)\",\"(7.2,0.0)\",\"(7.2,0.1)\",\"(7.2,0.2)\",\"(7.2,0.3)\",\"(7.2,0.4)\",\"(7.2,0.5)\",\"(7.2,0.6)\",\"(7.2,0.7)\",\"(7.2,0.8)\",\"(7.2,0.9)\",\"(7.3,0.0)\",\"(7.3,0.1)\",\"(7.3,0.2)\",\"(7.3,0.3)\",\"(7.3,0.4)\",\"(7.3,0.5)\",\"(7.3,0.6)\",\"(7.3,0.7)\",\"(7.3,0.8)\",\"(7.3,0.9)\",\"(7.4,0.0)\",\"(7.4,0.1)\",\"(7.4,0.2)\",\"(7.4,0.3)\",\"(7.4,0.4)\",\"(7.4,0.5)\",\"(7.4,0.6)\",\"(7.4,0.7)\",\"(7.4,0.8)\",\"(7.4,0.9)\",\"(7.5,0.0)\",\"(7.5,0.1)\",\"(7.5,0.2)\",\"(7.5,0.3)\",\"(7.5,0.4)\",\"(7.5,0.5)\",\"(7.5,0.6)\",\"(7.5,0.7)\",\"(7.5,0.8)\",\"(7.5,0.9)\",\"(7.6,0.0)\",\"(7.6,0.1)\",\"(7.6,0.2)\",\"(7.6,0.3)\",\"(7.6,0.4)\",\"(7.6,0.5)\",\"(7.6,0.6)\",\"(7.6,0.7)\",\"(7.6,0.8)\",\"(7.6,0.9)\",\"(7.7,0.0)\",\"(7.7,0.1)\",\"(7.7,0.2)\",\"(7.7,0.3)\",\"(7.7,0.4)\",\"(7.7,0.5)\",\"(7.7,0.6)\",\"(7.7,0.7)\",\"(7.7,0.8)\",\"(7.7,0.9)\",\"(7.8,0.0)\",\"(7.8,0.1)\",\"(7.8,0.2)\",\"(7.8,0.3)\",\"(7.8,0.4)\",\"(7.8,0.5)\",\"(7.8,0.6)\",\"(7.8,0.7)\",\"(7.8,0.8)\",\"(7.8,0.9)\",\"(7.9,0.0)\",\"(7.9,0.1)\",\"(7.9,0.2)\",\"(7.9,0.3)\",\"(7.9,0.4)\",\"(7.9,0.5)\",\"(7.9,0.6)\",\"(7.9,0.7)\",\"(7.9,0.8)\",\"(7.9,0.9)\",\"(8.0,0.0)\",\"(8.0,0.1)\",\"(8.0,0.2)\",\"(8.0,0.3)\",\"(8.0,0.4)\",\"(8.0,0.5)\",\"(8.0,0.6)\",\"(8.0,0.7)\",\"(8.0,0.8)\",\"(8.0,0.9)\",\"(8.1,0.0)\",\"(8.1,0.1)\",\"(8.1,0.2)\",\"(8.1,0.3)\",\"(8.1,0.4)\",\"(8.1,0.5)\",\"(8.1,0.6)\",\"(8.1,0.7)\",\"(8.1,0.8)\",\"(8.1,0.9)\",\"(8.2,0.0)\",\"(8.2,0.1)\",\"(8.2,0.2)\",\"(8.2,0.3)\",\"(8.2,0.4)\",\"(8.2,0.5)\",\"(8.2,0.6)\",\"(8.2,0.7)\",\"(8.2,0.8)\",\"(8.2,0.9)\",\"(8.3,0.0)\",\"(8.3,0.1)\",\"(8.3,0.2)\",\"(8.3,0.3)\",\"(8.3,0.4)\",\"(8.3,0.5)\",\"(8.3,0.6)\",\"(8.3,0.7)\",\"(8.3,0.8)\",\"(8.3,0.9)\",\"(8.4,0.0)\",\"(8.4,0.1)\",\"(8.4,0.2)\",\"(8.4,0.3)\",\"(8.4,0.4)\",\"(8.4,0.5)\",\"(8.4,0.6)\",\"(8.4,0.7)\",\"(8.4,0.8)\",\"(8.4,0.9)\",\"(8.5,0.0)\",\"(8.5,0.1)\",\"(8.5,0.2)\",\"(8.5,0.3)\",\"(8.5,0.4)\",\"(8.5,0.5)\",\"(8.5,0.6)\",\"(8.5,0.7)\",\"(8.5,0.8)\",\"(8.5,0.9)\",\"(8.6,0.0)\",\"(8.6,0.1)\",\"(8.6,0.2)\",\"(8.6,0.3)\",\"(8.6,0.4)\",\"(8.6,0.5)\",\"(8.6,0.6)\",\"(8.6,0.7)\",\"(8.6,0.8)\",\"(8.6,0.9)\",\"(8.7,0.0)\",\"(8.7,0.1)\",\"(8.7,0.2)\",\"(8.7,0.3)\",\"(8.7,0.4)\",\"(8.7,0.5)\",\"(8.7,0.6)\",\"(8.7,0.7)\",\"(8.7,0.8)\",\"(8.7,0.9)\",\"(8.8,0.0)\",\"(8.8,0.1)\",\"(8.8,0.2)\",\"(8.8,0.3)\",\"(8.8,0.4)\",\"(8.8,0.5)\",\"(8.8,0.6)\",\"(8.8,0.7)\",\"(8.8,0.8)\",\"(8.8,0.9)\",\"(8.9,0.0)\",\"(8.9,0.1)\",\"(8.9,0.2)\",\"(8.9,0.3)\",\"(8.9,0.4)\",\"(8.9,0.5)\",\"(8.9,0.6)\",\"(8.9,0.7)\",\"(8.9,0.8)\",\"(8.9,0.9)\",\"(9.0,0.0)\",\"(9.0,0.1)\",\"(9.0,0.2)\",\"(9.0,0.3)\",\"(9.0,0.4)\",\"(9.0,0.5)\",\"(9.0,0.6)\",\"(9.0,0.7)\",\"(9.0,0.8)\",\"(9.0,0.9)\",\"(9.1,0.0)\",\"(9.1,0.1)\",\"(9.1,0.2)\",\"(9.1,0.3)\",\"(9.1,0.4)\",\"(9.1,0.5)\",\"(9.1,0.6)\",\"(9.1,0.7)\",\"(9.1,0.8)\",\"(9.1,0.9)\",\"(9.2,0.0)\",\"(9.2,0.1)\",\"(9.2,0.2)\",\"(9.2,0.3)\",\"(9.2,0.4)\",\"(9.2,0.5)\",\"(9.2,0.6)\",\"(9.2,0.7)\",\"(9.2,0.8)\",\"(9.2,0.9)\",\"(9.3,0.0)\",\"(9.3,0.1)\",\"(9.3,0.2)\",\"(9.3,0.3)\",\"(9.3,0.4)\",\"(9.3,0.5)\",\"(9.3,0.6)\",\"(9.3,0.7)\",\"(9.3,0.8)\",\"(9.3,0.9)\",\"(9.4,0.0)\",\"(9.4,0.1)\",\"(9.4,0.2)\",\"(9.4,0.3)\",\"(9.4,0.4)\",\"(9.4,0.5)\",\"(9.4,0.6)\",\"(9.4,0.7)\",\"(9.4,0.8)\",\"(9.4,0.9)\",\"(9.5,0.0)\",\"(9.5,0.1)\",\"(9.5,0.2)\",\"(9.5,0.3)\",\"(9.5,0.4)\",\"(9.5,0.5)\",\"(9.5,0.6)\",\"(9.5,0.7)\",\"(9.5,0.8)\",\"(9.5,0.9)\",\"(9.6,0.0)\",\"(9.6,0.1)\",\"(9.6,0.2)\",\"(9.6,0.3)\",\"(9.6,0.4)\",\"(9.6,0.5)\",\"(9.6,0.6)\",\"(9.6,0.7)\",\"(9.6,0.8)\",\"(9.6,0.9)\",\"(9.7,0.0)\",\"(9.7,0.1)\",\"(9.7,0.2)\",\"(9.7,0.3)\",\"(9.7,0.4)\",\"(9.7,0.5)\",\"(9.7,0.6)\",\"(9.7,0.7)\",\"(9.7,0.8)\",\"(9.7,0.9)\",\"(9.8,0.0)\",\"(9.8,0.1)\",\"(9.8,0.2)\",\"(9.8,0.3)\",\"(9.8,0.4)\",\"(9.8,0.5)\",\"(9.8,0.6)\",\"(9.8,0.7)\",\"(9.8,0.8)\",\"(9.8,0.9)\",\"(9.9,0.0)\",\"(9.9,0.1)\",\"(9.9,0.2)\",\"(9.9,0.3)\",\"(9.9,0.4)\",\"(9.9,0.5)\",\"(9.9,0.6)\",\"(9.9,0.7)\",\"(9.9,0.8)\",\"(9.9,0.9)\"],\"y\":[0.4728801335387184,0.4817013661854827,0.49130631122243845,0.501960035718716,0.5134629445044958,0.5266456402171696,0.541715129587993,0.5587254576359675,0.5780724374864337,0.5937760142653865,0.4074131514110777,0.41698345925795494,0.4278142386198395,0.4406446445556819,0.45556509916103416,0.47251120836132093,0.48789593023103794,0.505766996763168,0.5255089015038684,0.5499682970645737,0.3759114894846676,0.38610406164214794,0.3980989654990603,0.4121933780588476,0.4275740673360826,0.44274442143852233,0.46035720595844576,0.48138027840632713,0.5065972781060857,0.5372115999300027,0.35931880860761956,0.3710302632826347,0.3850480243406514,0.4013994811703531,0.4174177292249497,0.43586189992260366,0.45749805414712813,0.47818103038765586,0.49942272745460675,0.5287132942033976,0.35007221054600424,0.36409145488982203,0.38099406737446134,0.3997874325588472,0.41064084354043656,0.41740195394443586,0.42659192715539335,0.43948037309675414,0.45759825915297214,0.48440266347101557,0.3447106686354988,0.3615694501044995,0.38058555445333075,0.38354914406520546,0.386531763166403,0.3909304896739723,0.39751239245055026,0.40720794036417757,0.421755319511681,0.4446166486183859,0.341486008430782,0.36150022927515907,0.36513104448558925,0.36552024647341247,0.3667603856557223,0.36907354481210936,0.37318169187327555,0.3797616682095927,0.39035133998508187,0.41060093276907333,0.3394518054293826,0.3499601288716105,0.3513899296766789,0.3504369876506036,0.35007856002464444,0.35061316617503213,0.35237249398104503,0.35600292235581243,0.3642989772970664,0.38008954087962477,0.33807023825551585,0.3397407989481586,0.339550091807832,0.3374275975767637,0.33567676006033803,0.3345807965280686,0.33422437780098024,0.3357941448687687,0.34127005384335884,0.3524961530341147,0.33702560865388637,0.33074044363551247,0.32913929989465573,0.32599320146772476,0.32306293721631,0.3204213652089897,0.3181540418854769,0.3182516444719985,0.3206681329107283,0.32746926824394473,0.33612908790239715,0.3226695438438544,0.31984922728110016,0.3157513484665927,0.3117400575849003,0.307715064272473,0.30427162662550755,0.30250016187343126,0.30196192240147585,0.30455967247381516,0.3352671059617416,0.31532507285367234,0.3114377545643648,0.3064749956348863,0.3014637954663352,0.2961875708577287,0.2918190667633584,0.2881261795010447,0.28499589536708037,0.2835559787606079,0.33437202767876567,0.3085765050073532,0.30373235880074434,0.2980017774929314,0.2920087686411077,0.28561865178063994,0.280304626939876,0.2749523967341846,0.26961880534305893,0.26468960779647355,0.333404838439939,0.3023135134683635,0.29659850504583,0.2901472828837048,0.2832513548194423,0.2761327349574763,0.2696699130459248,0.2628213962999806,0.25548221931131965,0.2477182938923026,0.33234459680722117,0.29901063987127885,0.2899306095955534,0.28280854002400185,0.2750301707198551,0.2672967535770442,0.2597727307348578,0.2516099113432252,0.24259933430208044,0.23217552000485694,0.33118184556594993,0.2959133584754912,0.28367961657455054,0.275843106637014,0.2673147011418287,0.2590144677026055,0.25051526611091074,0.24118030571898616,0.2307747257388411,0.219322976254482,0.3299144123809765,0.2928031541791328,0.2777548556932979,0.26927650478686266,0.260005762071577,0.25119808402288274,0.2418249876549058,0.2314491711447608,0.2197517457942704,0.20790380997723384,0.32854469183145,0.28963946691258297,0.27213531752693587,0.263043993406068,0.2531427583035185,0.24378749536621286,0.2336238491043161,0.22241340390426256,0.2100334278482492,0.197461336168777,0.3270778665544832,0.2863943334697499,0.2667901669775465,0.25711344643300543,0.24677470088786474,0.23676951039218486,0.22584721627495877,0.21383514376127816,0.20133131565105242,0.18782534164448678,0.3255207349786583,0.28312602502425094,0.2616789690805543,0.25142964944216706,0.24067438116909498,0.23006870953519953,0.21844146887587965,0.20569128312972149,0.19312265012904564,0.1801637768741747,0.32388093698288956,0.2798561100846484,0.25677052463188726,0.2460004047877978,0.23486422385910394,0.22363422537860195,0.21146694880085518,0.1983181915902571,0.18531762728038928,0.1735592852848735,0.322166443890135,0.27657889350563086,0.2520701643398048,0.2407848241225855,0.2292809952979453,0.2174874288731058,0.20477238311229332,0.19148834513849625,0.17786188193318694,0.16756021622428577,0.3203852257759628,0.2733086417655281,0.2475472707144828,0.2357697316202463,0.2239058055396223,0.21158508140600815,0.19831379687547665,0.18493892929853256,0.1716226880490956,0.1616541949778803,0.31854503855761096,0.27005962003477463,0.24319352150704912,0.23091742993348371,0.2186980756246856,0.20591043027591666,0.1921187163753747,0.1786226820139732,0.16587140388658542,0.15583065318685943,0.3166532923366081,0.2668134336940405,0.23899429039176842,0.22625170398478864,0.21369834895583512,0.2004763011886492,0.18634465966589422,0.17252374796523404,0.16066468838384082,0.15010238091129083,0.3147169749198814,0.26357462187392966,0.23491978242233247,0.22173799898579416,0.2088673450681807,0.19523217252312522,0.18094334661144876,0.16663029131078022,0.15553342733381953,0.144509240615076,0.3127426127161931,0.2603481073985881,0.23099034003542834,0.21741113778124954,0.2041961811545883,0.19015572360414124,0.1757082015974619,0.16157986139484953,0.1504983916085242,0.13971282459592657,0.3107362567683288,0.25714052167339957,0.2271819849841278,0.21329102743226946,0.19967626301999,0.1852395597422014,0.1706285275028778,0.1567770232721188,0.14556931189357902,0.1350651547468092,0.30870348546519194,0.2539485612421555,0.22348901885268607,0.20929444440805817,0.1953012330356211,0.18045535748390318,0.16569966028303443,0.1523586945746133,0.14080285246819113,0.13053266019655,0.3066494180742772,0.2507766799156004,0.2198839041088668,0.20541651088010432,0.19106479582363323,0.17584175029416121,0.16091797979445752,0.14803761289915987,0.13639500310367114,0.12611698320030446,0.304578735031577,0.24762889019099374,0.21640298426463145,0.20165099737186798,0.18696449047894234,0.17147923268051782,0.15626831893672863,0.14382587597523153,0.13236541531782764,0.12186199582018319,0.30249570217654037,0.24450962995711603,0.21301963371482646,0.19796952371047621,0.18299431737719468,0.16734216223439782,0.15200090646941455,0.13973405823912827,0.12844439445348133,0.11773252204724025,0.30040419699609733,0.24141582993509786,0.2097282909584795,0.1944164033507943,0.17913507193779063,0.1633180463632478,0.14799829570595105,0.13577289441995383,0.12463860544465982,0.11378432758835837,0.298307735556735,0.23835199031754153,0.20652624682723925,0.19096266148437674,0.17538395064158166,0.15940429459886418,0.14438411870124906,0.13195287524830573,0.12095590849680375,0.10988351291082861,0.29620949923717355,0.23531869676270695,0.20340871272733288,0.1876051982889947,0.17173747886634586,0.15558184958911775,0.14086434391989416,0.12851699367402966,0.11739319850316712,0.10605083767743316,0.2941123606799728,0.23231918463664883,0.200373230586777,0.18433955904707264,0.16819288538548513,0.1518592190496849,0.1374424942364811,0.1252206291166811,0.1139886101561503,0.10243228814525314,0.2920189085951862,0.22935357521997876,0.19739161791277943,0.18116391294787368,0.16472748197031334,0.14823690480933516,0.13412348460692328,0.12202149453003376,0.11072390591025516,0.09908220299538385,0.2899314712002887,0.22642571881156207,0.1945101755439721,0.17807509453161205,0.16137963741190892,0.14471397859356033,0.13091138155183604,0.11892618250371062,0.107577410763943,0.09602214586769685,0.2878521381855515,0.22353181536892394,0.19170148106526713,0.17507068536124606,0.1581173865512739,0.14129014738832515,0.12781305007243837,0.11593817275972255,0.10440267764058979,0.0941218647746585,0.2857827811666973,0.22067450612706166,0.1889628332728862,0.17214773838738132,0.15494569646844555,0.138120366424141,0.1248297939796328,0.11306137537580241,0.10140776329671544,0.09344976193158899,0.28372507263569946,0.2178554979199935,0.1862952498500306,0.16930509550712458,0.15195548321807828,0.13525252285689002,0.1221037960856738,0.11030073732568499,0.09861012811519307,0.09274512609344059,0.28168050345318374,0.2150743539151307,0.18369259101388716,0.16653889832224542,0.1490407589703431,0.13253315487212805,0.11947773584750843,0.10765315151636874,0.0960176407519554,0.09135549843077113,0.27965039894672944,0.2123321212193482,0.18115311915846202,0.16384197379690235,0.1461954077007174,0.129892840301607,0.11692015399533195,0.10515131248093225,0.09364442731629886,0.09011898688580994,0.2776359336914424,0.2096279025518525,0.17867521271735287,0.16120888812275605,0.1434224223933536,0.12733332846184275,0.11445984874191635,0.10265988621836071,0.09221860806620487,0.08902685052107548,0.27563814505572476,0.20696577631650293,0.17625639321526898,0.1586404650923522,0.14072165523504376,0.12485696969808,0.11208442402411115,0.100229130930397,0.09162543135161624,0.08802004123353956,0.2736579455976033,0.20434107409600918,0.1738951847817411,0.15613521715828685,0.13809106951828184,0.12246306854276566,0.1097948990659433,0.09793483671681487,0.09129698115810451,0.08708674806004542,0.27169613439616513,0.20176040739927437,0.17158960034033682,0.15367255551759823,0.13553084974723972,0.12015406973954847,0.10759268688208175,0.09578439464511332,0.09008386871907821,0.08623460775185739,0.26975340740055903,0.19922161597410817,0.169350135741366,0.1512901025582885,0.13304033522173228,0.11793064999162427,0.10547942589967217,0.09378121170293156,0.08894715149639151,0.08531175730313226,0.26783036687531797,0.1967217929119384,0.1672038761462732,0.14896676511359302,0.130613976484039,0.11582735059947534,0.10345686650334782,0.09192325798179428,0.08797094766848085,0.08442453563386926,0.265927530016485,0.19426153745692365,0.16510811968534306,0.14670073135949557,0.12822660113364243,0.11383336764715458,0.10152640637174162,0.09038076015865541,0.08706951259252596,0.08359468671153955,0.2640453368083088,0.19184031751584169,0.16306172692690035,0.14449092054994844,0.1259035668004179,0.11190048253401373,0.09968523586231928,0.08980566071832706,0.08622348460606105,0.08281129071095021,0.26218415718555527,0.18945711970265827,0.16106375576585372,0.14233663240425543,0.12377847612262174,0.11002950003743092,0.09782012955814945,0.08940514805495406,0.08544014766239107,0.08202171864350691,0.26034429756151656,0.1871136028489126,0.15911266373812527,0.14023792681456168,0.12187539792180278,0.10820765342070056,0.09604335890363276,0.08911000391976212,0.08471342169467387,0.08104419523418213,0.25852600677713966,0.1848081658515259,0.15720725247953785,0.1381922793964486,0.12002958156664152,0.10646015964914056,0.09436792508583246,0.08812211966072299,0.08394959862999661,0.08013296551330207,0.25672948152231445,0.182540341572718,0.1553461549412083,0.13619955605432854,0.11824118063117517,0.10477394889666311,0.09278942854047306,0.08718497485630393,0.08320965928096719,0.07951409335272949,0.2549548712760942,0.18031054172801925,0.15352727468151156,0.13425859882303837,0.11650869206772146,0.1031493785691459,0.091309402768235,0.08633766553769728,0.08249018609681483,0.07908599217970125,0.25320228280850177,0.17811766855383349,0.15174911378663714,0.13236812694575795,0.11483241303138056,0.10158649399049687,0.08992990987824787,0.08557693119271792,0.08178880430307976,0.07867024562658305,0.2514717842830289,0.1759589777072673,0.15001233508859765,0.1305470977943874,0.11321269174373695,0.10008506707632021,0.08865023047976223,0.08487227944811919,0.08113541185731697,0.07826623048217625,0.24976340899537242,0.17384013432439216,0.14829889406969854,0.12877840358520215,0.11164922134634021,0.09864575750441683,0.08785540736206232,0.08420901063790563,0.08046943056426915,0.07787361392593983,0.24807715878095513,0.17175746369629633,0.1466430297820542,0.1270539185634438,0.11014156209206487,0.09726978400277424,0.08746182118754528,0.08358490965002953,0.0796773443724085,0.07749189369261607,0.2464130071207922,0.1697101616443461,0.14502593465808322,0.12537299364811202,0.10869012322734604,0.09596556107452794,0.08716543256226032,0.08299760876470935,0.07893130146818117,0.07712064007340848,0.24477090197247914,0.16769826790862688,0.14344670414707802,0.12373523124544665,0.10730253018041187,0.09466745927117626,0.08697490016898954,0.0823782541419651,0.0782998636945087,0.07676207869028964,0.24315076835095997,0.16572161876109767,0.1418950760811856,0.12213950933228114,0.10596019167695746,0.09338926540245372,0.08638199663982626,0.08176900780204116,0.07795789382045733,0.0764105157024898,0.24155251068115727,0.16377968596319875,0.1403774281006151,0.12058536182953213,0.10465814005019401,0.09216622616462919,0.0856370922061294,0.08118438454708084,0.07762451437608953,0.07606835912587771,0.2399760149428216,0.16187139485152224,0.1388937205014929,0.11907235164704974,0.10339651297044244,0.09101425597804384,0.08493630197053438,0.08062062983007107,0.07730024576498337,0.07573529857014899,0.23842115062597188,0.1599971086148272,0.1374430836690669,0.1175755460698574,0.10216385621993684,0.08992178667023268,0.08430407021331932,0.080096836179604,0.07698734103944194,0.07541097794942961,0.23688777251366,0.15815578293677734,0.13602506127084338,0.11611943376961413,0.10098179136032767,0.08888964507135645,0.0837094403742949,0.07959068625654063,0.07668022624123716,0.07509509833511331,0.2353757223072481,0.1563470903362696,0.1346385031102175,0.11470188607944312,0.09983886371471973,0.08791833153218863,0.0831457314185172,0.0790783830507784,0.07638119765662012,0.07478737834071492,0.23388483010810737,0.15457110905010785,0.13328326392841888,0.11332150570788763,0.0987342944198904,0.08700636107230843,0.08261717915834947,0.0784631553825815,0.07609004576516189,0.07448757383344586,0.23241491576829368,0.15304691929243475,0.13195881110518715,0.1119846456459565,0.09766812578411545,0.08615432221543157,0.08213274183205024,0.07788076826099656,0.07580652038877418,0.07419544263583003,0.23096579012162274,0.15180613781793234,0.1306640101549461,0.11077368515182527,0.09663942382687232,0.08555347224074064,0.0816762135915288,0.07733102806908705,0.07553041577719116,0.07391077343804195,0.22953725610563053,0.1505984439624236,0.12939891740185808,0.10959994214116449,0.09564852567997238,0.08528067643261825,0.08124361204782711,0.07695576679857491,0.0752614572632721,0.07363337012653182,0.22812910978386106,0.14941614619628585,0.12816256053638325,0.108461032269582,0.09469504718453528,0.0850621531471898,0.08076109375936866,0.07670250497684472,0.07499945062324259,0.07336306097210378,0.22674114127716608,0.14825633206258496,0.12695477064532754,0.10735775317477925,0.09377902004471715,0.08489776717889111,0.0802927532488086,0.07645592220400332,0.07474416759823418,0.07309969655993794,0.2253731356118534,0.1471198292438729,0.1257748179401466,0.10631416435855869,0.09289812691495343,0.08478564338616122,0.07984713919649203,0.0762177870193198,0.07449541819241327,0.07284303577845287,0.22402487349187325,0.14600680025498403,0.12462210839938825,0.10533839448407929,0.09205353806329816,0.08451217414324237,0.07940992065583292,0.07598377670078489,0.07425303226001109,0.07259278084236308,0.22269613200153862,0.14491675037705304,0.12349639284814895,0.10439422777121324,0.0912441726958657,0.08397534495795309,0.07900326331036978,0.07575582976431365,0.07401686391840748,0.07234913351674689,0.22138668524486854,0.14384907700416938,0.12239646826848011,0.10348105833191602,0.09044007120406891,0.08346240610570814,0.07861344658969353,0.07553379027523835,0.07378678547278497,0.07211201703934139,0.22009630492677087,0.1428038130483568,0.12132242470856135,0.10259850286228091,0.0896516046707753,0.08297929402889115,0.07824020752624705,0.07531746358853814,0.07356263258677523,0.07188183635748027,0.21882476088127215,0.14178010668976151,0.12027374642890448,0.10174589501760187,0.08889778536286767,0.08253857248175359,0.0778815300353614,0.0751052200456418,0.07334435008037721,0.07165593081722843,0.21757182155110635,0.14077745849943704,0.11926004126668821,0.10092325252039033,0.08817834475984414,0.08212287668647296,0.07747825518022312,0.07489987598451216,0.07313060532009615,0.07143833616205848,0.21633725442296226,0.13979557348844499,0.11827282833135992,0.10012976373297389,0.08748474140863705,0.0817239920376628,0.07707042799619052,0.07469985834066681,0.07292379781461021,0.0712273171935761,0.21512082642203686,0.13883403467882716,0.11731103426601562,0.09936070389508551,0.08683149883773128,0.0813421569119993,0.07668308232139805,0.07450548152382191,0.07272267188624089,0.07102625421038147,0.21392230426943923,0.1378920192083805,0.11636202403573437,0.0986147356979747,0.0862102233550825,0.08097512959161415,0.07629625460903755,0.0743158682567452,0.07253280409058278,0.07087090888006158,0.21274145480554996,0.13696317257440052,0.11544967151620311,0.09788028468337438,0.0856205211487865,0.08062478068047708,0.07601780248377056,0.07414576016626771,0.07238545822236264,0.07072172985607579,0.21157804528222723,0.1360602706404401,0.11456054549157631,0.09717950742839859,0.0850630552514402,0.08029691688566092,0.07587549479356832,0.07400889143839891,0.0722434154756286,0.07057844151493323,0.210431843626469,0.13517607843000373,0.11369523197247272,0.09650026640260721,0.08455888687767066,0.08001253384493913,0.07575133905804722,0.07387665478976412,0.07210637551548983,0.07044107813510488,0.20930261867803845,0.13431021047118946,0.11285219385290028,0.0958427331245372,0.0840890755417675,0.0797254965900579,0.07562998607370512,0.07374889933524639,0.07197428290019513,0.07031265601396364,0.2081901404031209,0.13346231183191357,0.11203168728989218,0.09520607252415444,0.08364965344717357,0.07943356528083856,0.07551275577594396,0.07362552218479151,0.07184709653509865,0.0701874943202183,0.20709418008614586,0.13263203710929808,0.11123324518152805,0.09459038221240675,0.08352481119270429,0.07914899843032491,0.07539963871934942,0.07350642390533657,0.07172479598263753,0.0703111710418912,0.2060145105015843,0.13181883142558753,0.1104565075206111,0.09399516282011859,0.08342919838321039,0.07887451758159851,0.07529047024369488,0.07339152010629789,0.0716073784941984,0.07049021685970247,0.2049509060674013,0.1310227892082444,0.10970168985711469,0.09341983775728344,0.08335949842313896,0.07862118561882242,0.07518512492557602,0.07328074026460406,0.07149485896876467,0.07067832479294277,0.20390314298175882,0.13024336449906398,0.10896734628020162,0.09286436931117395,0.08331267357674504,0.07837852345371707,0.0750834947119523,0.07317402661670587,0.07138726763164659,0.07087544635661244,0.2028709993443136,0.12948030722976336,0.10825232811432021,0.09233059432732503,0.08328945313386273,0.07814726919741721,0.07498549202416523,0.07307131534167077,0.07128465622700567,0.07108260873523538,0.20185425526354295,0.12873307958030242,0.10755541963221356,0.09181359839004109,0.083288227276901,0.07792665623504029,0.07489102910657798,0.07297247525545311,0.07118709261635851,0.07129984000215905,0.20085269295117408,0.12800154478134973,0.10687832853392061,0.09131539308559511,0.08330406622411814,0.07771680430270127,0.07480001635091357,0.0728774426332866,0.07109466153613904,0.07152686468233366,0.19986609680485792,0.12728540544402686,0.10622064987971115,0.09083579131201493,0.08300149872782688,0.07751562159107778,0.07471240290737556,0.07278636990109985,0.07106464924795855,0.07176425087880592,0.19889425348012865,0.12658421349423762,0.10558151759662848,0.0903733086529484,0.08272084822110534,0.0773261641492128,0.0746281049969053,0.07269926185215035,0.07123867363598123,0.07201229582516887,0.1979369519525187,0.1258980092501154,0.10494994671884779,0.0899288328404282,0.0824332290078498,0.07709622662921607,0.0745470678013816,0.0726161402181659,0.07142003809222815,0.07227127843930486]}],                        {\"legend\":{\"bgcolor\":\"#151516\",\"font\":{\"color\":\"#D9D9D9\"}},\"paper_bgcolor\":\"#151516\",\"plot_bgcolor\":\"#151516\",\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"color\":\"#D9D9D9\"}},\"xaxis\":{\"gridcolor\":\"#434343\",\"showgrid\":true,\"tickfont\":{\"color\":\"#C2C2C2\"},\"title\":{\"font\":{\"color\":\"#D9D9D9\"},\"text\":\"\"},\"zerolinecolor\":\"#666570\"},\"yaxis\":{\"gridcolor\":\"#434343\",\"showgrid\":true,\"tickfont\":{\"color\":\"#C2C2C2\"},\"title\":{\"font\":{\"color\":\"#D9D9D9\"},\"text\":\"\"},\"zerolinecolor\":\"#666570\"}},                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('ba94a9a2-5a1a-4bf2-9dda-0aed90145765');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_res.set_index([\"alpha\", \"l1_ratio\"])[[\"score\", \"std\"]].iplot(theme=\"solar\", colors=['blue', 'orange'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df_res.columns:\n",
    "    df_res[x]=df_res[x].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Alpha=%{x}<br>L1 Ratio=%{y}<br>Score=%{z}<br>STD=%{marker.color}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": [
           0.4728801335387184,
           0.4817013661854827,
           0.49130631122243845,
           0.501960035718716,
           0.5134629445044958,
           0.5266456402171696,
           0.541715129587993,
           0.5587254576359675,
           0.5780724374864337,
           0.5937760142653865,
           0.4074131514110777,
           0.41698345925795494,
           0.4278142386198395,
           0.4406446445556819,
           0.45556509916103416,
           0.47251120836132093,
           0.48789593023103794,
           0.505766996763168,
           0.5255089015038684,
           0.5499682970645737,
           0.3759114894846676,
           0.38610406164214794,
           0.3980989654990603,
           0.4121933780588476,
           0.4275740673360826,
           0.44274442143852233,
           0.46035720595844576,
           0.48138027840632713,
           0.5065972781060857,
           0.5372115999300027,
           0.35931880860761956,
           0.3710302632826347,
           0.3850480243406514,
           0.4013994811703531,
           0.4174177292249497,
           0.43586189992260366,
           0.45749805414712813,
           0.47818103038765586,
           0.49942272745460675,
           0.5287132942033976,
           0.35007221054600424,
           0.36409145488982203,
           0.38099406737446134,
           0.3997874325588472,
           0.41064084354043656,
           0.41740195394443586,
           0.42659192715539335,
           0.43948037309675414,
           0.45759825915297214,
           0.48440266347101557,
           0.3447106686354988,
           0.3615694501044995,
           0.38058555445333075,
           0.38354914406520546,
           0.386531763166403,
           0.3909304896739723,
           0.39751239245055026,
           0.40720794036417757,
           0.421755319511681,
           0.4446166486183859,
           0.341486008430782,
           0.36150022927515907,
           0.36513104448558925,
           0.36552024647341247,
           0.3667603856557223,
           0.36907354481210936,
           0.37318169187327555,
           0.3797616682095927,
           0.39035133998508187,
           0.41060093276907333,
           0.3394518054293826,
           0.3499601288716105,
           0.3513899296766789,
           0.3504369876506036,
           0.35007856002464444,
           0.35061316617503213,
           0.35237249398104503,
           0.35600292235581243,
           0.3642989772970664,
           0.38008954087962477,
           0.33807023825551585,
           0.3397407989481586,
           0.339550091807832,
           0.3374275975767637,
           0.33567676006033803,
           0.3345807965280686,
           0.33422437780098024,
           0.3357941448687687,
           0.34127005384335884,
           0.3524961530341147,
           0.33702560865388637,
           0.33074044363551247,
           0.32913929989465573,
           0.32599320146772476,
           0.32306293721631,
           0.3204213652089897,
           0.3181540418854769,
           0.3182516444719985,
           0.3206681329107283,
           0.32746926824394473,
           0.33612908790239715,
           0.3226695438438544,
           0.31984922728110016,
           0.3157513484665927,
           0.3117400575849003,
           0.307715064272473,
           0.30427162662550755,
           0.30250016187343126,
           0.30196192240147585,
           0.30455967247381516,
           0.3352671059617416,
           0.31532507285367234,
           0.3114377545643648,
           0.3064749956348863,
           0.3014637954663352,
           0.2961875708577287,
           0.2918190667633584,
           0.2881261795010447,
           0.28499589536708037,
           0.2835559787606079,
           0.33437202767876567,
           0.3085765050073532,
           0.30373235880074434,
           0.2980017774929314,
           0.2920087686411077,
           0.28561865178063994,
           0.280304626939876,
           0.2749523967341846,
           0.26961880534305893,
           0.26468960779647355,
           0.333404838439939,
           0.3023135134683635,
           0.29659850504583,
           0.2901472828837048,
           0.2832513548194423,
           0.2761327349574763,
           0.2696699130459248,
           0.2628213962999806,
           0.25548221931131965,
           0.2477182938923026,
           0.33234459680722117,
           0.29901063987127885,
           0.2899306095955534,
           0.28280854002400185,
           0.2750301707198551,
           0.2672967535770442,
           0.2597727307348578,
           0.2516099113432252,
           0.24259933430208044,
           0.23217552000485694,
           0.33118184556594993,
           0.2959133584754912,
           0.28367961657455054,
           0.275843106637014,
           0.2673147011418287,
           0.2590144677026055,
           0.25051526611091074,
           0.24118030571898616,
           0.2307747257388411,
           0.219322976254482,
           0.3299144123809765,
           0.2928031541791328,
           0.2777548556932979,
           0.26927650478686266,
           0.260005762071577,
           0.25119808402288274,
           0.2418249876549058,
           0.2314491711447608,
           0.2197517457942704,
           0.20790380997723384,
           0.32854469183145,
           0.28963946691258297,
           0.27213531752693587,
           0.263043993406068,
           0.2531427583035185,
           0.24378749536621286,
           0.2336238491043161,
           0.22241340390426256,
           0.2100334278482492,
           0.197461336168777,
           0.3270778665544832,
           0.2863943334697499,
           0.2667901669775465,
           0.25711344643300543,
           0.24677470088786474,
           0.23676951039218486,
           0.22584721627495877,
           0.21383514376127816,
           0.20133131565105242,
           0.18782534164448678,
           0.3255207349786583,
           0.28312602502425094,
           0.2616789690805543,
           0.25142964944216706,
           0.24067438116909498,
           0.23006870953519953,
           0.21844146887587965,
           0.20569128312972149,
           0.19312265012904564,
           0.1801637768741747,
           0.32388093698288956,
           0.2798561100846484,
           0.25677052463188726,
           0.2460004047877978,
           0.23486422385910394,
           0.22363422537860195,
           0.21146694880085518,
           0.1983181915902571,
           0.18531762728038928,
           0.1735592852848735,
           0.322166443890135,
           0.27657889350563086,
           0.2520701643398048,
           0.2407848241225855,
           0.2292809952979453,
           0.2174874288731058,
           0.20477238311229332,
           0.19148834513849625,
           0.17786188193318694,
           0.16756021622428577,
           0.3203852257759628,
           0.2733086417655281,
           0.2475472707144828,
           0.2357697316202463,
           0.2239058055396223,
           0.21158508140600815,
           0.19831379687547665,
           0.18493892929853256,
           0.1716226880490956,
           0.1616541949778803,
           0.31854503855761096,
           0.27005962003477463,
           0.24319352150704912,
           0.23091742993348371,
           0.2186980756246856,
           0.20591043027591666,
           0.1921187163753747,
           0.1786226820139732,
           0.16587140388658542,
           0.15583065318685943,
           0.3166532923366081,
           0.2668134336940405,
           0.23899429039176842,
           0.22625170398478864,
           0.21369834895583512,
           0.2004763011886492,
           0.18634465966589422,
           0.17252374796523404,
           0.16066468838384082,
           0.15010238091129083,
           0.3147169749198814,
           0.26357462187392966,
           0.23491978242233247,
           0.22173799898579416,
           0.2088673450681807,
           0.19523217252312522,
           0.18094334661144876,
           0.16663029131078022,
           0.15553342733381953,
           0.144509240615076,
           0.3127426127161931,
           0.2603481073985881,
           0.23099034003542834,
           0.21741113778124954,
           0.2041961811545883,
           0.19015572360414124,
           0.1757082015974619,
           0.16157986139484953,
           0.1504983916085242,
           0.13971282459592657,
           0.3107362567683288,
           0.25714052167339957,
           0.2271819849841278,
           0.21329102743226946,
           0.19967626301999,
           0.1852395597422014,
           0.1706285275028778,
           0.1567770232721188,
           0.14556931189357902,
           0.1350651547468092,
           0.30870348546519194,
           0.2539485612421555,
           0.22348901885268607,
           0.20929444440805817,
           0.1953012330356211,
           0.18045535748390318,
           0.16569966028303443,
           0.1523586945746133,
           0.14080285246819113,
           0.13053266019655,
           0.3066494180742772,
           0.2507766799156004,
           0.2198839041088668,
           0.20541651088010432,
           0.19106479582363323,
           0.17584175029416121,
           0.16091797979445752,
           0.14803761289915987,
           0.13639500310367114,
           0.12611698320030446,
           0.304578735031577,
           0.24762889019099374,
           0.21640298426463145,
           0.20165099737186798,
           0.18696449047894234,
           0.17147923268051782,
           0.15626831893672863,
           0.14382587597523153,
           0.13236541531782764,
           0.12186199582018319,
           0.30249570217654037,
           0.24450962995711603,
           0.21301963371482646,
           0.19796952371047621,
           0.18299431737719468,
           0.16734216223439782,
           0.15200090646941455,
           0.13973405823912827,
           0.12844439445348133,
           0.11773252204724025,
           0.30040419699609733,
           0.24141582993509786,
           0.2097282909584795,
           0.1944164033507943,
           0.17913507193779063,
           0.1633180463632478,
           0.14799829570595105,
           0.13577289441995383,
           0.12463860544465982,
           0.11378432758835837,
           0.298307735556735,
           0.23835199031754153,
           0.20652624682723925,
           0.19096266148437674,
           0.17538395064158166,
           0.15940429459886418,
           0.14438411870124906,
           0.13195287524830573,
           0.12095590849680375,
           0.10988351291082861,
           0.29620949923717355,
           0.23531869676270695,
           0.20340871272733288,
           0.1876051982889947,
           0.17173747886634586,
           0.15558184958911775,
           0.14086434391989416,
           0.12851699367402966,
           0.11739319850316712,
           0.10605083767743316,
           0.2941123606799728,
           0.23231918463664883,
           0.200373230586777,
           0.18433955904707264,
           0.16819288538548513,
           0.1518592190496849,
           0.1374424942364811,
           0.1252206291166811,
           0.1139886101561503,
           0.10243228814525314,
           0.2920189085951862,
           0.22935357521997876,
           0.19739161791277943,
           0.18116391294787368,
           0.16472748197031334,
           0.14823690480933516,
           0.13412348460692328,
           0.12202149453003376,
           0.11072390591025516,
           0.09908220299538385,
           0.2899314712002887,
           0.22642571881156207,
           0.1945101755439721,
           0.17807509453161205,
           0.16137963741190892,
           0.14471397859356033,
           0.13091138155183604,
           0.11892618250371062,
           0.107577410763943,
           0.09602214586769685,
           0.2878521381855515,
           0.22353181536892394,
           0.19170148106526713,
           0.17507068536124606,
           0.1581173865512739,
           0.14129014738832515,
           0.12781305007243837,
           0.11593817275972255,
           0.10440267764058979,
           0.0941218647746585,
           0.2857827811666973,
           0.22067450612706166,
           0.1889628332728862,
           0.17214773838738132,
           0.15494569646844555,
           0.138120366424141,
           0.1248297939796328,
           0.11306137537580241,
           0.10140776329671544,
           0.09344976193158899,
           0.28372507263569946,
           0.2178554979199935,
           0.1862952498500306,
           0.16930509550712458,
           0.15195548321807828,
           0.13525252285689002,
           0.1221037960856738,
           0.11030073732568499,
           0.09861012811519307,
           0.09274512609344059,
           0.28168050345318374,
           0.2150743539151307,
           0.18369259101388716,
           0.16653889832224542,
           0.1490407589703431,
           0.13253315487212805,
           0.11947773584750843,
           0.10765315151636874,
           0.0960176407519554,
           0.09135549843077113,
           0.27965039894672944,
           0.2123321212193482,
           0.18115311915846202,
           0.16384197379690235,
           0.1461954077007174,
           0.129892840301607,
           0.11692015399533195,
           0.10515131248093225,
           0.09364442731629886,
           0.09011898688580994,
           0.2776359336914424,
           0.2096279025518525,
           0.17867521271735287,
           0.16120888812275605,
           0.1434224223933536,
           0.12733332846184275,
           0.11445984874191635,
           0.10265988621836071,
           0.09221860806620487,
           0.08902685052107548,
           0.27563814505572476,
           0.20696577631650293,
           0.17625639321526898,
           0.1586404650923522,
           0.14072165523504376,
           0.12485696969808,
           0.11208442402411115,
           0.100229130930397,
           0.09162543135161624,
           0.08802004123353956,
           0.2736579455976033,
           0.20434107409600918,
           0.1738951847817411,
           0.15613521715828685,
           0.13809106951828184,
           0.12246306854276566,
           0.1097948990659433,
           0.09793483671681487,
           0.09129698115810451,
           0.08708674806004542,
           0.27169613439616513,
           0.20176040739927437,
           0.17158960034033682,
           0.15367255551759823,
           0.13553084974723972,
           0.12015406973954847,
           0.10759268688208175,
           0.09578439464511332,
           0.09008386871907821,
           0.08623460775185739,
           0.26975340740055903,
           0.19922161597410817,
           0.169350135741366,
           0.1512901025582885,
           0.13304033522173228,
           0.11793064999162427,
           0.10547942589967217,
           0.09378121170293156,
           0.08894715149639151,
           0.08531175730313226,
           0.26783036687531797,
           0.1967217929119384,
           0.1672038761462732,
           0.14896676511359302,
           0.130613976484039,
           0.11582735059947534,
           0.10345686650334782,
           0.09192325798179428,
           0.08797094766848085,
           0.08442453563386926,
           0.265927530016485,
           0.19426153745692365,
           0.16510811968534306,
           0.14670073135949557,
           0.12822660113364243,
           0.11383336764715458,
           0.10152640637174162,
           0.09038076015865541,
           0.08706951259252596,
           0.08359468671153955,
           0.2640453368083088,
           0.19184031751584169,
           0.16306172692690035,
           0.14449092054994844,
           0.1259035668004179,
           0.11190048253401373,
           0.09968523586231928,
           0.08980566071832706,
           0.08622348460606105,
           0.08281129071095021,
           0.26218415718555527,
           0.18945711970265827,
           0.16106375576585372,
           0.14233663240425543,
           0.12377847612262174,
           0.11002950003743092,
           0.09782012955814945,
           0.08940514805495406,
           0.08544014766239107,
           0.08202171864350691,
           0.26034429756151656,
           0.1871136028489126,
           0.15911266373812527,
           0.14023792681456168,
           0.12187539792180278,
           0.10820765342070056,
           0.09604335890363276,
           0.08911000391976212,
           0.08471342169467387,
           0.08104419523418213,
           0.25852600677713966,
           0.1848081658515259,
           0.15720725247953785,
           0.1381922793964486,
           0.12002958156664152,
           0.10646015964914056,
           0.09436792508583246,
           0.08812211966072299,
           0.08394959862999661,
           0.08013296551330207,
           0.25672948152231445,
           0.182540341572718,
           0.1553461549412083,
           0.13619955605432854,
           0.11824118063117517,
           0.10477394889666311,
           0.09278942854047306,
           0.08718497485630393,
           0.08320965928096719,
           0.07951409335272949,
           0.2549548712760942,
           0.18031054172801925,
           0.15352727468151156,
           0.13425859882303837,
           0.11650869206772146,
           0.1031493785691459,
           0.091309402768235,
           0.08633766553769728,
           0.08249018609681483,
           0.07908599217970125,
           0.25320228280850177,
           0.17811766855383349,
           0.15174911378663714,
           0.13236812694575795,
           0.11483241303138056,
           0.10158649399049687,
           0.08992990987824787,
           0.08557693119271792,
           0.08178880430307976,
           0.07867024562658305,
           0.2514717842830289,
           0.1759589777072673,
           0.15001233508859765,
           0.1305470977943874,
           0.11321269174373695,
           0.10008506707632021,
           0.08865023047976223,
           0.08487227944811919,
           0.08113541185731697,
           0.07826623048217625,
           0.24976340899537242,
           0.17384013432439216,
           0.14829889406969854,
           0.12877840358520215,
           0.11164922134634021,
           0.09864575750441683,
           0.08785540736206232,
           0.08420901063790563,
           0.08046943056426915,
           0.07787361392593983,
           0.24807715878095513,
           0.17175746369629633,
           0.1466430297820542,
           0.1270539185634438,
           0.11014156209206487,
           0.09726978400277424,
           0.08746182118754528,
           0.08358490965002953,
           0.0796773443724085,
           0.07749189369261607,
           0.2464130071207922,
           0.1697101616443461,
           0.14502593465808322,
           0.12537299364811202,
           0.10869012322734604,
           0.09596556107452794,
           0.08716543256226032,
           0.08299760876470935,
           0.07893130146818117,
           0.07712064007340848,
           0.24477090197247914,
           0.16769826790862688,
           0.14344670414707802,
           0.12373523124544665,
           0.10730253018041187,
           0.09466745927117626,
           0.08697490016898954,
           0.0823782541419651,
           0.0782998636945087,
           0.07676207869028964,
           0.24315076835095997,
           0.16572161876109767,
           0.1418950760811856,
           0.12213950933228114,
           0.10596019167695746,
           0.09338926540245372,
           0.08638199663982626,
           0.08176900780204116,
           0.07795789382045733,
           0.0764105157024898,
           0.24155251068115727,
           0.16377968596319875,
           0.1403774281006151,
           0.12058536182953213,
           0.10465814005019401,
           0.09216622616462919,
           0.0856370922061294,
           0.08118438454708084,
           0.07762451437608953,
           0.07606835912587771,
           0.2399760149428216,
           0.16187139485152224,
           0.1388937205014929,
           0.11907235164704974,
           0.10339651297044244,
           0.09101425597804384,
           0.08493630197053438,
           0.08062062983007107,
           0.07730024576498337,
           0.07573529857014899,
           0.23842115062597188,
           0.1599971086148272,
           0.1374430836690669,
           0.1175755460698574,
           0.10216385621993684,
           0.08992178667023268,
           0.08430407021331932,
           0.080096836179604,
           0.07698734103944194,
           0.07541097794942961,
           0.23688777251366,
           0.15815578293677734,
           0.13602506127084338,
           0.11611943376961413,
           0.10098179136032767,
           0.08888964507135645,
           0.0837094403742949,
           0.07959068625654063,
           0.07668022624123716,
           0.07509509833511331,
           0.2353757223072481,
           0.1563470903362696,
           0.1346385031102175,
           0.11470188607944312,
           0.09983886371471973,
           0.08791833153218863,
           0.0831457314185172,
           0.0790783830507784,
           0.07638119765662012,
           0.07478737834071492,
           0.23388483010810737,
           0.15457110905010785,
           0.13328326392841888,
           0.11332150570788763,
           0.0987342944198904,
           0.08700636107230843,
           0.08261717915834947,
           0.0784631553825815,
           0.07609004576516189,
           0.07448757383344586,
           0.23241491576829368,
           0.15304691929243475,
           0.13195881110518715,
           0.1119846456459565,
           0.09766812578411545,
           0.08615432221543157,
           0.08213274183205024,
           0.07788076826099656,
           0.07580652038877418,
           0.07419544263583003,
           0.23096579012162274,
           0.15180613781793234,
           0.1306640101549461,
           0.11077368515182527,
           0.09663942382687232,
           0.08555347224074064,
           0.0816762135915288,
           0.07733102806908705,
           0.07553041577719116,
           0.07391077343804195,
           0.22953725610563053,
           0.1505984439624236,
           0.12939891740185808,
           0.10959994214116449,
           0.09564852567997238,
           0.08528067643261825,
           0.08124361204782711,
           0.07695576679857491,
           0.0752614572632721,
           0.07363337012653182,
           0.22812910978386106,
           0.14941614619628585,
           0.12816256053638325,
           0.108461032269582,
           0.09469504718453528,
           0.0850621531471898,
           0.08076109375936866,
           0.07670250497684472,
           0.07499945062324259,
           0.07336306097210378,
           0.22674114127716608,
           0.14825633206258496,
           0.12695477064532754,
           0.10735775317477925,
           0.09377902004471715,
           0.08489776717889111,
           0.0802927532488086,
           0.07645592220400332,
           0.07474416759823418,
           0.07309969655993794,
           0.2253731356118534,
           0.1471198292438729,
           0.1257748179401466,
           0.10631416435855869,
           0.09289812691495343,
           0.08478564338616122,
           0.07984713919649203,
           0.0762177870193198,
           0.07449541819241327,
           0.07284303577845287,
           0.22402487349187325,
           0.14600680025498403,
           0.12462210839938825,
           0.10533839448407929,
           0.09205353806329816,
           0.08451217414324237,
           0.07940992065583292,
           0.07598377670078489,
           0.07425303226001109,
           0.07259278084236308,
           0.22269613200153862,
           0.14491675037705304,
           0.12349639284814895,
           0.10439422777121324,
           0.0912441726958657,
           0.08397534495795309,
           0.07900326331036978,
           0.07575582976431365,
           0.07401686391840748,
           0.07234913351674689,
           0.22138668524486854,
           0.14384907700416938,
           0.12239646826848011,
           0.10348105833191602,
           0.09044007120406891,
           0.08346240610570814,
           0.07861344658969353,
           0.07553379027523835,
           0.07378678547278497,
           0.07211201703934139,
           0.22009630492677087,
           0.1428038130483568,
           0.12132242470856135,
           0.10259850286228091,
           0.0896516046707753,
           0.08297929402889115,
           0.07824020752624705,
           0.07531746358853814,
           0.07356263258677523,
           0.07188183635748027,
           0.21882476088127215,
           0.14178010668976151,
           0.12027374642890448,
           0.10174589501760187,
           0.08889778536286767,
           0.08253857248175359,
           0.0778815300353614,
           0.0751052200456418,
           0.07334435008037721,
           0.07165593081722843,
           0.21757182155110635,
           0.14077745849943704,
           0.11926004126668821,
           0.10092325252039033,
           0.08817834475984414,
           0.08212287668647296,
           0.07747825518022312,
           0.07489987598451216,
           0.07313060532009615,
           0.07143833616205848,
           0.21633725442296226,
           0.13979557348844499,
           0.11827282833135992,
           0.10012976373297389,
           0.08748474140863705,
           0.0817239920376628,
           0.07707042799619052,
           0.07469985834066681,
           0.07292379781461021,
           0.0712273171935761,
           0.21512082642203686,
           0.13883403467882716,
           0.11731103426601562,
           0.09936070389508551,
           0.08683149883773128,
           0.0813421569119993,
           0.07668308232139805,
           0.07450548152382191,
           0.07272267188624089,
           0.07102625421038147,
           0.21392230426943923,
           0.1378920192083805,
           0.11636202403573437,
           0.0986147356979747,
           0.0862102233550825,
           0.08097512959161415,
           0.07629625460903755,
           0.0743158682567452,
           0.07253280409058278,
           0.07087090888006158,
           0.21274145480554996,
           0.13696317257440052,
           0.11544967151620311,
           0.09788028468337438,
           0.0856205211487865,
           0.08062478068047708,
           0.07601780248377056,
           0.07414576016626771,
           0.07238545822236264,
           0.07072172985607579,
           0.21157804528222723,
           0.1360602706404401,
           0.11456054549157631,
           0.09717950742839859,
           0.0850630552514402,
           0.08029691688566092,
           0.07587549479356832,
           0.07400889143839891,
           0.0722434154756286,
           0.07057844151493323,
           0.210431843626469,
           0.13517607843000373,
           0.11369523197247272,
           0.09650026640260721,
           0.08455888687767066,
           0.08001253384493913,
           0.07575133905804722,
           0.07387665478976412,
           0.07210637551548983,
           0.07044107813510488,
           0.20930261867803845,
           0.13431021047118946,
           0.11285219385290028,
           0.0958427331245372,
           0.0840890755417675,
           0.0797254965900579,
           0.07562998607370512,
           0.07374889933524639,
           0.07197428290019513,
           0.07031265601396364,
           0.2081901404031209,
           0.13346231183191357,
           0.11203168728989218,
           0.09520607252415444,
           0.08364965344717357,
           0.07943356528083856,
           0.07551275577594396,
           0.07362552218479151,
           0.07184709653509865,
           0.0701874943202183,
           0.20709418008614586,
           0.13263203710929808,
           0.11123324518152805,
           0.09459038221240675,
           0.08352481119270429,
           0.07914899843032491,
           0.07539963871934942,
           0.07350642390533657,
           0.07172479598263753,
           0.0703111710418912,
           0.2060145105015843,
           0.13181883142558753,
           0.1104565075206111,
           0.09399516282011859,
           0.08342919838321039,
           0.07887451758159851,
           0.07529047024369488,
           0.07339152010629789,
           0.0716073784941984,
           0.07049021685970247,
           0.2049509060674013,
           0.1310227892082444,
           0.10970168985711469,
           0.09341983775728344,
           0.08335949842313896,
           0.07862118561882242,
           0.07518512492557602,
           0.07328074026460406,
           0.07149485896876467,
           0.07067832479294277,
           0.20390314298175882,
           0.13024336449906398,
           0.10896734628020162,
           0.09286436931117395,
           0.08331267357674504,
           0.07837852345371707,
           0.0750834947119523,
           0.07317402661670587,
           0.07138726763164659,
           0.07087544635661244,
           0.2028709993443136,
           0.12948030722976336,
           0.10825232811432021,
           0.09233059432732503,
           0.08328945313386273,
           0.07814726919741721,
           0.07498549202416523,
           0.07307131534167077,
           0.07128465622700567,
           0.07108260873523538,
           0.20185425526354295,
           0.12873307958030242,
           0.10755541963221356,
           0.09181359839004109,
           0.083288227276901,
           0.07792665623504029,
           0.07489102910657798,
           0.07297247525545311,
           0.07118709261635851,
           0.07129984000215905,
           0.20085269295117408,
           0.12800154478134973,
           0.10687832853392061,
           0.09131539308559511,
           0.08330406622411814,
           0.07771680430270127,
           0.07480001635091357,
           0.0728774426332866,
           0.07109466153613904,
           0.07152686468233366,
           0.19986609680485792,
           0.12728540544402686,
           0.10622064987971115,
           0.09083579131201493,
           0.08300149872782688,
           0.07751562159107778,
           0.07471240290737556,
           0.07278636990109985,
           0.07106464924795855,
           0.07176425087880592,
           0.19889425348012865,
           0.12658421349423762,
           0.10558151759662848,
           0.0903733086529484,
           0.08272084822110534,
           0.0773261641492128,
           0.0746281049969053,
           0.07269926185215035,
           0.07123867363598123,
           0.07201229582516887,
           0.1979369519525187,
           0.1258980092501154,
           0.10494994671884779,
           0.0899288328404282,
           0.0824332290078498,
           0.07709622662921607,
           0.0745470678013816,
           0.0726161402181659,
           0.07142003809222815,
           0.07227127843930486
          ],
          "coloraxis": "coloraxis",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "scene": "scene",
         "showlegend": false,
         "type": "scatter3d",
         "x": [
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.3,
          0.3,
          0.3,
          0.3,
          0.3,
          0.3,
          0.3,
          0.3,
          0.3,
          0.3,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.6,
          0.6,
          0.6,
          0.6,
          0.6,
          0.6,
          0.6,
          0.6,
          0.6,
          0.6,
          0.7,
          0.7,
          0.7,
          0.7,
          0.7,
          0.7,
          0.7,
          0.7,
          0.7,
          0.7,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1.1,
          1.1,
          1.1,
          1.1,
          1.1,
          1.1,
          1.1,
          1.1,
          1.1,
          1.1,
          1.2,
          1.2,
          1.2,
          1.2,
          1.2,
          1.2,
          1.2,
          1.2,
          1.2,
          1.2,
          1.3,
          1.3,
          1.3,
          1.3,
          1.3,
          1.3,
          1.3,
          1.3,
          1.3,
          1.3,
          1.4,
          1.4,
          1.4,
          1.4,
          1.4,
          1.4,
          1.4,
          1.4,
          1.4,
          1.4,
          1.5,
          1.5,
          1.5,
          1.5,
          1.5,
          1.5,
          1.5,
          1.5,
          1.5,
          1.5,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.7,
          1.7,
          1.7,
          1.7,
          1.7,
          1.7,
          1.7,
          1.7,
          1.7,
          1.7,
          1.8,
          1.8,
          1.8,
          1.8,
          1.8,
          1.8,
          1.8,
          1.8,
          1.8,
          1.8,
          1.9,
          1.9,
          1.9,
          1.9,
          1.9,
          1.9,
          1.9,
          1.9,
          1.9,
          1.9,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2.1,
          2.1,
          2.1,
          2.1,
          2.1,
          2.1,
          2.1,
          2.1,
          2.1,
          2.1,
          2.2,
          2.2,
          2.2,
          2.2,
          2.2,
          2.2,
          2.2,
          2.2,
          2.2,
          2.2,
          2.3,
          2.3,
          2.3,
          2.3,
          2.3,
          2.3,
          2.3,
          2.3,
          2.3,
          2.3,
          2.4,
          2.4,
          2.4,
          2.4,
          2.4,
          2.4,
          2.4,
          2.4,
          2.4,
          2.4,
          2.5,
          2.5,
          2.5,
          2.5,
          2.5,
          2.5,
          2.5,
          2.5,
          2.5,
          2.5,
          2.6,
          2.6,
          2.6,
          2.6,
          2.6,
          2.6,
          2.6,
          2.6,
          2.6,
          2.6,
          2.7,
          2.7,
          2.7,
          2.7,
          2.7,
          2.7,
          2.7,
          2.7,
          2.7,
          2.7,
          2.8,
          2.8,
          2.8,
          2.8,
          2.8,
          2.8,
          2.8,
          2.8,
          2.8,
          2.8,
          2.9,
          2.9,
          2.9,
          2.9,
          2.9,
          2.9,
          2.9,
          2.9,
          2.9,
          2.9,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3.1,
          3.1,
          3.1,
          3.1,
          3.1,
          3.1,
          3.1,
          3.1,
          3.1,
          3.1,
          3.2,
          3.2,
          3.2,
          3.2,
          3.2,
          3.2,
          3.2,
          3.2,
          3.2,
          3.2,
          3.3,
          3.3,
          3.3,
          3.3,
          3.3,
          3.3,
          3.3,
          3.3,
          3.3,
          3.3,
          3.4,
          3.4,
          3.4,
          3.4,
          3.4,
          3.4,
          3.4,
          3.4,
          3.4,
          3.4,
          3.5,
          3.5,
          3.5,
          3.5,
          3.5,
          3.5,
          3.5,
          3.5,
          3.5,
          3.5,
          3.6,
          3.6,
          3.6,
          3.6,
          3.6,
          3.6,
          3.6,
          3.6,
          3.6,
          3.6,
          3.7,
          3.7,
          3.7,
          3.7,
          3.7,
          3.7,
          3.7,
          3.7,
          3.7,
          3.7,
          3.8,
          3.8,
          3.8,
          3.8,
          3.8,
          3.8,
          3.8,
          3.8,
          3.8,
          3.8,
          3.9,
          3.9,
          3.9,
          3.9,
          3.9,
          3.9,
          3.9,
          3.9,
          3.9,
          3.9,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4.1,
          4.1,
          4.1,
          4.1,
          4.1,
          4.1,
          4.1,
          4.1,
          4.1,
          4.1,
          4.2,
          4.2,
          4.2,
          4.2,
          4.2,
          4.2,
          4.2,
          4.2,
          4.2,
          4.2,
          4.3,
          4.3,
          4.3,
          4.3,
          4.3,
          4.3,
          4.3,
          4.3,
          4.3,
          4.3,
          4.4,
          4.4,
          4.4,
          4.4,
          4.4,
          4.4,
          4.4,
          4.4,
          4.4,
          4.4,
          4.5,
          4.5,
          4.5,
          4.5,
          4.5,
          4.5,
          4.5,
          4.5,
          4.5,
          4.5,
          4.6,
          4.6,
          4.6,
          4.6,
          4.6,
          4.6,
          4.6,
          4.6,
          4.6,
          4.6,
          4.7,
          4.7,
          4.7,
          4.7,
          4.7,
          4.7,
          4.7,
          4.7,
          4.7,
          4.7,
          4.8,
          4.8,
          4.8,
          4.8,
          4.8,
          4.8,
          4.8,
          4.8,
          4.8,
          4.8,
          4.9,
          4.9,
          4.9,
          4.9,
          4.9,
          4.9,
          4.9,
          4.9,
          4.9,
          4.9,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5.1,
          5.1,
          5.1,
          5.1,
          5.1,
          5.1,
          5.1,
          5.1,
          5.1,
          5.1,
          5.2,
          5.2,
          5.2,
          5.2,
          5.2,
          5.2,
          5.2,
          5.2,
          5.2,
          5.2,
          5.3,
          5.3,
          5.3,
          5.3,
          5.3,
          5.3,
          5.3,
          5.3,
          5.3,
          5.3,
          5.4,
          5.4,
          5.4,
          5.4,
          5.4,
          5.4,
          5.4,
          5.4,
          5.4,
          5.4,
          5.5,
          5.5,
          5.5,
          5.5,
          5.5,
          5.5,
          5.5,
          5.5,
          5.5,
          5.5,
          5.6,
          5.6,
          5.6,
          5.6,
          5.6,
          5.6,
          5.6,
          5.6,
          5.6,
          5.6,
          5.7,
          5.7,
          5.7,
          5.7,
          5.7,
          5.7,
          5.7,
          5.7,
          5.7,
          5.7,
          5.8,
          5.8,
          5.8,
          5.8,
          5.8,
          5.8,
          5.8,
          5.8,
          5.8,
          5.8,
          5.9,
          5.9,
          5.9,
          5.9,
          5.9,
          5.9,
          5.9,
          5.9,
          5.9,
          5.9,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6.1,
          6.1,
          6.1,
          6.1,
          6.1,
          6.1,
          6.1,
          6.1,
          6.1,
          6.1,
          6.2,
          6.2,
          6.2,
          6.2,
          6.2,
          6.2,
          6.2,
          6.2,
          6.2,
          6.2,
          6.3,
          6.3,
          6.3,
          6.3,
          6.3,
          6.3,
          6.3,
          6.3,
          6.3,
          6.3,
          6.4,
          6.4,
          6.4,
          6.4,
          6.4,
          6.4,
          6.4,
          6.4,
          6.4,
          6.4,
          6.5,
          6.5,
          6.5,
          6.5,
          6.5,
          6.5,
          6.5,
          6.5,
          6.5,
          6.5,
          6.6,
          6.6,
          6.6,
          6.6,
          6.6,
          6.6,
          6.6,
          6.6,
          6.6,
          6.6,
          6.7,
          6.7,
          6.7,
          6.7,
          6.7,
          6.7,
          6.7,
          6.7,
          6.7,
          6.7,
          6.8,
          6.8,
          6.8,
          6.8,
          6.8,
          6.8,
          6.8,
          6.8,
          6.8,
          6.8,
          6.9,
          6.9,
          6.9,
          6.9,
          6.9,
          6.9,
          6.9,
          6.9,
          6.9,
          6.9,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7.1,
          7.1,
          7.1,
          7.1,
          7.1,
          7.1,
          7.1,
          7.1,
          7.1,
          7.1,
          7.2,
          7.2,
          7.2,
          7.2,
          7.2,
          7.2,
          7.2,
          7.2,
          7.2,
          7.2,
          7.3,
          7.3,
          7.3,
          7.3,
          7.3,
          7.3,
          7.3,
          7.3,
          7.3,
          7.3,
          7.4,
          7.4,
          7.4,
          7.4,
          7.4,
          7.4,
          7.4,
          7.4,
          7.4,
          7.4,
          7.5,
          7.5,
          7.5,
          7.5,
          7.5,
          7.5,
          7.5,
          7.5,
          7.5,
          7.5,
          7.6,
          7.6,
          7.6,
          7.6,
          7.6,
          7.6,
          7.6,
          7.6,
          7.6,
          7.6,
          7.7,
          7.7,
          7.7,
          7.7,
          7.7,
          7.7,
          7.7,
          7.7,
          7.7,
          7.7,
          7.8,
          7.8,
          7.8,
          7.8,
          7.8,
          7.8,
          7.8,
          7.8,
          7.8,
          7.8,
          7.9,
          7.9,
          7.9,
          7.9,
          7.9,
          7.9,
          7.9,
          7.9,
          7.9,
          7.9,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8.1,
          8.1,
          8.1,
          8.1,
          8.1,
          8.1,
          8.1,
          8.1,
          8.1,
          8.1,
          8.2,
          8.2,
          8.2,
          8.2,
          8.2,
          8.2,
          8.2,
          8.2,
          8.2,
          8.2,
          8.3,
          8.3,
          8.3,
          8.3,
          8.3,
          8.3,
          8.3,
          8.3,
          8.3,
          8.3,
          8.4,
          8.4,
          8.4,
          8.4,
          8.4,
          8.4,
          8.4,
          8.4,
          8.4,
          8.4,
          8.5,
          8.5,
          8.5,
          8.5,
          8.5,
          8.5,
          8.5,
          8.5,
          8.5,
          8.5,
          8.6,
          8.6,
          8.6,
          8.6,
          8.6,
          8.6,
          8.6,
          8.6,
          8.6,
          8.6,
          8.7,
          8.7,
          8.7,
          8.7,
          8.7,
          8.7,
          8.7,
          8.7,
          8.7,
          8.7,
          8.8,
          8.8,
          8.8,
          8.8,
          8.8,
          8.8,
          8.8,
          8.8,
          8.8,
          8.8,
          8.9,
          8.9,
          8.9,
          8.9,
          8.9,
          8.9,
          8.9,
          8.9,
          8.9,
          8.9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9.1,
          9.1,
          9.1,
          9.1,
          9.1,
          9.1,
          9.1,
          9.1,
          9.1,
          9.1,
          9.2,
          9.2,
          9.2,
          9.2,
          9.2,
          9.2,
          9.2,
          9.2,
          9.2,
          9.2,
          9.3,
          9.3,
          9.3,
          9.3,
          9.3,
          9.3,
          9.3,
          9.3,
          9.3,
          9.3,
          9.4,
          9.4,
          9.4,
          9.4,
          9.4,
          9.4,
          9.4,
          9.4,
          9.4,
          9.4,
          9.5,
          9.5,
          9.5,
          9.5,
          9.5,
          9.5,
          9.5,
          9.5,
          9.5,
          9.5,
          9.6,
          9.6,
          9.6,
          9.6,
          9.6,
          9.6,
          9.6,
          9.6,
          9.6,
          9.6,
          9.7,
          9.7,
          9.7,
          9.7,
          9.7,
          9.7,
          9.7,
          9.7,
          9.7,
          9.7,
          9.8,
          9.8,
          9.8,
          9.8,
          9.8,
          9.8,
          9.8,
          9.8,
          9.8,
          9.8,
          9.9,
          9.9,
          9.9,
          9.9,
          9.9,
          9.9,
          9.9,
          9.9,
          9.9,
          9.9
         ],
         "y": [
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9,
          0,
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9
         ],
         "z": [
          0.29289590910141733,
          0.28673566103515646,
          0.2799391918735423,
          0.2723063707258394,
          0.26401996261741306,
          0.2549564741577474,
          0.24455339811080723,
          0.23267903223865122,
          0.21892606634616762,
          0.2063968386625814,
          0.32895610899178473,
          0.32258204761290765,
          0.3153202757471999,
          0.307229918702398,
          0.2978188333131305,
          0.28695730729046537,
          0.27671268689990086,
          0.26461386927543235,
          0.2508574766712583,
          0.23353648792333437,
          0.34234327883568794,
          0.3355457015521946,
          0.3278780093138807,
          0.31910476195075116,
          0.3094067485183694,
          0.29966706064120574,
          0.2881867172887829,
          0.27437948031897735,
          0.25762080614890703,
          0.23652034197854416,
          0.3466224831596823,
          0.33875603521801384,
          0.32986638508412525,
          0.3195530016004402,
          0.3092692026374486,
          0.29733838315267375,
          0.2835565518272535,
          0.26981122055141915,
          0.25500425615215216,
          0.23427902105822895,
          0.346716648734065,
          0.33723284780517987,
          0.3264218000471719,
          0.31434297876910755,
          0.3066752397375098,
          0.3014409941507938,
          0.2944610955228993,
          0.2848517752528723,
          0.2713949791034217,
          0.2513936607735131,
          0.3447524312784082,
          0.3333453697261683,
          0.32091607825182955,
          0.3176025352017648,
          0.3142208558868139,
          0.3098466927481525,
          0.30382886456053393,
          0.2954351391810256,
          0.2832856785751213,
          0.2645592810826197,
          0.341756407801572,
          0.3282005428072222,
          0.32428330021212404,
          0.32198702139370466,
          0.319214243002381,
          0.3154551324383144,
          0.3101683635871944,
          0.30273187175557503,
          0.29181396052439423,
          0.2776434715938957,
          0.3382627860744525,
          0.32988502180877266,
          0.3267996220134552,
          0.32488616461235365,
          0.32246435515377053,
          0.3190599385963839,
          0.31431199588964764,
          0.30755617403399693,
          0.29978675457387527,
          0.2882120287997718,
          0.3345638222316132,
          0.330961529104724,
          0.32835560845912565,
          0.3266869366782597,
          0.3244661079352515,
          0.32126920243685214,
          0.31682931738545417,
          0.3115559108264551,
          0.30571022262724873,
          0.29601907781682313,
          0.33082426835344314,
          0.3314764250989874,
          0.32921849799368724,
          0.3276900647967462,
          0.32551513704270096,
          0.3224290833531881,
          0.3181586282284115,
          0.3146206489244992,
          0.3096576590956711,
          0.30140031766741454,
          0.3271380351934931,
          0.33158585598309565,
          0.32957868940548124,
          0.3281108084570235,
          0.3259031918768156,
          0.32279791324923407,
          0.31935101007095845,
          0.3164030532556386,
          0.3119498672600335,
          0.3044602217659622,
          0.3235580782467914,
          0.33139711434034413,
          0.32959294468819467,
          0.3280773224170277,
          0.32577456831130586,
          0.32260749154099777,
          0.3199471370335079,
          0.3168660350030552,
          0.3124081317844279,
          0.3054414258439203,
          0.3201129804462904,
          0.33097668362298294,
          0.3293045960135347,
          0.32767897649910516,
          0.3252536112449536,
          0.32191723527095567,
          0.31956592871049094,
          0.31631319332663865,
          0.31166152643418127,
          0.30525449126406756,
          0.31681653675276567,
          0.3303825242723408,
          0.32878849028182994,
          0.3270203793371518,
          0.3243818181414225,
          0.32114819513150084,
          0.31860445044023117,
          0.3150329526183592,
          0.31014191486755377,
          0.30559970344209747,
          0.3136734787746756,
          0.32816094786827926,
          0.32809900230762273,
          0.3261525087180203,
          0.3231031502631901,
          0.3200742093935684,
          0.3171808700879282,
          0.3132676478740431,
          0.3085979023096487,
          0.30469635474246287,
          0.31068298431094477,
          0.325913321516219,
          0.3272618505675485,
          0.32495842912003436,
          0.3216455589405619,
          0.31869216003449274,
          0.3153999461893993,
          0.31112169101377307,
          0.3073312327454192,
          0.3047342006589979,
          0.3078408728170687,
          0.3237638057386548,
          0.3262446627181515,
          0.3236304256381,
          0.32003337719576874,
          0.3170597950738428,
          0.31347032942314634,
          0.3086531669622719,
          0.3054383995934127,
          0.3043011758666102,
          0.3051409992805277,
          0.321728398759659,
          0.32506232359583703,
          0.3222009606014086,
          0.3183584718980742,
          0.3152939004395206,
          0.311250709347652,
          0.306950955080973,
          0.30389422633218693,
          0.30378983528529063,
          0.3025761476121836,
          0.31975747790880377,
          0.3238102893628852,
          0.32070159594082304,
          0.3167873581958139,
          0.3134209374379551,
          0.30878638296030436,
          0.3049241668134782,
          0.30251808389551205,
          0.3024344105288957,
          0.30013860548490623,
          0.31783021058783667,
          0.32251273163329425,
          0.319149473859303,
          0.3151450905093707,
          0.3113898573511747,
          0.30616083662790033,
          0.302592647242145,
          0.3010868661095844,
          0.2995397371160008,
          0.2978205332300234,
          0.3159889455574569,
          0.32117984565849667,
          0.31753001694860883,
          0.31346510084865287,
          0.30923579517965294,
          0.3042511901784264,
          0.3006028581060229,
          0.2992766848812355,
          0.2956759769032974,
          0.2956141979614886,
          0.3142298198499327,
          0.3198099796531624,
          0.3158676804545077,
          0.31169596797531973,
          0.3069515326145426,
          0.30217359465893734,
          0.29875082708496764,
          0.2970885417941632,
          0.292051321661414,
          0.29351211871795413,
          0.31257059473664217,
          0.31841291934487176,
          0.3141897577900268,
          0.3098548914927679,
          0.3045664368362325,
          0.29996179522326505,
          0.29689443465263277,
          0.29397011989229405,
          0.2889647985912211,
          0.29150715253536236,
          0.31101633273093887,
          0.3170180109102749,
          0.3125275904368905,
          0.30796075572029347,
          0.302093459999427,
          0.29759780387354884,
          0.2948536035249632,
          0.2903924642120254,
          0.28564021916708415,
          0.289592541242329,
          0.3095278858248474,
          0.3156217532523618,
          0.310818071360884,
          0.3059974160971035,
          0.3000354149520907,
          0.29543597406467326,
          0.2925998495441922,
          0.2873093216666177,
          0.2822110888639928,
          0.287761932211404,
          0.308093697081197,
          0.31421961586046,
          0.30908460889794726,
          0.30398289139091444,
          0.29807072799627254,
          0.2934509324046151,
          0.2901522516981083,
          0.28459534169663825,
          0.2785420014661718,
          0.2860093819872322,
          0.3067139023588778,
          0.3127941491939178,
          0.30737899177970607,
          0.3019270736766524,
          0.2960385231276214,
          0.2914780253288274,
          0.2871152498123458,
          0.2818082758085047,
          0.27612394103157334,
          0.28432934884152217,
          0.3053796628329503,
          0.3113554081265459,
          0.3057420146569753,
          0.2998350689590293,
          0.29394153973920906,
          0.28943418293218226,
          0.2840478617230856,
          0.2788805276858521,
          0.2736462021349405,
          0.28271667837187575,
          0.3040944643702193,
          0.30991058360978396,
          0.3040794708552241,
          0.2977127375078196,
          0.2918046399731007,
          0.2872843910400192,
          0.2817803510522542,
          0.2758017157817998,
          0.2710090515575164,
          0.28116658494884184,
          0.3028480600595321,
          0.3084684433051841,
          0.30240221064933037,
          0.2955645910488038,
          0.28960771044879097,
          0.2850390015927875,
          0.2794475149610348,
          0.27310066974408986,
          0.2682298089447206,
          0.2796746309166043,
          0.3016421451791639,
          0.30701219383570816,
          0.30070907272202535,
          0.2934952424844376,
          0.2875623049928724,
          0.28281737552304365,
          0.27702479125755886,
          0.27097257238288575,
          0.2652861154610845,
          0.2782367048342475,
          0.3004675752693577,
          0.3055531256168732,
          0.2990140915216606,
          0.2917323774366566,
          0.2856377599328414,
          0.28046974235023314,
          0.27452833138549854,
          0.26875000305484675,
          0.2622128695379658,
          0.276848999615958,
          0.2993294549801913,
          0.3040886903043385,
          0.29729632770306413,
          0.2899369872428491,
          0.28373572007196757,
          0.27809051569493887,
          0.2719548504763816,
          0.26643362296397904,
          0.2589931548588706,
          0.27550799113208246,
          0.29822179920245817,
          0.30262677417650874,
          0.2955669187694328,
          0.2881234988332343,
          0.2818165452119449,
          0.27613900625175103,
          0.26930898354541866,
          0.26402383274170294,
          0.25613796352992974,
          0.27421041762693715,
          0.29713903176955986,
          0.3011643860602405,
          0.29383369672615156,
          0.2862874045020839,
          0.2800456824765084,
          0.2741432669871393,
          0.2674286245099408,
          0.2615363815670974,
          0.25365600898417195,
          0.27295326016648025,
          0.29608479025985507,
          0.2997071968356643,
          0.292090856349159,
          0.28443874123565693,
          0.278261459782271,
          0.27211073892649523,
          0.2655524289451141,
          0.2589454908241966,
          0.25101049672884745,
          0.27173372423089664,
          0.2950537140919557,
          0.2982639889456567,
          0.2903442511293763,
          0.28258033527108195,
          0.27644425316799925,
          0.2700390652402738,
          0.26362721812746226,
          0.25627971518945136,
          0.24823745101915573,
          0.27054922249969227,
          0.29404062064659886,
          0.29680698963765045,
          0.28859442910781885,
          0.28071224734955846,
          0.27459032217118173,
          0.26792937568372693,
          0.2616533292839143,
          0.25370343054082534,
          0.24531998780354722,
          0.2693973588318117,
          0.2930513558020491,
          0.2953551353794907,
          0.28684608777580467,
          0.27896663510737857,
          0.2727107649722281,
          0.26578156134874376,
          0.2596305565523015,
          0.25168804875295103,
          0.2427871433038309,
          0.2682759134132334,
          0.2920782763819981,
          0.2939054786508548,
          0.2850920696388013,
          0.27720499911509955,
          0.27091717885949973,
          0.26360770894098795,
          0.25755778379845484,
          0.2495675984974049,
          0.2406210007082448,
          0.26718282902559004,
          0.2911252292518705,
          0.29248958141376474,
          0.28333831799730913,
          0.2756384409839392,
          0.2692429065070928,
          0.26198422736678467,
          0.25544177337955654,
          0.24737007376804085,
          0.23925549192702236,
          0.26611619837784617,
          0.29018735957456615,
          0.2910797313994391,
          0.2816642593727401,
          0.27411869192319327,
          0.2675783470050572,
          0.2604063498990626,
          0.2532871269652666,
          0.24509536007107116,
          0.23954144376607617,
          0.26507425243689997,
          0.289264494457515,
          0.289674314029917,
          0.2801523675655529,
          0.2726360561663813,
          0.2659012607246961,
          0.25881225899350446,
          0.25107289506648334,
          0.24273921062988343,
          0.23978804410789062,
          0.2640553496905188,
          0.2883514849128836,
          0.2882786967735239,
          0.27876736496334653,
          0.27114285914129455,
          0.26420841482934354,
          0.2571806565740306,
          0.24922536599170944,
          0.2407373784154055,
          0.23997727214413025,
          0.2630579662759889,
          0.28745317922477615,
          0.2868894170997762,
          0.27738863276582315,
          0.26963498613235976,
          0.2624951462805673,
          0.2555268345865507,
          0.2475348979603506,
          0.23900248041376973,
          0.24009271789065886,
          0.2620806869093794,
          0.28656713819760127,
          0.28550756501174057,
          0.2760092775669127,
          0.2681180161695912,
          0.2607755512167264,
          0.2538479335086233,
          0.24579639263086783,
          0.2372233260413836,
          0.24014660268438587,
          0.26112219655310814,
          0.28571712929585963,
          0.28413013008649923,
          0.2746413890990974,
          0.2665922846727291,
          0.2590439465038126,
          0.2521487442610707,
          0.24401567378143157,
          0.2374150442585942,
          0.24012756769320137,
          0.26018127276278913,
          0.2848901576429072,
          0.2827732689631147,
          0.2732623128091912,
          0.26505478070600963,
          0.2573005894830439,
          0.25042840412965367,
          0.2421944706335359,
          0.23754203333345023,
          0.24021376384437995,
          0.25925677865784813,
          0.284073244003456,
          0.28146204754174686,
          0.27188096806543843,
          0.26353604515511536,
          0.2557495932484397,
          0.24868777535853623,
          0.24033658954967085,
          0.23765491872872155,
          0.24024619073178938,
          0.2583476564643672,
          0.2832669286487876,
          0.2801533821002904,
          0.2705045166654655,
          0.2621732988389821,
          0.2544402521360274,
          0.24692651649542763,
          0.23852302159968222,
          0.2377000111921171,
          0.24021215380562996,
          0.25745292158228555,
          0.28246981156766604,
          0.2788528172416958,
          0.2691341863224083,
          0.2608047599724897,
          0.2531177204238531,
          0.24522072966186015,
          0.23714772748746007,
          0.23769760524252156,
          0.24013146943999863,
          0.2565716571327042,
          0.28167778484601086,
          0.2775583677854948,
          0.26776340018714184,
          0.2595108806732881,
          0.2517857226396959,
          0.243851974956409,
          0.23573175704015634,
          0.23764403194033482,
          0.24007626519161868,
          0.25570300894480436,
          0.280897115160905,
          0.27626940891764706,
          0.2663816853537976,
          0.2581520922068315,
          0.2504519636807333,
          0.2424566482706013,
          0.23439691927858314,
          0.2375392614922677,
          0.24034874879873427,
          0.2548461809449697,
          0.2801238039832656,
          0.27498316595970207,
          0.26500334034335515,
          0.25678921373704733,
          0.2490982019599679,
          0.24103767716664806,
          0.23443111551213983,
          0.2375182826754282,
          0.24057081862118906,
          0.2540004309140314,
          0.27935652380193227,
          0.27370464312659204,
          0.26362610558020905,
          0.2554176533225424,
          0.24773317033000852,
          0.23959672904620014,
          0.2344172100967371,
          0.23748695145332757,
          0.24031963521280403,
          0.25316506658128285,
          0.2785962305380959,
          0.2724287720095464,
          0.26224986075888035,
          0.25404721864535684,
          0.24636033418249095,
          0.23813607235973674,
          0.234442919992138,
          0.23741190053917946,
          0.2397258835018143,
          0.25233944202679026,
          0.27783898647152383,
          0.27115159416136647,
          0.2608772674188802,
          0.2526732190309514,
          0.24497843573229777,
          0.23665164852051349,
          0.23438956161655358,
          0.2372889439701884,
          0.23910429059780186,
          0.25152295436590855,
          0.27709092249139816,
          0.2698820879479411,
          0.2595815185380185,
          0.2512962051922632,
          0.2435860801578002,
          0.23514900273074985,
          0.23428063769303617,
          0.23711121812642286,
          0.23845515006983115,
          0.2507150406922104,
          0.27634672446857383,
          0.26862841212868704,
          0.2583597358863471,
          0.24991601547620923,
          0.2421873467697457,
          0.2338517067754975,
          0.23413627559464664,
          0.23697174644452706,
          0.23777831307779268,
          0.24991517525711587,
          0.2756070652027483,
          0.2673656156297818,
          0.25713625320557365,
          0.2485318869429736,
          0.24078141651416238,
          0.23271344774626324,
          0.23395892833253928,
          0.23708370848480406,
          0.2370739291669965,
          0.24912286686641444,
          0.2748707930508215,
          0.2661108854144937,
          0.2559111441251971,
          0.24714639249152603,
          0.23935847405934316,
          0.23155910366542934,
          0.23375430105194453,
          0.2371656168067039,
          0.23634212484897463,
          0.24833765647569145,
          0.274136534389931,
          0.2648581980615375,
          0.2546812346412056,
          0.24598867756724968,
          0.23811541479146509,
          0.23037663621856674,
          0.23360957502179067,
          0.23707367260240722,
          0.23557742116899708,
          0.24755911496810568,
          0.27340868096172144,
          0.263765624257447,
          0.25345362950939615,
          0.24489408444983984,
          0.2369708370658392,
          0.22995898200782106,
          0.233467030645677,
          0.23640634005833672,
          0.23479109699054027,
          0.2467868410995977,
          0.27268407189855143,
          0.2626843754716899,
          0.25222502319696427,
          0.24379465366496045,
          0.23582334631462698,
          0.2298155756042545,
          0.23329638764984462,
          0.23571731801599272,
          0.2339774713908084,
          0.24602045959775948,
          0.2719615765722503,
          0.26160206075243364,
          0.25099566779454946,
          0.24268959253663502,
          0.2346517826119582,
          0.22964655651202825,
          0.23311191154508384,
          0.23500493144996085,
          0.23313654105039297,
          0.24525961940188296,
          0.27124273320486547,
          0.260524133124968,
          0.24983310315956164,
          0.24158979480656884,
          0.2334735112236942,
          0.2295022834057782,
          0.2328801611770176,
          0.2342635069310654,
          0.2322684519321252,
          0.24450399203279044,
          0.27052372154537263,
          0.2594452872824339,
          0.2487237403967847,
          0.24047681886714065,
          0.23228416466421625,
          0.22932455395311588,
          0.2326210779219924,
          0.2335047211313725,
          0.23137325396598896,
          0.24375327008201397,
          0.2698090031082441,
          0.25837027162816595,
          0.2476119533282478,
          0.23935996423233058,
          0.23108207548165147,
          0.2291199428213735,
          0.2323376780692718,
          0.2327228951847132,
          0.23045099076106373,
          0.24300716581078485,
          0.26909735646043786,
          0.2572971474673519,
          0.2465015773646173,
          0.23823894686311284,
          0.22987160208435875,
          0.22887643339380115,
          0.2322824216396421,
          0.23191808610751194,
          0.22950169662197115,
          0.24226540985013945,
          0.2682501402506884,
          0.2562233117683984,
          0.24539278002657716,
          0.2371127701986306,
          0.22864890081938877,
          0.22858454112149207,
          0.23220626138189232,
          0.2310903413443238,
          0.22852543339870365,
          0.24152774999418075,
          0.267246133306323,
          0.2551530696143166,
          0.24434457153489453,
          0.23598406267615266,
          0.22753238303250387,
          0.228270546874152,
          0.23210789829518097,
          0.23023963617701365,
          0.22752224299891383,
          0.24079395007921517,
          0.26623990242925466,
          0.25408250687003137,
          0.24329025267035967,
          0.2348519748540457,
          0.2265622104079917,
          0.22793301394476811,
          0.23163841637970273,
          0.22936614867179597,
          0.22649217409778039,
          0.24006378894210278,
          0.2652356065125817,
          0.2530159861206287,
          0.24223804802690435,
          0.23371660695827925,
          0.22558239110516204,
          0.2276732309496187,
          0.23088021257125335,
          0.22846990094716593,
          0.2254352721784397,
          0.239337059451652,
          0.2642037833702381,
          0.2519489550180636,
          0.24118370252785937,
          0.23257676962810658,
          0.2245892514159109,
          0.22740106894890205,
          0.2301029489460705,
          0.22755105112543508,
          0.2243515824130055,
          0.23861356760755392,
          0.26316306924945343,
          0.2508835179203307,
          0.24010861245352375,
          0.2314344599563052,
          0.22358533943163375,
          0.2270997309759111,
          0.2293016767493223,
          0.22660968394507183,
          0.2232412758494557,
          0.2378931317016632,
          0.2621252555121326,
          0.24981909867067378,
          0.23900541428921301,
          0.23028911192756402,
          0.2228773869426554,
          0.22679860711657998,
          0.22848681508973126,
          0.2256458736334698,
          0.22210460783799885,
          0.23717558153692925,
          0.26109027013943187,
          0.2487562993278893,
          0.23790172932417794,
          0.22914033901619185,
          0.22257762691762725,
          0.22646110334487077,
          0.22765311985879724,
          0.2246596937614626,
          0.22094130978795776,
          0.23646075769961977,
          0.26005705525168143,
          0.24769964572767877,
          0.23679746184077052,
          0.2280916796541693,
          0.22225271751634873,
          0.2261049374851403,
          0.22680076818939693,
          0.2236512124038704,
          0.21975150639340632,
          0.23574851088096233,
          0.25902750542308617,
          0.2466442735057487,
          0.23569196444452797,
          0.22711240310195954,
          0.2219388456978817,
          0.22573015562037127,
          0.2259299183042539,
          0.22262062952356243,
          0.21853411214980112,
          0.235038701244422,
          0.25800065332310973,
          0.24558997600016674,
          0.23458669655244632,
          0.226127307255798,
          0.22162845833861097,
          0.22534037062166862,
          0.22503982910027803,
          0.22156791351012595,
          0.21729001616704186,
          0.23433119783538114,
          0.2569736235384691,
          0.24446402343426496,
          0.2334810909123537,
          0.22513403718174232,
          0.22129446581559942,
          0.22506036728725845,
          0.22413214892891878,
          0.22049113076924795,
          0.2160204978340471,
          0.2336258780300164,
          0.25595214743461236,
          0.24332937506479055,
          0.23237493532668074,
          0.22414459957064967,
          0.2209408795592535,
          0.2248309453246207,
          0.22320620252851492,
          0.21939418742212796,
          0.21472454988674547,
          0.2329226270206584,
          0.2549332936107202,
          0.24219333328678286,
          0.231342204731542,
          0.2231404126431985,
          0.22057279539323218,
          0.2245892906931705,
          0.22226104443294364,
          0.21827532565213514,
          0.21339313769837523,
          0.232221337334869,
          0.2539160383440263,
          0.24106515981607246,
          0.23033912117236188,
          0.2221321590353157,
          0.22018776179498478,
          0.22431713382368776,
          0.22129867719877364,
          0.2171199303367233,
          0.21192715071741222,
          0.23152190838595738,
          0.2529064168026858,
          0.23992859105601588,
          0.22934898298031517,
          0.22111811944306645,
          0.21978932510285773,
          0.2237742468970932,
          0.22028275356139324,
          0.21584702011721185,
          0.21043394599615753,
          0.23082424605260343,
          0.2518947963916527,
          0.23879593867457896,
          0.22834204276675832,
          0.22009753750461505,
          0.21935140996902658,
          0.22286221660913658,
          0.2191791150691505,
          0.21455182358551173,
          0.20891435027773755,
          0.23012826228562128,
          0.2508827175197498,
          0.23766114005309044,
          0.22733339637893143,
          0.21899511280954106,
          0.21882020448477552,
          0.22190227693827758,
          0.21805766412062652,
          0.2132350004079584,
          0.20736840822955138,
          0.22943387473985805,
          0.24987599951978456,
          0.23653042937013585,
          0.22632297257329334,
          0.2178737779264929,
          0.21830154546557456,
          0.22093254120824202,
          0.21691862316376623,
          0.21189662352251423,
          0.2057979229766531,
          0.2287410064296117,
          0.24887161425853907,
          0.23540099704561876,
          0.2253104977487856,
          0.2167449370228377,
          0.2177906680291173,
          0.21994851252579195,
          0.21576207565606403,
          0.21053676912461286,
          0.2041995116868092,
          0.22804958540580572,
          0.24786952504155635,
          0.23427276178586726,
          0.2242962629572279,
          0.21578118632547125,
          0.21726872259939423,
          0.21895029192307988,
          0.2145881182590051,
          0.20915550998172072,
          0.2027192108967354,
          0.22735954445354228,
          0.2468689053763061,
          0.2331456136407709,
          0.22327906997786198,
          0.21481340741796928,
          0.2167422431854911,
          0.21793807753440325,
          0.21339684338009346,
          0.20775291855845243,
          0.20124192050716297,
          0.2266708208085602,
          0.24587135895379375,
          0.23201612575266622,
          0.22226106170288418,
          0.21383720217140603,
          0.21619270824302872,
          0.2169119752343499,
          0.2121883397956713,
          0.20632906701799575,
          0.19974004088946104,
          0.22598335589136465,
          0.2448760189844276,
          0.2308912022478183,
          0.2212413348619404,
          0.21285751429820582,
          0.21563205005654776,
          0.21587208168035166,
          0.21096269574051632,
          0.20488402587766957,
          0.19821347117884255,
          0.22529709505783901,
          0.24388017554539956,
          0.22977346119142103,
          0.2202119145747786,
          0.211870816831303,
          0.2150591755034237,
          0.2148184572193179,
          0.20972001867158085,
          0.2034178677373325,
          0.1966627374322525,
          0.22461198736518823,
          0.24288934174711063,
          0.2286658870648056,
          0.21918890797736376,
          0.21087969588050598,
          0.21447473408937226,
          0.2137511909979565,
          0.20846049961855795,
          0.20193066412438448,
          0.19508775961610525,
          0.22392798535225233,
          0.24190061435141635,
          0.22755940129194138,
          0.2181643015348554,
          0.20988913783917595,
          0.21387817186483543,
          0.2126704076696847,
          0.2071842707844332,
          0.20042248601100351,
          0.19348826582179426,
          0.22324504483320684,
          0.2409139668387773,
          0.2264635300264244,
          0.21713703804608406,
          0.20933644091660625,
          0.21327391486092595,
          0.2115761475401686,
          0.205891249612478,
          0.19892742129551913,
          0.1918644505168786,
          0.2225631247037847,
          0.23992863088170935,
          0.2253977052488984,
          0.21610883960294638,
          0.20875942141000545,
          0.2126535200454133,
          0.21046856387726767,
          0.20458152165909263,
          0.19752969838662368,
          0.19021634465177006,
          0.22188218675919438,
          0.23894609332211078,
          0.22437583793955537,
          0.21507932023812473,
          0.2081956113111417,
          0.21214720535766393,
          0.20934775369324557,
          0.20325516693955126,
          0.19611228188415636,
          0.18854401302375726
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "STD"
          }
         },
         "colorscale": [
          [
           1,
           "red"
          ],
          [
           0,
           "blue"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "scene": {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "xaxis": {
          "title": {
           "text": "Alpha"
          }
         },
         "yaxis": {
          "title": {
           "text": "L1 Ratio"
          }
         },
         "zaxis": {
          "title": {
           "text": "Score"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Gráfica 3D: Alpha vs L1_Ratio vs Score (Color por STD)"
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"5b7c946c-1c9c-44f0-83df-80d34922de0e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5b7c946c-1c9c-44f0-83df-80d34922de0e\")) {                    Plotly.newPlot(                        \"5b7c946c-1c9c-44f0-83df-80d34922de0e\",                        [{\"hovertemplate\":\"Alpha=%{x}<br>L1 Ratio=%{y}<br>Score=%{z}<br>STD=%{marker.color}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":[0.4728801335387184,0.4817013661854827,0.49130631122243845,0.501960035718716,0.5134629445044958,0.5266456402171696,0.541715129587993,0.5587254576359675,0.5780724374864337,0.5937760142653865,0.4074131514110777,0.41698345925795494,0.4278142386198395,0.4406446445556819,0.45556509916103416,0.47251120836132093,0.48789593023103794,0.505766996763168,0.5255089015038684,0.5499682970645737,0.3759114894846676,0.38610406164214794,0.3980989654990603,0.4121933780588476,0.4275740673360826,0.44274442143852233,0.46035720595844576,0.48138027840632713,0.5065972781060857,0.5372115999300027,0.35931880860761956,0.3710302632826347,0.3850480243406514,0.4013994811703531,0.4174177292249497,0.43586189992260366,0.45749805414712813,0.47818103038765586,0.49942272745460675,0.5287132942033976,0.35007221054600424,0.36409145488982203,0.38099406737446134,0.3997874325588472,0.41064084354043656,0.41740195394443586,0.42659192715539335,0.43948037309675414,0.45759825915297214,0.48440266347101557,0.3447106686354988,0.3615694501044995,0.38058555445333075,0.38354914406520546,0.386531763166403,0.3909304896739723,0.39751239245055026,0.40720794036417757,0.421755319511681,0.4446166486183859,0.341486008430782,0.36150022927515907,0.36513104448558925,0.36552024647341247,0.3667603856557223,0.36907354481210936,0.37318169187327555,0.3797616682095927,0.39035133998508187,0.41060093276907333,0.3394518054293826,0.3499601288716105,0.3513899296766789,0.3504369876506036,0.35007856002464444,0.35061316617503213,0.35237249398104503,0.35600292235581243,0.3642989772970664,0.38008954087962477,0.33807023825551585,0.3397407989481586,0.339550091807832,0.3374275975767637,0.33567676006033803,0.3345807965280686,0.33422437780098024,0.3357941448687687,0.34127005384335884,0.3524961530341147,0.33702560865388637,0.33074044363551247,0.32913929989465573,0.32599320146772476,0.32306293721631,0.3204213652089897,0.3181540418854769,0.3182516444719985,0.3206681329107283,0.32746926824394473,0.33612908790239715,0.3226695438438544,0.31984922728110016,0.3157513484665927,0.3117400575849003,0.307715064272473,0.30427162662550755,0.30250016187343126,0.30196192240147585,0.30455967247381516,0.3352671059617416,0.31532507285367234,0.3114377545643648,0.3064749956348863,0.3014637954663352,0.2961875708577287,0.2918190667633584,0.2881261795010447,0.28499589536708037,0.2835559787606079,0.33437202767876567,0.3085765050073532,0.30373235880074434,0.2980017774929314,0.2920087686411077,0.28561865178063994,0.280304626939876,0.2749523967341846,0.26961880534305893,0.26468960779647355,0.333404838439939,0.3023135134683635,0.29659850504583,0.2901472828837048,0.2832513548194423,0.2761327349574763,0.2696699130459248,0.2628213962999806,0.25548221931131965,0.2477182938923026,0.33234459680722117,0.29901063987127885,0.2899306095955534,0.28280854002400185,0.2750301707198551,0.2672967535770442,0.2597727307348578,0.2516099113432252,0.24259933430208044,0.23217552000485694,0.33118184556594993,0.2959133584754912,0.28367961657455054,0.275843106637014,0.2673147011418287,0.2590144677026055,0.25051526611091074,0.24118030571898616,0.2307747257388411,0.219322976254482,0.3299144123809765,0.2928031541791328,0.2777548556932979,0.26927650478686266,0.260005762071577,0.25119808402288274,0.2418249876549058,0.2314491711447608,0.2197517457942704,0.20790380997723384,0.32854469183145,0.28963946691258297,0.27213531752693587,0.263043993406068,0.2531427583035185,0.24378749536621286,0.2336238491043161,0.22241340390426256,0.2100334278482492,0.197461336168777,0.3270778665544832,0.2863943334697499,0.2667901669775465,0.25711344643300543,0.24677470088786474,0.23676951039218486,0.22584721627495877,0.21383514376127816,0.20133131565105242,0.18782534164448678,0.3255207349786583,0.28312602502425094,0.2616789690805543,0.25142964944216706,0.24067438116909498,0.23006870953519953,0.21844146887587965,0.20569128312972149,0.19312265012904564,0.1801637768741747,0.32388093698288956,0.2798561100846484,0.25677052463188726,0.2460004047877978,0.23486422385910394,0.22363422537860195,0.21146694880085518,0.1983181915902571,0.18531762728038928,0.1735592852848735,0.322166443890135,0.27657889350563086,0.2520701643398048,0.2407848241225855,0.2292809952979453,0.2174874288731058,0.20477238311229332,0.19148834513849625,0.17786188193318694,0.16756021622428577,0.3203852257759628,0.2733086417655281,0.2475472707144828,0.2357697316202463,0.2239058055396223,0.21158508140600815,0.19831379687547665,0.18493892929853256,0.1716226880490956,0.1616541949778803,0.31854503855761096,0.27005962003477463,0.24319352150704912,0.23091742993348371,0.2186980756246856,0.20591043027591666,0.1921187163753747,0.1786226820139732,0.16587140388658542,0.15583065318685943,0.3166532923366081,0.2668134336940405,0.23899429039176842,0.22625170398478864,0.21369834895583512,0.2004763011886492,0.18634465966589422,0.17252374796523404,0.16066468838384082,0.15010238091129083,0.3147169749198814,0.26357462187392966,0.23491978242233247,0.22173799898579416,0.2088673450681807,0.19523217252312522,0.18094334661144876,0.16663029131078022,0.15553342733381953,0.144509240615076,0.3127426127161931,0.2603481073985881,0.23099034003542834,0.21741113778124954,0.2041961811545883,0.19015572360414124,0.1757082015974619,0.16157986139484953,0.1504983916085242,0.13971282459592657,0.3107362567683288,0.25714052167339957,0.2271819849841278,0.21329102743226946,0.19967626301999,0.1852395597422014,0.1706285275028778,0.1567770232721188,0.14556931189357902,0.1350651547468092,0.30870348546519194,0.2539485612421555,0.22348901885268607,0.20929444440805817,0.1953012330356211,0.18045535748390318,0.16569966028303443,0.1523586945746133,0.14080285246819113,0.13053266019655,0.3066494180742772,0.2507766799156004,0.2198839041088668,0.20541651088010432,0.19106479582363323,0.17584175029416121,0.16091797979445752,0.14803761289915987,0.13639500310367114,0.12611698320030446,0.304578735031577,0.24762889019099374,0.21640298426463145,0.20165099737186798,0.18696449047894234,0.17147923268051782,0.15626831893672863,0.14382587597523153,0.13236541531782764,0.12186199582018319,0.30249570217654037,0.24450962995711603,0.21301963371482646,0.19796952371047621,0.18299431737719468,0.16734216223439782,0.15200090646941455,0.13973405823912827,0.12844439445348133,0.11773252204724025,0.30040419699609733,0.24141582993509786,0.2097282909584795,0.1944164033507943,0.17913507193779063,0.1633180463632478,0.14799829570595105,0.13577289441995383,0.12463860544465982,0.11378432758835837,0.298307735556735,0.23835199031754153,0.20652624682723925,0.19096266148437674,0.17538395064158166,0.15940429459886418,0.14438411870124906,0.13195287524830573,0.12095590849680375,0.10988351291082861,0.29620949923717355,0.23531869676270695,0.20340871272733288,0.1876051982889947,0.17173747886634586,0.15558184958911775,0.14086434391989416,0.12851699367402966,0.11739319850316712,0.10605083767743316,0.2941123606799728,0.23231918463664883,0.200373230586777,0.18433955904707264,0.16819288538548513,0.1518592190496849,0.1374424942364811,0.1252206291166811,0.1139886101561503,0.10243228814525314,0.2920189085951862,0.22935357521997876,0.19739161791277943,0.18116391294787368,0.16472748197031334,0.14823690480933516,0.13412348460692328,0.12202149453003376,0.11072390591025516,0.09908220299538385,0.2899314712002887,0.22642571881156207,0.1945101755439721,0.17807509453161205,0.16137963741190892,0.14471397859356033,0.13091138155183604,0.11892618250371062,0.107577410763943,0.09602214586769685,0.2878521381855515,0.22353181536892394,0.19170148106526713,0.17507068536124606,0.1581173865512739,0.14129014738832515,0.12781305007243837,0.11593817275972255,0.10440267764058979,0.0941218647746585,0.2857827811666973,0.22067450612706166,0.1889628332728862,0.17214773838738132,0.15494569646844555,0.138120366424141,0.1248297939796328,0.11306137537580241,0.10140776329671544,0.09344976193158899,0.28372507263569946,0.2178554979199935,0.1862952498500306,0.16930509550712458,0.15195548321807828,0.13525252285689002,0.1221037960856738,0.11030073732568499,0.09861012811519307,0.09274512609344059,0.28168050345318374,0.2150743539151307,0.18369259101388716,0.16653889832224542,0.1490407589703431,0.13253315487212805,0.11947773584750843,0.10765315151636874,0.0960176407519554,0.09135549843077113,0.27965039894672944,0.2123321212193482,0.18115311915846202,0.16384197379690235,0.1461954077007174,0.129892840301607,0.11692015399533195,0.10515131248093225,0.09364442731629886,0.09011898688580994,0.2776359336914424,0.2096279025518525,0.17867521271735287,0.16120888812275605,0.1434224223933536,0.12733332846184275,0.11445984874191635,0.10265988621836071,0.09221860806620487,0.08902685052107548,0.27563814505572476,0.20696577631650293,0.17625639321526898,0.1586404650923522,0.14072165523504376,0.12485696969808,0.11208442402411115,0.100229130930397,0.09162543135161624,0.08802004123353956,0.2736579455976033,0.20434107409600918,0.1738951847817411,0.15613521715828685,0.13809106951828184,0.12246306854276566,0.1097948990659433,0.09793483671681487,0.09129698115810451,0.08708674806004542,0.27169613439616513,0.20176040739927437,0.17158960034033682,0.15367255551759823,0.13553084974723972,0.12015406973954847,0.10759268688208175,0.09578439464511332,0.09008386871907821,0.08623460775185739,0.26975340740055903,0.19922161597410817,0.169350135741366,0.1512901025582885,0.13304033522173228,0.11793064999162427,0.10547942589967217,0.09378121170293156,0.08894715149639151,0.08531175730313226,0.26783036687531797,0.1967217929119384,0.1672038761462732,0.14896676511359302,0.130613976484039,0.11582735059947534,0.10345686650334782,0.09192325798179428,0.08797094766848085,0.08442453563386926,0.265927530016485,0.19426153745692365,0.16510811968534306,0.14670073135949557,0.12822660113364243,0.11383336764715458,0.10152640637174162,0.09038076015865541,0.08706951259252596,0.08359468671153955,0.2640453368083088,0.19184031751584169,0.16306172692690035,0.14449092054994844,0.1259035668004179,0.11190048253401373,0.09968523586231928,0.08980566071832706,0.08622348460606105,0.08281129071095021,0.26218415718555527,0.18945711970265827,0.16106375576585372,0.14233663240425543,0.12377847612262174,0.11002950003743092,0.09782012955814945,0.08940514805495406,0.08544014766239107,0.08202171864350691,0.26034429756151656,0.1871136028489126,0.15911266373812527,0.14023792681456168,0.12187539792180278,0.10820765342070056,0.09604335890363276,0.08911000391976212,0.08471342169467387,0.08104419523418213,0.25852600677713966,0.1848081658515259,0.15720725247953785,0.1381922793964486,0.12002958156664152,0.10646015964914056,0.09436792508583246,0.08812211966072299,0.08394959862999661,0.08013296551330207,0.25672948152231445,0.182540341572718,0.1553461549412083,0.13619955605432854,0.11824118063117517,0.10477394889666311,0.09278942854047306,0.08718497485630393,0.08320965928096719,0.07951409335272949,0.2549548712760942,0.18031054172801925,0.15352727468151156,0.13425859882303837,0.11650869206772146,0.1031493785691459,0.091309402768235,0.08633766553769728,0.08249018609681483,0.07908599217970125,0.25320228280850177,0.17811766855383349,0.15174911378663714,0.13236812694575795,0.11483241303138056,0.10158649399049687,0.08992990987824787,0.08557693119271792,0.08178880430307976,0.07867024562658305,0.2514717842830289,0.1759589777072673,0.15001233508859765,0.1305470977943874,0.11321269174373695,0.10008506707632021,0.08865023047976223,0.08487227944811919,0.08113541185731697,0.07826623048217625,0.24976340899537242,0.17384013432439216,0.14829889406969854,0.12877840358520215,0.11164922134634021,0.09864575750441683,0.08785540736206232,0.08420901063790563,0.08046943056426915,0.07787361392593983,0.24807715878095513,0.17175746369629633,0.1466430297820542,0.1270539185634438,0.11014156209206487,0.09726978400277424,0.08746182118754528,0.08358490965002953,0.0796773443724085,0.07749189369261607,0.2464130071207922,0.1697101616443461,0.14502593465808322,0.12537299364811202,0.10869012322734604,0.09596556107452794,0.08716543256226032,0.08299760876470935,0.07893130146818117,0.07712064007340848,0.24477090197247914,0.16769826790862688,0.14344670414707802,0.12373523124544665,0.10730253018041187,0.09466745927117626,0.08697490016898954,0.0823782541419651,0.0782998636945087,0.07676207869028964,0.24315076835095997,0.16572161876109767,0.1418950760811856,0.12213950933228114,0.10596019167695746,0.09338926540245372,0.08638199663982626,0.08176900780204116,0.07795789382045733,0.0764105157024898,0.24155251068115727,0.16377968596319875,0.1403774281006151,0.12058536182953213,0.10465814005019401,0.09216622616462919,0.0856370922061294,0.08118438454708084,0.07762451437608953,0.07606835912587771,0.2399760149428216,0.16187139485152224,0.1388937205014929,0.11907235164704974,0.10339651297044244,0.09101425597804384,0.08493630197053438,0.08062062983007107,0.07730024576498337,0.07573529857014899,0.23842115062597188,0.1599971086148272,0.1374430836690669,0.1175755460698574,0.10216385621993684,0.08992178667023268,0.08430407021331932,0.080096836179604,0.07698734103944194,0.07541097794942961,0.23688777251366,0.15815578293677734,0.13602506127084338,0.11611943376961413,0.10098179136032767,0.08888964507135645,0.0837094403742949,0.07959068625654063,0.07668022624123716,0.07509509833511331,0.2353757223072481,0.1563470903362696,0.1346385031102175,0.11470188607944312,0.09983886371471973,0.08791833153218863,0.0831457314185172,0.0790783830507784,0.07638119765662012,0.07478737834071492,0.23388483010810737,0.15457110905010785,0.13328326392841888,0.11332150570788763,0.0987342944198904,0.08700636107230843,0.08261717915834947,0.0784631553825815,0.07609004576516189,0.07448757383344586,0.23241491576829368,0.15304691929243475,0.13195881110518715,0.1119846456459565,0.09766812578411545,0.08615432221543157,0.08213274183205024,0.07788076826099656,0.07580652038877418,0.07419544263583003,0.23096579012162274,0.15180613781793234,0.1306640101549461,0.11077368515182527,0.09663942382687232,0.08555347224074064,0.0816762135915288,0.07733102806908705,0.07553041577719116,0.07391077343804195,0.22953725610563053,0.1505984439624236,0.12939891740185808,0.10959994214116449,0.09564852567997238,0.08528067643261825,0.08124361204782711,0.07695576679857491,0.0752614572632721,0.07363337012653182,0.22812910978386106,0.14941614619628585,0.12816256053638325,0.108461032269582,0.09469504718453528,0.0850621531471898,0.08076109375936866,0.07670250497684472,0.07499945062324259,0.07336306097210378,0.22674114127716608,0.14825633206258496,0.12695477064532754,0.10735775317477925,0.09377902004471715,0.08489776717889111,0.0802927532488086,0.07645592220400332,0.07474416759823418,0.07309969655993794,0.2253731356118534,0.1471198292438729,0.1257748179401466,0.10631416435855869,0.09289812691495343,0.08478564338616122,0.07984713919649203,0.0762177870193198,0.07449541819241327,0.07284303577845287,0.22402487349187325,0.14600680025498403,0.12462210839938825,0.10533839448407929,0.09205353806329816,0.08451217414324237,0.07940992065583292,0.07598377670078489,0.07425303226001109,0.07259278084236308,0.22269613200153862,0.14491675037705304,0.12349639284814895,0.10439422777121324,0.0912441726958657,0.08397534495795309,0.07900326331036978,0.07575582976431365,0.07401686391840748,0.07234913351674689,0.22138668524486854,0.14384907700416938,0.12239646826848011,0.10348105833191602,0.09044007120406891,0.08346240610570814,0.07861344658969353,0.07553379027523835,0.07378678547278497,0.07211201703934139,0.22009630492677087,0.1428038130483568,0.12132242470856135,0.10259850286228091,0.0896516046707753,0.08297929402889115,0.07824020752624705,0.07531746358853814,0.07356263258677523,0.07188183635748027,0.21882476088127215,0.14178010668976151,0.12027374642890448,0.10174589501760187,0.08889778536286767,0.08253857248175359,0.0778815300353614,0.0751052200456418,0.07334435008037721,0.07165593081722843,0.21757182155110635,0.14077745849943704,0.11926004126668821,0.10092325252039033,0.08817834475984414,0.08212287668647296,0.07747825518022312,0.07489987598451216,0.07313060532009615,0.07143833616205848,0.21633725442296226,0.13979557348844499,0.11827282833135992,0.10012976373297389,0.08748474140863705,0.0817239920376628,0.07707042799619052,0.07469985834066681,0.07292379781461021,0.0712273171935761,0.21512082642203686,0.13883403467882716,0.11731103426601562,0.09936070389508551,0.08683149883773128,0.0813421569119993,0.07668308232139805,0.07450548152382191,0.07272267188624089,0.07102625421038147,0.21392230426943923,0.1378920192083805,0.11636202403573437,0.0986147356979747,0.0862102233550825,0.08097512959161415,0.07629625460903755,0.0743158682567452,0.07253280409058278,0.07087090888006158,0.21274145480554996,0.13696317257440052,0.11544967151620311,0.09788028468337438,0.0856205211487865,0.08062478068047708,0.07601780248377056,0.07414576016626771,0.07238545822236264,0.07072172985607579,0.21157804528222723,0.1360602706404401,0.11456054549157631,0.09717950742839859,0.0850630552514402,0.08029691688566092,0.07587549479356832,0.07400889143839891,0.0722434154756286,0.07057844151493323,0.210431843626469,0.13517607843000373,0.11369523197247272,0.09650026640260721,0.08455888687767066,0.08001253384493913,0.07575133905804722,0.07387665478976412,0.07210637551548983,0.07044107813510488,0.20930261867803845,0.13431021047118946,0.11285219385290028,0.0958427331245372,0.0840890755417675,0.0797254965900579,0.07562998607370512,0.07374889933524639,0.07197428290019513,0.07031265601396364,0.2081901404031209,0.13346231183191357,0.11203168728989218,0.09520607252415444,0.08364965344717357,0.07943356528083856,0.07551275577594396,0.07362552218479151,0.07184709653509865,0.0701874943202183,0.20709418008614586,0.13263203710929808,0.11123324518152805,0.09459038221240675,0.08352481119270429,0.07914899843032491,0.07539963871934942,0.07350642390533657,0.07172479598263753,0.0703111710418912,0.2060145105015843,0.13181883142558753,0.1104565075206111,0.09399516282011859,0.08342919838321039,0.07887451758159851,0.07529047024369488,0.07339152010629789,0.0716073784941984,0.07049021685970247,0.2049509060674013,0.1310227892082444,0.10970168985711469,0.09341983775728344,0.08335949842313896,0.07862118561882242,0.07518512492557602,0.07328074026460406,0.07149485896876467,0.07067832479294277,0.20390314298175882,0.13024336449906398,0.10896734628020162,0.09286436931117395,0.08331267357674504,0.07837852345371707,0.0750834947119523,0.07317402661670587,0.07138726763164659,0.07087544635661244,0.2028709993443136,0.12948030722976336,0.10825232811432021,0.09233059432732503,0.08328945313386273,0.07814726919741721,0.07498549202416523,0.07307131534167077,0.07128465622700567,0.07108260873523538,0.20185425526354295,0.12873307958030242,0.10755541963221356,0.09181359839004109,0.083288227276901,0.07792665623504029,0.07489102910657798,0.07297247525545311,0.07118709261635851,0.07129984000215905,0.20085269295117408,0.12800154478134973,0.10687832853392061,0.09131539308559511,0.08330406622411814,0.07771680430270127,0.07480001635091357,0.0728774426332866,0.07109466153613904,0.07152686468233366,0.19986609680485792,0.12728540544402686,0.10622064987971115,0.09083579131201493,0.08300149872782688,0.07751562159107778,0.07471240290737556,0.07278636990109985,0.07106464924795855,0.07176425087880592,0.19889425348012865,0.12658421349423762,0.10558151759662848,0.0903733086529484,0.08272084822110534,0.0773261641492128,0.0746281049969053,0.07269926185215035,0.07123867363598123,0.07201229582516887,0.1979369519525187,0.1258980092501154,0.10494994671884779,0.0899288328404282,0.0824332290078498,0.07709622662921607,0.0745470678013816,0.0726161402181659,0.07142003809222815,0.07227127843930486],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"scene\":\"scene\",\"showlegend\":false,\"type\":\"scatter3d\",\"x\":[0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.4,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.7,0.7,0.7,0.7,0.7,0.7,0.7,0.7,0.7,0.7,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.1,1.1,1.1,1.1,1.1,1.1,1.1,1.1,1.1,1.1,1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.3,1.3,1.3,1.3,1.3,1.3,1.3,1.3,1.3,1.3,1.4,1.4,1.4,1.4,1.4,1.4,1.4,1.4,1.4,1.4,1.5,1.5,1.5,1.5,1.5,1.5,1.5,1.5,1.5,1.5,1.6,1.6,1.6,1.6,1.6,1.6,1.6,1.6,1.6,1.6,1.7,1.7,1.7,1.7,1.7,1.7,1.7,1.7,1.7,1.7,1.8,1.8,1.8,1.8,1.8,1.8,1.8,1.8,1.8,1.8,1.9,1.9,1.9,1.9,1.9,1.9,1.9,1.9,1.9,1.9,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.1,2.1,2.1,2.1,2.1,2.1,2.1,2.1,2.1,2.1,2.2,2.2,2.2,2.2,2.2,2.2,2.2,2.2,2.2,2.2,2.3,2.3,2.3,2.3,2.3,2.3,2.3,2.3,2.3,2.3,2.4,2.4,2.4,2.4,2.4,2.4,2.4,2.4,2.4,2.4,2.5,2.5,2.5,2.5,2.5,2.5,2.5,2.5,2.5,2.5,2.6,2.6,2.6,2.6,2.6,2.6,2.6,2.6,2.6,2.6,2.7,2.7,2.7,2.7,2.7,2.7,2.7,2.7,2.7,2.7,2.8,2.8,2.8,2.8,2.8,2.8,2.8,2.8,2.8,2.8,2.9,2.9,2.9,2.9,2.9,2.9,2.9,2.9,2.9,2.9,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.1,3.1,3.1,3.1,3.1,3.1,3.1,3.1,3.1,3.1,3.2,3.2,3.2,3.2,3.2,3.2,3.2,3.2,3.2,3.2,3.3,3.3,3.3,3.3,3.3,3.3,3.3,3.3,3.3,3.3,3.4,3.4,3.4,3.4,3.4,3.4,3.4,3.4,3.4,3.4,3.5,3.5,3.5,3.5,3.5,3.5,3.5,3.5,3.5,3.5,3.6,3.6,3.6,3.6,3.6,3.6,3.6,3.6,3.6,3.6,3.7,3.7,3.7,3.7,3.7,3.7,3.7,3.7,3.7,3.7,3.8,3.8,3.8,3.8,3.8,3.8,3.8,3.8,3.8,3.8,3.9,3.9,3.9,3.9,3.9,3.9,3.9,3.9,3.9,3.9,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.1,4.1,4.1,4.1,4.1,4.1,4.1,4.1,4.1,4.1,4.2,4.2,4.2,4.2,4.2,4.2,4.2,4.2,4.2,4.2,4.3,4.3,4.3,4.3,4.3,4.3,4.3,4.3,4.3,4.3,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.5,4.5,4.5,4.5,4.5,4.5,4.5,4.5,4.5,4.5,4.6,4.6,4.6,4.6,4.6,4.6,4.6,4.6,4.6,4.6,4.7,4.7,4.7,4.7,4.7,4.7,4.7,4.7,4.7,4.7,4.8,4.8,4.8,4.8,4.8,4.8,4.8,4.8,4.8,4.8,4.9,4.9,4.9,4.9,4.9,4.9,4.9,4.9,4.9,4.9,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.1,5.1,5.1,5.1,5.1,5.1,5.1,5.1,5.1,5.1,5.2,5.2,5.2,5.2,5.2,5.2,5.2,5.2,5.2,5.2,5.3,5.3,5.3,5.3,5.3,5.3,5.3,5.3,5.3,5.3,5.4,5.4,5.4,5.4,5.4,5.4,5.4,5.4,5.4,5.4,5.5,5.5,5.5,5.5,5.5,5.5,5.5,5.5,5.5,5.5,5.6,5.6,5.6,5.6,5.6,5.6,5.6,5.6,5.6,5.6,5.7,5.7,5.7,5.7,5.7,5.7,5.7,5.7,5.7,5.7,5.8,5.8,5.8,5.8,5.8,5.8,5.8,5.8,5.8,5.8,5.9,5.9,5.9,5.9,5.9,5.9,5.9,5.9,5.9,5.9,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.1,6.1,6.1,6.1,6.1,6.1,6.1,6.1,6.1,6.1,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.3,6.3,6.3,6.3,6.3,6.3,6.3,6.3,6.3,6.3,6.4,6.4,6.4,6.4,6.4,6.4,6.4,6.4,6.4,6.4,6.5,6.5,6.5,6.5,6.5,6.5,6.5,6.5,6.5,6.5,6.6,6.6,6.6,6.6,6.6,6.6,6.6,6.6,6.6,6.6,6.7,6.7,6.7,6.7,6.7,6.7,6.7,6.7,6.7,6.7,6.8,6.8,6.8,6.8,6.8,6.8,6.8,6.8,6.8,6.8,6.9,6.9,6.9,6.9,6.9,6.9,6.9,6.9,6.9,6.9,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.1,7.1,7.1,7.1,7.1,7.1,7.1,7.1,7.1,7.1,7.2,7.2,7.2,7.2,7.2,7.2,7.2,7.2,7.2,7.2,7.3,7.3,7.3,7.3,7.3,7.3,7.3,7.3,7.3,7.3,7.4,7.4,7.4,7.4,7.4,7.4,7.4,7.4,7.4,7.4,7.5,7.5,7.5,7.5,7.5,7.5,7.5,7.5,7.5,7.5,7.6,7.6,7.6,7.6,7.6,7.6,7.6,7.6,7.6,7.6,7.7,7.7,7.7,7.7,7.7,7.7,7.7,7.7,7.7,7.7,7.8,7.8,7.8,7.8,7.8,7.8,7.8,7.8,7.8,7.8,7.9,7.9,7.9,7.9,7.9,7.9,7.9,7.9,7.9,7.9,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.1,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.2,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.3,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.4,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.5,8.6,8.6,8.6,8.6,8.6,8.6,8.6,8.6,8.6,8.6,8.7,8.7,8.7,8.7,8.7,8.7,8.7,8.7,8.7,8.7,8.8,8.8,8.8,8.8,8.8,8.8,8.8,8.8,8.8,8.8,8.9,8.9,8.9,8.9,8.9,8.9,8.9,8.9,8.9,8.9,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.1,9.1,9.1,9.1,9.1,9.1,9.1,9.1,9.1,9.1,9.2,9.2,9.2,9.2,9.2,9.2,9.2,9.2,9.2,9.2,9.3,9.3,9.3,9.3,9.3,9.3,9.3,9.3,9.3,9.3,9.4,9.4,9.4,9.4,9.4,9.4,9.4,9.4,9.4,9.4,9.5,9.5,9.5,9.5,9.5,9.5,9.5,9.5,9.5,9.5,9.6,9.6,9.6,9.6,9.6,9.6,9.6,9.6,9.6,9.6,9.7,9.7,9.7,9.7,9.7,9.7,9.7,9.7,9.7,9.7,9.8,9.8,9.8,9.8,9.8,9.8,9.8,9.8,9.8,9.8,9.9,9.9,9.9,9.9,9.9,9.9,9.9,9.9,9.9,9.9],\"y\":[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\"z\":[0.29289590910141733,0.28673566103515646,0.2799391918735423,0.2723063707258394,0.26401996261741306,0.2549564741577474,0.24455339811080723,0.23267903223865122,0.21892606634616762,0.2063968386625814,0.32895610899178473,0.32258204761290765,0.3153202757471999,0.307229918702398,0.2978188333131305,0.28695730729046537,0.27671268689990086,0.26461386927543235,0.2508574766712583,0.23353648792333437,0.34234327883568794,0.3355457015521946,0.3278780093138807,0.31910476195075116,0.3094067485183694,0.29966706064120574,0.2881867172887829,0.27437948031897735,0.25762080614890703,0.23652034197854416,0.3466224831596823,0.33875603521801384,0.32986638508412525,0.3195530016004402,0.3092692026374486,0.29733838315267375,0.2835565518272535,0.26981122055141915,0.25500425615215216,0.23427902105822895,0.346716648734065,0.33723284780517987,0.3264218000471719,0.31434297876910755,0.3066752397375098,0.3014409941507938,0.2944610955228993,0.2848517752528723,0.2713949791034217,0.2513936607735131,0.3447524312784082,0.3333453697261683,0.32091607825182955,0.3176025352017648,0.3142208558868139,0.3098466927481525,0.30382886456053393,0.2954351391810256,0.2832856785751213,0.2645592810826197,0.341756407801572,0.3282005428072222,0.32428330021212404,0.32198702139370466,0.319214243002381,0.3154551324383144,0.3101683635871944,0.30273187175557503,0.29181396052439423,0.2776434715938957,0.3382627860744525,0.32988502180877266,0.3267996220134552,0.32488616461235365,0.32246435515377053,0.3190599385963839,0.31431199588964764,0.30755617403399693,0.29978675457387527,0.2882120287997718,0.3345638222316132,0.330961529104724,0.32835560845912565,0.3266869366782597,0.3244661079352515,0.32126920243685214,0.31682931738545417,0.3115559108264551,0.30571022262724873,0.29601907781682313,0.33082426835344314,0.3314764250989874,0.32921849799368724,0.3276900647967462,0.32551513704270096,0.3224290833531881,0.3181586282284115,0.3146206489244992,0.3096576590956711,0.30140031766741454,0.3271380351934931,0.33158585598309565,0.32957868940548124,0.3281108084570235,0.3259031918768156,0.32279791324923407,0.31935101007095845,0.3164030532556386,0.3119498672600335,0.3044602217659622,0.3235580782467914,0.33139711434034413,0.32959294468819467,0.3280773224170277,0.32577456831130586,0.32260749154099777,0.3199471370335079,0.3168660350030552,0.3124081317844279,0.3054414258439203,0.3201129804462904,0.33097668362298294,0.3293045960135347,0.32767897649910516,0.3252536112449536,0.32191723527095567,0.31956592871049094,0.31631319332663865,0.31166152643418127,0.30525449126406756,0.31681653675276567,0.3303825242723408,0.32878849028182994,0.3270203793371518,0.3243818181414225,0.32114819513150084,0.31860445044023117,0.3150329526183592,0.31014191486755377,0.30559970344209747,0.3136734787746756,0.32816094786827926,0.32809900230762273,0.3261525087180203,0.3231031502631901,0.3200742093935684,0.3171808700879282,0.3132676478740431,0.3085979023096487,0.30469635474246287,0.31068298431094477,0.325913321516219,0.3272618505675485,0.32495842912003436,0.3216455589405619,0.31869216003449274,0.3153999461893993,0.31112169101377307,0.3073312327454192,0.3047342006589979,0.3078408728170687,0.3237638057386548,0.3262446627181515,0.3236304256381,0.32003337719576874,0.3170597950738428,0.31347032942314634,0.3086531669622719,0.3054383995934127,0.3043011758666102,0.3051409992805277,0.321728398759659,0.32506232359583703,0.3222009606014086,0.3183584718980742,0.3152939004395206,0.311250709347652,0.306950955080973,0.30389422633218693,0.30378983528529063,0.3025761476121836,0.31975747790880377,0.3238102893628852,0.32070159594082304,0.3167873581958139,0.3134209374379551,0.30878638296030436,0.3049241668134782,0.30251808389551205,0.3024344105288957,0.30013860548490623,0.31783021058783667,0.32251273163329425,0.319149473859303,0.3151450905093707,0.3113898573511747,0.30616083662790033,0.302592647242145,0.3010868661095844,0.2995397371160008,0.2978205332300234,0.3159889455574569,0.32117984565849667,0.31753001694860883,0.31346510084865287,0.30923579517965294,0.3042511901784264,0.3006028581060229,0.2992766848812355,0.2956759769032974,0.2956141979614886,0.3142298198499327,0.3198099796531624,0.3158676804545077,0.31169596797531973,0.3069515326145426,0.30217359465893734,0.29875082708496764,0.2970885417941632,0.292051321661414,0.29351211871795413,0.31257059473664217,0.31841291934487176,0.3141897577900268,0.3098548914927679,0.3045664368362325,0.29996179522326505,0.29689443465263277,0.29397011989229405,0.2889647985912211,0.29150715253536236,0.31101633273093887,0.3170180109102749,0.3125275904368905,0.30796075572029347,0.302093459999427,0.29759780387354884,0.2948536035249632,0.2903924642120254,0.28564021916708415,0.289592541242329,0.3095278858248474,0.3156217532523618,0.310818071360884,0.3059974160971035,0.3000354149520907,0.29543597406467326,0.2925998495441922,0.2873093216666177,0.2822110888639928,0.287761932211404,0.308093697081197,0.31421961586046,0.30908460889794726,0.30398289139091444,0.29807072799627254,0.2934509324046151,0.2901522516981083,0.28459534169663825,0.2785420014661718,0.2860093819872322,0.3067139023588778,0.3127941491939178,0.30737899177970607,0.3019270736766524,0.2960385231276214,0.2914780253288274,0.2871152498123458,0.2818082758085047,0.27612394103157334,0.28432934884152217,0.3053796628329503,0.3113554081265459,0.3057420146569753,0.2998350689590293,0.29394153973920906,0.28943418293218226,0.2840478617230856,0.2788805276858521,0.2736462021349405,0.28271667837187575,0.3040944643702193,0.30991058360978396,0.3040794708552241,0.2977127375078196,0.2918046399731007,0.2872843910400192,0.2817803510522542,0.2758017157817998,0.2710090515575164,0.28116658494884184,0.3028480600595321,0.3084684433051841,0.30240221064933037,0.2955645910488038,0.28960771044879097,0.2850390015927875,0.2794475149610348,0.27310066974408986,0.2682298089447206,0.2796746309166043,0.3016421451791639,0.30701219383570816,0.30070907272202535,0.2934952424844376,0.2875623049928724,0.28281737552304365,0.27702479125755886,0.27097257238288575,0.2652861154610845,0.2782367048342475,0.3004675752693577,0.3055531256168732,0.2990140915216606,0.2917323774366566,0.2856377599328414,0.28046974235023314,0.27452833138549854,0.26875000305484675,0.2622128695379658,0.276848999615958,0.2993294549801913,0.3040886903043385,0.29729632770306413,0.2899369872428491,0.28373572007196757,0.27809051569493887,0.2719548504763816,0.26643362296397904,0.2589931548588706,0.27550799113208246,0.29822179920245817,0.30262677417650874,0.2955669187694328,0.2881234988332343,0.2818165452119449,0.27613900625175103,0.26930898354541866,0.26402383274170294,0.25613796352992974,0.27421041762693715,0.29713903176955986,0.3011643860602405,0.29383369672615156,0.2862874045020839,0.2800456824765084,0.2741432669871393,0.2674286245099408,0.2615363815670974,0.25365600898417195,0.27295326016648025,0.29608479025985507,0.2997071968356643,0.292090856349159,0.28443874123565693,0.278261459782271,0.27211073892649523,0.2655524289451141,0.2589454908241966,0.25101049672884745,0.27173372423089664,0.2950537140919557,0.2982639889456567,0.2903442511293763,0.28258033527108195,0.27644425316799925,0.2700390652402738,0.26362721812746226,0.25627971518945136,0.24823745101915573,0.27054922249969227,0.29404062064659886,0.29680698963765045,0.28859442910781885,0.28071224734955846,0.27459032217118173,0.26792937568372693,0.2616533292839143,0.25370343054082534,0.24531998780354722,0.2693973588318117,0.2930513558020491,0.2953551353794907,0.28684608777580467,0.27896663510737857,0.2727107649722281,0.26578156134874376,0.2596305565523015,0.25168804875295103,0.2427871433038309,0.2682759134132334,0.2920782763819981,0.2939054786508548,0.2850920696388013,0.27720499911509955,0.27091717885949973,0.26360770894098795,0.25755778379845484,0.2495675984974049,0.2406210007082448,0.26718282902559004,0.2911252292518705,0.29248958141376474,0.28333831799730913,0.2756384409839392,0.2692429065070928,0.26198422736678467,0.25544177337955654,0.24737007376804085,0.23925549192702236,0.26611619837784617,0.29018735957456615,0.2910797313994391,0.2816642593727401,0.27411869192319327,0.2675783470050572,0.2604063498990626,0.2532871269652666,0.24509536007107116,0.23954144376607617,0.26507425243689997,0.289264494457515,0.289674314029917,0.2801523675655529,0.2726360561663813,0.2659012607246961,0.25881225899350446,0.25107289506648334,0.24273921062988343,0.23978804410789062,0.2640553496905188,0.2883514849128836,0.2882786967735239,0.27876736496334653,0.27114285914129455,0.26420841482934354,0.2571806565740306,0.24922536599170944,0.2407373784154055,0.23997727214413025,0.2630579662759889,0.28745317922477615,0.2868894170997762,0.27738863276582315,0.26963498613235976,0.2624951462805673,0.2555268345865507,0.2475348979603506,0.23900248041376973,0.24009271789065886,0.2620806869093794,0.28656713819760127,0.28550756501174057,0.2760092775669127,0.2681180161695912,0.2607755512167264,0.2538479335086233,0.24579639263086783,0.2372233260413836,0.24014660268438587,0.26112219655310814,0.28571712929585963,0.28413013008649923,0.2746413890990974,0.2665922846727291,0.2590439465038126,0.2521487442610707,0.24401567378143157,0.2374150442585942,0.24012756769320137,0.26018127276278913,0.2848901576429072,0.2827732689631147,0.2732623128091912,0.26505478070600963,0.2573005894830439,0.25042840412965367,0.2421944706335359,0.23754203333345023,0.24021376384437995,0.25925677865784813,0.284073244003456,0.28146204754174686,0.27188096806543843,0.26353604515511536,0.2557495932484397,0.24868777535853623,0.24033658954967085,0.23765491872872155,0.24024619073178938,0.2583476564643672,0.2832669286487876,0.2801533821002904,0.2705045166654655,0.2621732988389821,0.2544402521360274,0.24692651649542763,0.23852302159968222,0.2377000111921171,0.24021215380562996,0.25745292158228555,0.28246981156766604,0.2788528172416958,0.2691341863224083,0.2608047599724897,0.2531177204238531,0.24522072966186015,0.23714772748746007,0.23769760524252156,0.24013146943999863,0.2565716571327042,0.28167778484601086,0.2775583677854948,0.26776340018714184,0.2595108806732881,0.2517857226396959,0.243851974956409,0.23573175704015634,0.23764403194033482,0.24007626519161868,0.25570300894480436,0.280897115160905,0.27626940891764706,0.2663816853537976,0.2581520922068315,0.2504519636807333,0.2424566482706013,0.23439691927858314,0.2375392614922677,0.24034874879873427,0.2548461809449697,0.2801238039832656,0.27498316595970207,0.26500334034335515,0.25678921373704733,0.2490982019599679,0.24103767716664806,0.23443111551213983,0.2375182826754282,0.24057081862118906,0.2540004309140314,0.27935652380193227,0.27370464312659204,0.26362610558020905,0.2554176533225424,0.24773317033000852,0.23959672904620014,0.2344172100967371,0.23748695145332757,0.24031963521280403,0.25316506658128285,0.2785962305380959,0.2724287720095464,0.26224986075888035,0.25404721864535684,0.24636033418249095,0.23813607235973674,0.234442919992138,0.23741190053917946,0.2397258835018143,0.25233944202679026,0.27783898647152383,0.27115159416136647,0.2608772674188802,0.2526732190309514,0.24497843573229777,0.23665164852051349,0.23438956161655358,0.2372889439701884,0.23910429059780186,0.25152295436590855,0.27709092249139816,0.2698820879479411,0.2595815185380185,0.2512962051922632,0.2435860801578002,0.23514900273074985,0.23428063769303617,0.23711121812642286,0.23845515006983115,0.2507150406922104,0.27634672446857383,0.26862841212868704,0.2583597358863471,0.24991601547620923,0.2421873467697457,0.2338517067754975,0.23413627559464664,0.23697174644452706,0.23777831307779268,0.24991517525711587,0.2756070652027483,0.2673656156297818,0.25713625320557365,0.2485318869429736,0.24078141651416238,0.23271344774626324,0.23395892833253928,0.23708370848480406,0.2370739291669965,0.24912286686641444,0.2748707930508215,0.2661108854144937,0.2559111441251971,0.24714639249152603,0.23935847405934316,0.23155910366542934,0.23375430105194453,0.2371656168067039,0.23634212484897463,0.24833765647569145,0.274136534389931,0.2648581980615375,0.2546812346412056,0.24598867756724968,0.23811541479146509,0.23037663621856674,0.23360957502179067,0.23707367260240722,0.23557742116899708,0.24755911496810568,0.27340868096172144,0.263765624257447,0.25345362950939615,0.24489408444983984,0.2369708370658392,0.22995898200782106,0.233467030645677,0.23640634005833672,0.23479109699054027,0.2467868410995977,0.27268407189855143,0.2626843754716899,0.25222502319696427,0.24379465366496045,0.23582334631462698,0.2298155756042545,0.23329638764984462,0.23571731801599272,0.2339774713908084,0.24602045959775948,0.2719615765722503,0.26160206075243364,0.25099566779454946,0.24268959253663502,0.2346517826119582,0.22964655651202825,0.23311191154508384,0.23500493144996085,0.23313654105039297,0.24525961940188296,0.27124273320486547,0.260524133124968,0.24983310315956164,0.24158979480656884,0.2334735112236942,0.2295022834057782,0.2328801611770176,0.2342635069310654,0.2322684519321252,0.24450399203279044,0.27052372154537263,0.2594452872824339,0.2487237403967847,0.24047681886714065,0.23228416466421625,0.22932455395311588,0.2326210779219924,0.2335047211313725,0.23137325396598896,0.24375327008201397,0.2698090031082441,0.25837027162816595,0.2476119533282478,0.23935996423233058,0.23108207548165147,0.2291199428213735,0.2323376780692718,0.2327228951847132,0.23045099076106373,0.24300716581078485,0.26909735646043786,0.2572971474673519,0.2465015773646173,0.23823894686311284,0.22987160208435875,0.22887643339380115,0.2322824216396421,0.23191808610751194,0.22950169662197115,0.24226540985013945,0.2682501402506884,0.2562233117683984,0.24539278002657716,0.2371127701986306,0.22864890081938877,0.22858454112149207,0.23220626138189232,0.2310903413443238,0.22852543339870365,0.24152774999418075,0.267246133306323,0.2551530696143166,0.24434457153489453,0.23598406267615266,0.22753238303250387,0.228270546874152,0.23210789829518097,0.23023963617701365,0.22752224299891383,0.24079395007921517,0.26623990242925466,0.25408250687003137,0.24329025267035967,0.2348519748540457,0.2265622104079917,0.22793301394476811,0.23163841637970273,0.22936614867179597,0.22649217409778039,0.24006378894210278,0.2652356065125817,0.2530159861206287,0.24223804802690435,0.23371660695827925,0.22558239110516204,0.2276732309496187,0.23088021257125335,0.22846990094716593,0.2254352721784397,0.239337059451652,0.2642037833702381,0.2519489550180636,0.24118370252785937,0.23257676962810658,0.2245892514159109,0.22740106894890205,0.2301029489460705,0.22755105112543508,0.2243515824130055,0.23861356760755392,0.26316306924945343,0.2508835179203307,0.24010861245352375,0.2314344599563052,0.22358533943163375,0.2270997309759111,0.2293016767493223,0.22660968394507183,0.2232412758494557,0.2378931317016632,0.2621252555121326,0.24981909867067378,0.23900541428921301,0.23028911192756402,0.2228773869426554,0.22679860711657998,0.22848681508973126,0.2256458736334698,0.22210460783799885,0.23717558153692925,0.26109027013943187,0.2487562993278893,0.23790172932417794,0.22914033901619185,0.22257762691762725,0.22646110334487077,0.22765311985879724,0.2246596937614626,0.22094130978795776,0.23646075769961977,0.26005705525168143,0.24769964572767877,0.23679746184077052,0.2280916796541693,0.22225271751634873,0.2261049374851403,0.22680076818939693,0.2236512124038704,0.21975150639340632,0.23574851088096233,0.25902750542308617,0.2466442735057487,0.23569196444452797,0.22711240310195954,0.2219388456978817,0.22573015562037127,0.2259299183042539,0.22262062952356243,0.21853411214980112,0.235038701244422,0.25800065332310973,0.24558997600016674,0.23458669655244632,0.226127307255798,0.22162845833861097,0.22534037062166862,0.22503982910027803,0.22156791351012595,0.21729001616704186,0.23433119783538114,0.2569736235384691,0.24446402343426496,0.2334810909123537,0.22513403718174232,0.22129446581559942,0.22506036728725845,0.22413214892891878,0.22049113076924795,0.2160204978340471,0.2336258780300164,0.25595214743461236,0.24332937506479055,0.23237493532668074,0.22414459957064967,0.2209408795592535,0.2248309453246207,0.22320620252851492,0.21939418742212796,0.21472454988674547,0.2329226270206584,0.2549332936107202,0.24219333328678286,0.231342204731542,0.2231404126431985,0.22057279539323218,0.2245892906931705,0.22226104443294364,0.21827532565213514,0.21339313769837523,0.232221337334869,0.2539160383440263,0.24106515981607246,0.23033912117236188,0.2221321590353157,0.22018776179498478,0.22431713382368776,0.22129867719877364,0.2171199303367233,0.21192715071741222,0.23152190838595738,0.2529064168026858,0.23992859105601588,0.22934898298031517,0.22111811944306645,0.21978932510285773,0.2237742468970932,0.22028275356139324,0.21584702011721185,0.21043394599615753,0.23082424605260343,0.2518947963916527,0.23879593867457896,0.22834204276675832,0.22009753750461505,0.21935140996902658,0.22286221660913658,0.2191791150691505,0.21455182358551173,0.20891435027773755,0.23012826228562128,0.2508827175197498,0.23766114005309044,0.22733339637893143,0.21899511280954106,0.21882020448477552,0.22190227693827758,0.21805766412062652,0.2132350004079584,0.20736840822955138,0.22943387473985805,0.24987599951978456,0.23653042937013585,0.22632297257329334,0.2178737779264929,0.21830154546557456,0.22093254120824202,0.21691862316376623,0.21189662352251423,0.2057979229766531,0.2287410064296117,0.24887161425853907,0.23540099704561876,0.2253104977487856,0.2167449370228377,0.2177906680291173,0.21994851252579195,0.21576207565606403,0.21053676912461286,0.2041995116868092,0.22804958540580572,0.24786952504155635,0.23427276178586726,0.2242962629572279,0.21578118632547125,0.21726872259939423,0.21895029192307988,0.2145881182590051,0.20915550998172072,0.2027192108967354,0.22735954445354228,0.2468689053763061,0.2331456136407709,0.22327906997786198,0.21481340741796928,0.2167422431854911,0.21793807753440325,0.21339684338009346,0.20775291855845243,0.20124192050716297,0.2266708208085602,0.24587135895379375,0.23201612575266622,0.22226106170288418,0.21383720217140603,0.21619270824302872,0.2169119752343499,0.2121883397956713,0.20632906701799575,0.19974004088946104,0.22598335589136465,0.2448760189844276,0.2308912022478183,0.2212413348619404,0.21285751429820582,0.21563205005654776,0.21587208168035166,0.21096269574051632,0.20488402587766957,0.19821347117884255,0.22529709505783901,0.24388017554539956,0.22977346119142103,0.2202119145747786,0.211870816831303,0.2150591755034237,0.2148184572193179,0.20972001867158085,0.2034178677373325,0.1966627374322525,0.22461198736518823,0.24288934174711063,0.2286658870648056,0.21918890797736376,0.21087969588050598,0.21447473408937226,0.2137511909979565,0.20846049961855795,0.20193066412438448,0.19508775961610525,0.22392798535225233,0.24190061435141635,0.22755940129194138,0.2181643015348554,0.20988913783917595,0.21387817186483543,0.2126704076696847,0.2071842707844332,0.20042248601100351,0.19348826582179426,0.22324504483320684,0.2409139668387773,0.2264635300264244,0.21713703804608406,0.20933644091660625,0.21327391486092595,0.2115761475401686,0.205891249612478,0.19892742129551913,0.1918644505168786,0.2225631247037847,0.23992863088170935,0.2253977052488984,0.21610883960294638,0.20875942141000545,0.2126535200454133,0.21046856387726767,0.20458152165909263,0.19752969838662368,0.19021634465177006,0.22188218675919438,0.23894609332211078,0.22437583793955537,0.21507932023812473,0.2081956113111417,0.21214720535766393,0.20934775369324557,0.20325516693955126,0.19611228188415636,0.18854401302375726]}],                        {\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"STD\"}},\"colorscale\":[[1,\"red\"],[0,\"blue\"]]},\"legend\":{\"tracegroupgap\":0},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"Alpha\"}},\"yaxis\":{\"title\":{\"text\":\"L1 Ratio\"}},\"zaxis\":{\"title\":{\"text\":\"Score\"}}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Gr\\u00e1fica 3D: Alpha vs L1_Ratio vs Score (Color por STD)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('5b7c946c-1c9c-44f0-83df-80d34922de0e');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gráfica 3D: alpha vs l1_ratio vs score\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_3d(df_res, x='alpha', y='l1_ratio', z='score', color='std',\n",
    "                    title='Gráfica 3D: Alpha vs L1_Ratio vs Score (Color por STD)',\n",
    "                    labels={'alpha': 'Alpha', 'l1_ratio': 'L1 Ratio', 'score': 'Score', 'std': 'STD'},\n",
    "                    color_continuous_scale=[[1, 'red'], [0, 'blue']])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:45.961158Z",
     "start_time": "2024-10-05T13:47:45.955145Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:53:54.484946Z",
     "iopub.status.busy": "2024-02-23T01:53:54.484613Z",
     "iopub.status.idle": "2024-02-23T01:53:54.491021Z",
     "shell.execute_reply": "2024-02-23T01:53:54.490124Z",
     "shell.execute_reply.started": "2024-02-23T01:53:54.484918Z"
    },
    "id": "92A8lqv7SSdv",
    "outputId": "fc45a567-083e-455f-cfcd-180d2a315ccd",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alpha      9.90000\n",
       "l1_ratio   0.90000\n",
       "score      0.34672\n",
       "std        0.59378\n",
       "dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:45.991438Z",
     "start_time": "2024-10-05T13:47:45.982460Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:54:01.488494Z",
     "iopub.status.busy": "2024-02-23T01:54:01.488250Z",
     "iopub.status.idle": "2024-02-23T01:54:01.496763Z",
     "shell.execute_reply": "2024-02-23T01:54:01.496160Z",
     "shell.execute_reply.started": "2024-02-23T01:54:01.488476Z"
    },
    "id": "PZlOyZLiSSdw",
    "outputId": "51aaf7f4-d2a8-4e8c-af9e-34475c916e69",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>score</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>9.90000</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>0.18854</td>\n",
       "      <td>0.07227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>9.80000</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>0.19022</td>\n",
       "      <td>0.07201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>9.70000</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>0.19186</td>\n",
       "      <td>0.07176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>9.60000</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>0.19349</td>\n",
       "      <td>0.07153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>9.50000</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>0.19509</td>\n",
       "      <td>0.07130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.70000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.34176</td>\n",
       "      <td>0.34149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.30000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.34234</td>\n",
       "      <td>0.37591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.60000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.34475</td>\n",
       "      <td>0.34471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.34662</td>\n",
       "      <td>0.35932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.34672</td>\n",
       "      <td>0.35007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alpha l1_ratio   score     std\n",
       "989 9.90000  0.90000 0.18854 0.07227\n",
       "979 9.80000  0.90000 0.19022 0.07201\n",
       "969 9.70000  0.90000 0.19186 0.07176\n",
       "959 9.60000  0.90000 0.19349 0.07153\n",
       "949 9.50000  0.90000 0.19509 0.07130\n",
       "..      ...      ...     ...     ...\n",
       "60  0.70000  0.00000 0.34176 0.34149\n",
       "20  0.30000  0.00000 0.34234 0.37591\n",
       "50  0.60000  0.00000 0.34475 0.34471\n",
       "30  0.40000  0.00000 0.34662 0.35932\n",
       "40  0.50000  0.00000 0.34672 0.35007\n",
       "\n",
       "[990 rows x 4 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res.sort_values(by = \"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.015016Z",
     "start_time": "2024-10-05T13:47:46.012109Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:54:37.858483Z",
     "iopub.status.busy": "2024-02-23T01:54:37.856606Z",
     "iopub.status.idle": "2024-02-23T01:54:37.872783Z",
     "shell.execute_reply": "2024-02-23T01:54:37.869816Z",
     "shell.execute_reply.started": "2024-02-23T01:54:37.858401Z"
    },
    "id": "wf6_MXobSSdw",
    "outputId": "2e010952-2652-4dc8-e029-0e498f38a1c8",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.50027647959311"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasnet.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.045635Z",
     "start_time": "2024-10-05T13:47:46.038191Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:54:41.898215Z",
     "iopub.status.busy": "2024-02-23T01:54:41.896328Z",
     "iopub.status.idle": "2024-02-23T01:54:41.923967Z",
     "shell.execute_reply": "2024-02-23T01:54:41.921520Z",
     "shell.execute_reply.started": "2024-02-23T01:54:41.898107Z"
    },
    "id": "1lHJpGj7SSdw",
    "outputId": "e49eeb4f-6533-4ac5-b745-3db9e175bb30",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-0.57781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.00902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.00083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.00745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.02756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1\n",
       "12    LSTAT -0.57781\n",
       "9       TAX -0.00902\n",
       "0      CRIM -0.00000\n",
       "2     INDUS -0.00000\n",
       "3      CHAS  0.00000\n",
       "4       NOX  0.00000\n",
       "5        RM  0.00000\n",
       "7       DIS -0.00000\n",
       "8       RAD  0.00000\n",
       "10  PTRATIO -0.00000\n",
       "6       AGE  0.00083\n",
       "11        B  0.00745\n",
       "1        ZN  0.02756"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip(X.columns, elasnet.coef_)).sort_values(by=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.068786Z",
     "start_time": "2024-10-05T13:47:46.066604Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:54:57.360764Z",
     "iopub.status.busy": "2024-02-23T01:54:57.359571Z",
     "iopub.status.idle": "2024-02-23T01:54:57.374392Z",
     "shell.execute_reply": "2024-02-23T01:54:57.370769Z",
     "shell.execute_reply.started": "2024-02-23T01:54:57.360644Z"
    },
    "id": "h2VcWckcSSdw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "elasnet = ElasticNet(alpha=0.5, l1_ratio=0, max_iter=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.110485Z",
     "start_time": "2024-10-05T13:47:46.090050Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:54:58.725861Z",
     "iopub.status.busy": "2024-02-23T01:54:58.724441Z",
     "iopub.status.idle": "2024-02-23T01:54:58.772429Z",
     "shell.execute_reply": "2024-02-23T01:54:58.771695Z",
     "shell.execute_reply.started": "2024-02-23T01:54:58.725780Z"
    },
    "id": "YRmssNujSSdw",
    "outputId": "cd875755-7550-4c45-8ecb-2fadb8850da8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.916e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.5, l1_ratio=0, max_iter=2500)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasnet.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.162215Z",
     "start_time": "2024-10-05T13:47:46.129256Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:54:59.089464Z",
     "iopub.status.busy": "2024-02-23T01:54:59.087486Z",
     "iopub.status.idle": "2024-02-23T01:54:59.221773Z",
     "shell.execute_reply": "2024-02-23T01:54:59.218920Z",
     "shell.execute_reply.started": "2024-02-23T01:54:59.089355Z"
    },
    "id": "-mfLpDq-SSdw",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.160e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.377e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.030e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dbh/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.462e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "ls_res = cross_val_score(estimator = elasnet, X=X, y=y, cv=4, n_jobs=-1, scoring=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.188596Z",
     "start_time": "2024-10-05T13:47:46.185078Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:55:03.246729Z",
     "iopub.status.busy": "2024-02-23T01:55:03.245824Z",
     "iopub.status.idle": "2024-02-23T01:55:03.257842Z",
     "shell.execute_reply": "2024-02-23T01:55:03.255501Z",
     "shell.execute_reply.started": "2024-02-23T01:55:03.246663Z"
    },
    "id": "oecqGfL2SSdw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dc_scores.update({str(elasnet).split(\"(\")[0]: np.mean(ls_res)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35007221054600424"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ls_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.211498Z",
     "start_time": "2024-10-05T13:47:46.207883Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:55:04.495708Z",
     "iopub.status.busy": "2024-02-23T01:55:04.494349Z",
     "iopub.status.idle": "2024-02-23T01:55:04.514005Z",
     "shell.execute_reply": "2024-02-23T01:55:04.511616Z",
     "shell.execute_reply.started": "2024-02-23T01:55:04.495572Z"
    },
    "id": "0K8kv8v0SSdw",
    "outputId": "c046b7e7-da02-473c-8ab7-3869fc02de5e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression': 0.11405301290101522,\n",
       " 'Lars': 0.11388643958845451,\n",
       " 'Ridge': 0.2873317855328939,\n",
       " 'Lasso': 0.3060600729140215,\n",
       " 'ElasticNet': 0.346716648734065}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChFYlhhSSSdw"
   },
   "source": [
    "### Regresión Bayesiana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6h4NOF0SSdw"
   },
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mBayesianRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0malpha_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-06\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0malpha_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-06\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlambda_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-06\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlambda_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-06\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0malpha_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlambda_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcompute_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcopy_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Bayesian ridge regression.\n",
      "\n",
      "Fit a Bayesian ridge model. See the Notes section for details on this\n",
      "implementation and the optimization of the regularization parameters\n",
      "lambda (precision of the weights) and alpha (precision of the noise).\n",
      "\n",
      "Read more in the :ref:`User Guide <bayesian_regression>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "n_iter : int, default=300\n",
      "    Maximum number of iterations. Should be greater than or equal to 1.\n",
      "\n",
      "tol : float, default=1e-3\n",
      "    Stop the algorithm if w has converged.\n",
      "\n",
      "alpha_1 : float, default=1e-6\n",
      "    Hyper-parameter : shape parameter for the Gamma distribution prior\n",
      "    over the alpha parameter.\n",
      "\n",
      "alpha_2 : float, default=1e-6\n",
      "    Hyper-parameter : inverse scale parameter (rate parameter) for the\n",
      "    Gamma distribution prior over the alpha parameter.\n",
      "\n",
      "lambda_1 : float, default=1e-6\n",
      "    Hyper-parameter : shape parameter for the Gamma distribution prior\n",
      "    over the lambda parameter.\n",
      "\n",
      "lambda_2 : float, default=1e-6\n",
      "    Hyper-parameter : inverse scale parameter (rate parameter) for the\n",
      "    Gamma distribution prior over the lambda parameter.\n",
      "\n",
      "alpha_init : float, default=None\n",
      "    Initial value for alpha (precision of the noise).\n",
      "    If not set, alpha_init is 1/Var(y).\n",
      "\n",
      "        .. versionadded:: 0.22\n",
      "\n",
      "lambda_init : float, default=None\n",
      "    Initial value for lambda (precision of the weights).\n",
      "    If not set, lambda_init is 1.\n",
      "\n",
      "        .. versionadded:: 0.22\n",
      "\n",
      "compute_score : bool, default=False\n",
      "    If True, compute the log marginal likelihood at each iteration of the\n",
      "    optimization.\n",
      "\n",
      "fit_intercept : bool, default=True\n",
      "    Whether to calculate the intercept for this model.\n",
      "    The intercept is not treated as a probabilistic parameter\n",
      "    and thus has no associated variance. If set\n",
      "    to False, no intercept will be used in calculations\n",
      "    (i.e. data is expected to be centered).\n",
      "\n",
      "normalize : bool, default=False\n",
      "    This parameter is ignored when ``fit_intercept`` is set to False.\n",
      "    If True, the regressors X will be normalized before regression by\n",
      "    subtracting the mean and dividing by the l2-norm.\n",
      "    If you wish to standardize, please use\n",
      "    :class:`~sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
      "    on an estimator with ``normalize=False``.\n",
      "\n",
      "    .. deprecated:: 1.0\n",
      "        ``normalize`` was deprecated in version 1.0 and will be removed in\n",
      "        1.2.\n",
      "\n",
      "copy_X : bool, default=True\n",
      "    If True, X will be copied; else, it may be overwritten.\n",
      "\n",
      "verbose : bool, default=False\n",
      "    Verbose mode when fitting the model.\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "coef_ : array-like of shape (n_features,)\n",
      "    Coefficients of the regression model (mean of distribution)\n",
      "\n",
      "intercept_ : float\n",
      "    Independent term in decision function. Set to 0.0 if\n",
      "    ``fit_intercept = False``.\n",
      "\n",
      "alpha_ : float\n",
      "   Estimated precision of the noise.\n",
      "\n",
      "lambda_ : float\n",
      "   Estimated precision of the weights.\n",
      "\n",
      "sigma_ : array-like of shape (n_features, n_features)\n",
      "    Estimated variance-covariance matrix of the weights\n",
      "\n",
      "scores_ : array-like of shape (n_iter_+1,)\n",
      "    If computed_score is True, value of the log marginal likelihood (to be\n",
      "    maximized) at each iteration of the optimization. The array starts\n",
      "    with the value of the log marginal likelihood obtained for the initial\n",
      "    values of alpha and lambda and ends with the value obtained for the\n",
      "    estimated alpha and lambda.\n",
      "\n",
      "n_iter_ : int\n",
      "    The actual number of iterations to reach the stopping criterion.\n",
      "\n",
      "X_offset_ : float\n",
      "    If `normalize=True`, offset subtracted for centering data to a\n",
      "    zero mean.\n",
      "\n",
      "X_scale_ : float\n",
      "    If `normalize=True`, parameter used to scale data to a unit\n",
      "    standard deviation.\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Defined only when `X`\n",
      "    has feature names that are all strings.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "See Also\n",
      "--------\n",
      "ARDRegression : Bayesian ARD regression.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "There exist several strategies to perform Bayesian ridge regression. This\n",
      "implementation is based on the algorithm described in Appendix A of\n",
      "(Tipping, 2001) where updates of the regularization parameters are done as\n",
      "suggested in (MacKay, 1992). Note that according to A New\n",
      "View of Automatic Relevance Determination (Wipf and Nagarajan, 2008) these\n",
      "update rules do not guarantee that the marginal likelihood is increasing\n",
      "between two consecutive iterations of the optimization.\n",
      "\n",
      "References\n",
      "----------\n",
      "D. J. C. MacKay, Bayesian Interpolation, Computation and Neural Systems,\n",
      "Vol. 4, No. 3, 1992.\n",
      "\n",
      "M. E. Tipping, Sparse Bayesian Learning and the Relevance Vector Machine,\n",
      "Journal of Machine Learning Research, Vol. 1, 2001.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn import linear_model\n",
      ">>> clf = linear_model.BayesianRidge()\n",
      ">>> clf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])\n",
      "BayesianRidge()\n",
      ">>> clf.predict([[1, 1]])\n",
      "array([1.])\n",
      "\u001b[0;31mFile:\u001b[0m           ~/envs/diplo_cdd/lib/python3.8/site-packages/sklearn/linear_model/_bayes.py\n",
      "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "BayesianRidge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.236242Z",
     "start_time": "2024-10-05T13:47:46.234067Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:55:12.554107Z",
     "iopub.status.busy": "2024-02-23T01:55:12.552376Z",
     "iopub.status.idle": "2024-02-23T01:55:12.563944Z",
     "shell.execute_reply": "2024-02-23T01:55:12.560782Z",
     "shell.execute_reply.started": "2024-02-23T01:55:12.554034Z"
    },
    "id": "_8tFuv7tSSdw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "bayreg = BayesianRidge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.272044Z",
     "start_time": "2024-10-05T13:47:46.262738Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:55:13.276277Z",
     "iopub.status.busy": "2024-02-23T01:55:13.274438Z",
     "iopub.status.idle": "2024-02-23T01:55:13.306227Z",
     "shell.execute_reply": "2024-02-23T01:55:13.304048Z",
     "shell.execute_reply.started": "2024-02-23T01:55:13.276150Z"
    },
    "id": "bpHXZKkuSSdw",
    "outputId": "94ae37ad-09cf-40f0-f390-8fa36056c728",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesianRidge()"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rQDHSz6SSdw"
   },
   "source": [
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.310970Z",
     "start_time": "2024-10-05T13:47:46.296630Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:55:16.074982Z",
     "iopub.status.busy": "2024-02-23T01:55:16.074110Z",
     "iopub.status.idle": "2024-02-23T01:55:16.139408Z",
     "shell.execute_reply": "2024-02-23T01:55:16.136598Z",
     "shell.execute_reply.started": "2024-02-23T01:55:16.074911Z"
    },
    "id": "RptNY0yYSSdw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls_res = cross_val_score(estimator = bayreg, X=X, y=y, cv=4, n_jobs=-1, scoring=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.338161Z",
     "start_time": "2024-10-05T13:47:46.334958Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:55:16.771279Z",
     "iopub.status.busy": "2024-02-23T01:55:16.770276Z",
     "iopub.status.idle": "2024-02-23T01:55:16.789639Z",
     "shell.execute_reply": "2024-02-23T01:55:16.786540Z",
     "shell.execute_reply.started": "2024-02-23T01:55:16.771015Z"
    },
    "id": "Cc_gxen9SSdw",
    "outputId": "9c96587a-cb6e-467e-c43c-070c8cc13f28",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.64182838,  0.61663703,  0.37058843, -0.77508562])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.363787Z",
     "start_time": "2024-10-05T13:47:46.360368Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:55:30.701073Z",
     "iopub.status.busy": "2024-02-23T01:55:30.700290Z",
     "iopub.status.idle": "2024-02-23T01:55:30.717324Z",
     "shell.execute_reply": "2024-02-23T01:55:30.713732Z",
     "shell.execute_reply.started": "2024-02-23T01:55:30.701007Z"
    },
    "id": "8SlIRZocSSdw",
    "outputId": "1088b2af-73cc-4358-d214-33308bad5005",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.213492055305246, 0.5805090395044222)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ls_res), np.std(ls_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.388118Z",
     "start_time": "2024-10-05T13:47:46.385404Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:55:31.263876Z",
     "iopub.status.busy": "2024-02-23T01:55:31.262240Z",
     "iopub.status.idle": "2024-02-23T01:55:31.279309Z",
     "shell.execute_reply": "2024-02-23T01:55:31.276073Z",
     "shell.execute_reply.started": "2024-02-23T01:55:31.263789Z"
    },
    "id": "sWgpH2AmSSdw",
    "outputId": "df565e2a-55bb-45b6-8908-795b9e387618",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.551854857902597"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.412982Z",
     "start_time": "2024-10-05T13:47:46.407043Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:55:34.131694Z",
     "iopub.status.busy": "2024-02-23T01:55:34.129684Z",
     "iopub.status.idle": "2024-02-23T01:55:34.163810Z",
     "shell.execute_reply": "2024-02-23T01:55:34.161399Z",
     "shell.execute_reply.started": "2024-02-23T01:55:34.131588Z"
    },
    "id": "qTbYoUi7SSdw",
    "outputId": "af01d4fc-350b-43bd-ebd3-eef1718ed6f7",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>-2.14193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-1.24523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-0.79726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-0.56188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.10144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>-0.04384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.01406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>-0.01062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.01004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.04974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.28022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>1.89485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>3.67401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1\n",
       "4       NOX -2.14193\n",
       "7       DIS -1.24523\n",
       "10  PTRATIO -0.79726\n",
       "12    LSTAT -0.56188\n",
       "0      CRIM -0.10144\n",
       "2     INDUS -0.04384\n",
       "9       TAX -0.01406\n",
       "6       AGE -0.01062\n",
       "11        B  0.01004\n",
       "1        ZN  0.04974\n",
       "8       RAD  0.28022\n",
       "3      CHAS  1.89485\n",
       "5        RM  3.67401"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip(X.columns, bayreg.coef_)).sort_values(by=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Predicción con incertidumbre\n",
    "y_pred, y_std = bayreg.predict(X, return_std=True)\n",
    "\n",
    "# Nivel de confianza\n",
    "z = 1.96  # 95%\n",
    "\n",
    "# Intervalos\n",
    "lower_bound = y_pred - z * y_std\n",
    "upper_bound = y_pred + z * y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(range(len(y)), y, alpha=0.5, label=\"Observado\")\n",
    "plt.plot(y_pred, color=\"red\", label=\"Predicción media\")\n",
    "plt.fill_between(\n",
    "    range(len(y)),\n",
    "    lower_bound,\n",
    "    upper_bound,\n",
    "    alpha=0.3,\n",
    "    color=\"gray\",\n",
    "    label=\"IC 95%\"\n",
    ")\n",
    "plt.legend()\n",
    "plt.title(\"Regresión Bayesiana con Intervalo de Confianza\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coef_mean = bayreg.coef_\n",
    "coef_index = np.arange(len(coef_mean))\n",
    "coef_names = X.columns\n",
    "dict_idx_to_names = {i: name for i, name in zip(coef_index, coef_names)}\n",
    "dict_names_to_idx = {name: i for i, name in zip(coef_index, coef_names)}\n",
    "coef_var = np.diag(bayreg.sigma_)\n",
    "coef_std = np.sqrt(coef_var)\n",
    "\n",
    "\n",
    "lower = coef_mean - z * coef_std\n",
    "upper = coef_mean + z * coef_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "var_name='RM'\n",
    "#j=0\n",
    "#var_name=dict_idx_to_names[j]\n",
    "j = dict_names_to_idx[var_name]  # índice del coeficiente\n",
    "\n",
    "x = np.linspace(\n",
    "    coef_mean[j] - 4 * coef_std[j],\n",
    "    coef_mean[j] + 4 * coef_std[j],\n",
    "    500\n",
    ")\n",
    "\n",
    "plt.plot(x, norm.pdf(x, coef_mean[j], coef_std[j]))\n",
    "plt.axvline(0, color=\"red\", linestyle=\"--\", label=\"0\")\n",
    "plt.title(f\"Distribución posterior de β_{var_name}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef_mean</th>\n",
       "      <th>coef_std</th>\n",
       "      <th>lower_95</th>\n",
       "      <th>upper_95</th>\n",
       "      <th>signal_to_noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-0.56188</td>\n",
       "      <td>0.05074</td>\n",
       "      <td>-0.66133</td>\n",
       "      <td>-0.46243</td>\n",
       "      <td>11.07421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>3.67401</td>\n",
       "      <td>0.40547</td>\n",
       "      <td>2.87928</td>\n",
       "      <td>4.46873</td>\n",
       "      <td>9.06105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-1.24523</td>\n",
       "      <td>0.19344</td>\n",
       "      <td>-1.62436</td>\n",
       "      <td>-0.86609</td>\n",
       "      <td>6.43739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-0.79726</td>\n",
       "      <td>0.12554</td>\n",
       "      <td>-1.04333</td>\n",
       "      <td>-0.55119</td>\n",
       "      <td>6.35044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.28022</td>\n",
       "      <td>0.06653</td>\n",
       "      <td>0.14982</td>\n",
       "      <td>0.41061</td>\n",
       "      <td>4.21202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.01406</td>\n",
       "      <td>0.00380</td>\n",
       "      <td>-0.02151</td>\n",
       "      <td>-0.00662</td>\n",
       "      <td>3.70223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.01004</td>\n",
       "      <td>0.00272</td>\n",
       "      <td>0.00471</td>\n",
       "      <td>0.01537</td>\n",
       "      <td>3.69090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.04974</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.02251</td>\n",
       "      <td>0.07697</td>\n",
       "      <td>3.58059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.10144</td>\n",
       "      <td>0.03330</td>\n",
       "      <td>-0.16670</td>\n",
       "      <td>-0.03617</td>\n",
       "      <td>3.04608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>1.89485</td>\n",
       "      <td>0.74720</td>\n",
       "      <td>0.43033</td>\n",
       "      <td>3.35937</td>\n",
       "      <td>2.53592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>-2.14193</td>\n",
       "      <td>1.34794</td>\n",
       "      <td>-4.78389</td>\n",
       "      <td>0.50002</td>\n",
       "      <td>1.58905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>-0.01062</td>\n",
       "      <td>0.01295</td>\n",
       "      <td>-0.03600</td>\n",
       "      <td>0.01477</td>\n",
       "      <td>0.81983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>-0.04384</td>\n",
       "      <td>0.06027</td>\n",
       "      <td>-0.16197</td>\n",
       "      <td>0.07430</td>\n",
       "      <td>0.72731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  coef_mean  coef_std  lower_95  upper_95  signal_to_noise\n",
       "12    LSTAT   -0.56188   0.05074  -0.66133  -0.46243         11.07421\n",
       "5        RM    3.67401   0.40547   2.87928   4.46873          9.06105\n",
       "7       DIS   -1.24523   0.19344  -1.62436  -0.86609          6.43739\n",
       "10  PTRATIO   -0.79726   0.12554  -1.04333  -0.55119          6.35044\n",
       "8       RAD    0.28022   0.06653   0.14982   0.41061          4.21202\n",
       "9       TAX   -0.01406   0.00380  -0.02151  -0.00662          3.70223\n",
       "11        B    0.01004   0.00272   0.00471   0.01537          3.69090\n",
       "1        ZN    0.04974   0.01389   0.02251   0.07697          3.58059\n",
       "0      CRIM   -0.10144   0.03330  -0.16670  -0.03617          3.04608\n",
       "3      CHAS    1.89485   0.74720   0.43033   3.35937          2.53592\n",
       "4       NOX   -2.14193   1.34794  -4.78389   0.50002          1.58905\n",
       "6       AGE   -0.01062   0.01295  -0.03600   0.01477          0.81983\n",
       "2     INDUS   -0.04384   0.06027  -0.16197   0.07430          0.72731"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_params = pd.DataFrame({\n",
    "    \"feature\": X.columns,\n",
    "    \"coef_mean\": coef_mean,\n",
    "    \"coef_std\": coef_std,\n",
    "    \"lower_95\": lower,\n",
    "    \"upper_95\": upper\n",
    "})\n",
    "\n",
    "df_params[\"signal_to_noise\"] = abs(df_params[\"coef_mean\"]) / df_params[\"coef_std\"]\n",
    "df_params.sort_values(\"signal_to_noise\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.445121Z",
     "start_time": "2024-10-05T13:47:46.442594Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:55:34.610982Z",
     "iopub.status.busy": "2024-02-23T01:55:34.608228Z",
     "iopub.status.idle": "2024-02-23T01:55:34.626380Z",
     "shell.execute_reply": "2024-02-23T01:55:34.622621Z",
     "shell.execute_reply.started": "2024-02-23T01:55:34.610836Z"
    },
    "id": "AZAK-4JwSSdw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dc_scores.update({str(bayreg).split(\"(\")[0]: np.mean(ls_res)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.475672Z",
     "start_time": "2024-10-05T13:47:46.471939Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:55:39.230567Z",
     "iopub.status.busy": "2024-02-23T01:55:39.229844Z",
     "iopub.status.idle": "2024-02-23T01:55:39.244695Z",
     "shell.execute_reply": "2024-02-23T01:55:39.242006Z",
     "shell.execute_reply.started": "2024-02-23T01:55:39.230504Z"
    },
    "id": "4CpGzFSgSSdw",
    "outputId": "e92eee23-1d94-4ecb-9518-bc7152123ff6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression': 0.11405301290101522,\n",
       " 'Lars': 0.11388643958845451,\n",
       " 'Ridge': 0.2873317855328939,\n",
       " 'Lasso': 0.3060600729140215,\n",
       " 'ElasticNet': 0.346716648734065,\n",
       " 'BayesianRidge': 0.213492055305246}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0N9gCbOSSdw"
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.514762Z",
     "start_time": "2024-10-05T13:47:46.505401Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:55:44.768537Z",
     "iopub.status.busy": "2024-02-23T01:55:44.766614Z",
     "iopub.status.idle": "2024-02-23T01:55:44.815630Z",
     "shell.execute_reply": "2024-02-23T01:55:44.812771Z",
     "shell.execute_reply.started": "2024-02-23T01:55:44.768461Z"
    },
    "id": "mKI3nM9WSSdw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "resul = pd.DataFrame(columns=[])\n",
    "alfas = pd.DataFrame(columns=[])\n",
    "for model in [linreg, larsreg, ridgereg, lassreg, elasnet, bayreg]:\n",
    "    resul[str(model).split(\"(\")[0]] = model.coef_\n",
    "    alfas[str(model).split(\"(\")[0]] = [model.intercept_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.550576Z",
     "start_time": "2024-10-05T13:47:46.544369Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:55:45.484863Z",
     "iopub.status.busy": "2024-02-23T01:55:45.483183Z",
     "iopub.status.idle": "2024-02-23T01:55:45.515982Z",
     "shell.execute_reply": "2024-02-23T01:55:45.513063Z",
     "shell.execute_reply.started": "2024-02-23T01:55:45.484779Z"
    },
    "id": "nmv8fzHdSSdw",
    "outputId": "1330bb67-d5e5-4a4f-8014-96c6a0a159c5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>Lars</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>ElasticNet</th>\n",
       "      <th>BayesianRidge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.45949</td>\n",
       "      <td>36.95133</td>\n",
       "      <td>39.52662</td>\n",
       "      <td>32.52086</td>\n",
       "      <td>41.42140</td>\n",
       "      <td>27.55185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LinearRegression     Lars    Ridge    Lasso  ElasticNet  BayesianRidge\n",
       "0          36.45949 36.95133 39.52662 32.52086    41.42140       27.55185"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alfas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.580808Z",
     "start_time": "2024-10-05T13:47:46.575141Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:55:48.087163Z",
     "iopub.status.busy": "2024-02-23T01:55:48.085753Z",
     "iopub.status.idle": "2024-02-23T01:55:48.121075Z",
     "shell.execute_reply": "2024-02-23T01:55:48.118994Z",
     "shell.execute_reply.started": "2024-02-23T01:55:48.087060Z"
    },
    "id": "6rpk14t-SSdx",
    "outputId": "44af4aa9-3578-4673-93fc-c2c976355b9e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>Lars</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>ElasticNet</th>\n",
       "      <th>BayesianRidge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.10801</td>\n",
       "      <td>-0.10992</td>\n",
       "      <td>-0.10131</td>\n",
       "      <td>-0.08329</td>\n",
       "      <td>-0.09995</td>\n",
       "      <td>-0.10144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.04642</td>\n",
       "      <td>0.04775</td>\n",
       "      <td>0.05540</td>\n",
       "      <td>0.04954</td>\n",
       "      <td>0.05563</td>\n",
       "      <td>0.04974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02056</td>\n",
       "      <td>0.03427</td>\n",
       "      <td>-0.05245</td>\n",
       "      <td>-0.00525</td>\n",
       "      <td>-0.05039</td>\n",
       "      <td>-0.04384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.68673</td>\n",
       "      <td>2.67396</td>\n",
       "      <td>0.42892</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.31288</td>\n",
       "      <td>1.89485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-17.76661</td>\n",
       "      <td>-18.25012</td>\n",
       "      <td>-0.15001</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.09624</td>\n",
       "      <td>-2.14193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.80987</td>\n",
       "      <td>3.80245</td>\n",
       "      <td>1.82569</td>\n",
       "      <td>2.49821</td>\n",
       "      <td>1.46092</td>\n",
       "      <td>3.67401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00069</td>\n",
       "      <td>0.00098</td>\n",
       "      <td>0.00720</td>\n",
       "      <td>0.00360</td>\n",
       "      <td>0.01231</td>\n",
       "      <td>-0.01062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.47557</td>\n",
       "      <td>-1.48629</td>\n",
       "      <td>-1.08464</td>\n",
       "      <td>-0.93660</td>\n",
       "      <td>-1.00841</td>\n",
       "      <td>-1.24523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.30605</td>\n",
       "      <td>0.32042</td>\n",
       "      <td>0.32549</td>\n",
       "      <td>0.27745</td>\n",
       "      <td>0.33046</td>\n",
       "      <td>0.28022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.01233</td>\n",
       "      <td>-0.01313</td>\n",
       "      <td>-0.01632</td>\n",
       "      <td>-0.01544</td>\n",
       "      <td>-0.01659</td>\n",
       "      <td>-0.01406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.95275</td>\n",
       "      <td>-0.96037</td>\n",
       "      <td>-0.83129</td>\n",
       "      <td>-0.75875</td>\n",
       "      <td>-0.82171</td>\n",
       "      <td>-0.79726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.00931</td>\n",
       "      <td>0.00939</td>\n",
       "      <td>0.00906</td>\n",
       "      <td>0.00947</td>\n",
       "      <td>0.00879</td>\n",
       "      <td>0.01004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.52476</td>\n",
       "      <td>-0.52602</td>\n",
       "      <td>-0.69605</td>\n",
       "      <td>-0.65629</td>\n",
       "      <td>-0.72068</td>\n",
       "      <td>-0.56188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LinearRegression      Lars    Ridge    Lasso  ElasticNet  BayesianRidge\n",
       "0           -0.10801  -0.10992 -0.10131 -0.08329    -0.09995       -0.10144\n",
       "1            0.04642   0.04775  0.05540  0.04954     0.05563        0.04974\n",
       "2            0.02056   0.03427 -0.05245 -0.00525    -0.05039       -0.04384\n",
       "3            2.68673   2.67396  0.42892  0.00000     0.31288        1.89485\n",
       "4          -17.76661 -18.25012 -0.15001 -0.00000    -0.09624       -2.14193\n",
       "5            3.80987   3.80245  1.82569  2.49821     1.46092        3.67401\n",
       "6            0.00069   0.00098  0.00720  0.00360     0.01231       -0.01062\n",
       "7           -1.47557  -1.48629 -1.08464 -0.93660    -1.00841       -1.24523\n",
       "8            0.30605   0.32042  0.32549  0.27745     0.33046        0.28022\n",
       "9           -0.01233  -0.01313 -0.01632 -0.01544    -0.01659       -0.01406\n",
       "10          -0.95275  -0.96037 -0.83129 -0.75875    -0.82171       -0.79726\n",
       "11           0.00931   0.00939  0.00906  0.00947     0.00879        0.01004\n",
       "12          -0.52476  -0.52602 -0.69605 -0.65629    -0.72068       -0.56188"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#resul.index = ['intercepto'] + X.columns.to_list()\n",
    "resul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.605215Z",
     "start_time": "2024-10-05T13:47:46.601413Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:56:22.303344Z",
     "iopub.status.busy": "2024-02-23T01:56:22.302626Z",
     "iopub.status.idle": "2024-02-23T01:56:22.322845Z",
     "shell.execute_reply": "2024-02-23T01:56:22.319957Z",
     "shell.execute_reply.started": "2024-02-23T01:56:22.303281Z"
    },
    "id": "cMR_50ShSSdx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "resul[\"features\"] = ls_pred\n",
    "resul = resul.set_index(\"features\")\n",
    "alfas[\"features\"] = [\"intercepto\"]\n",
    "alfas = alfas.set_index(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.629961Z",
     "start_time": "2024-10-05T13:47:46.627576Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:56:40.236935Z",
     "iopub.status.busy": "2024-02-23T01:56:40.235966Z",
     "iopub.status.idle": "2024-02-23T01:56:40.248578Z",
     "shell.execute_reply": "2024-02-23T01:56:40.245990Z",
     "shell.execute_reply.started": "2024-02-23T01:56:40.236862Z"
    },
    "id": "re3aF3dBSSdx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "resul = pd.concat([alfas, resul])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAmR71pfSSdx"
   },
   "source": [
    "#### Interpretación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.660067Z",
     "start_time": "2024-10-05T13:47:46.653405Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:56:42.075629Z",
     "iopub.status.busy": "2024-02-23T01:56:42.073770Z",
     "iopub.status.idle": "2024-02-23T01:56:42.117538Z",
     "shell.execute_reply": "2024-02-23T01:56:42.114921Z",
     "shell.execute_reply.started": "2024-02-23T01:56:42.075542Z"
    },
    "id": "JtTeKRt3SSdx",
    "outputId": "240a3faa-14eb-4c7c-ef4a-d7d638ddc690",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>Lars</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>ElasticNet</th>\n",
       "      <th>BayesianRidge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-1.47557</td>\n",
       "      <td>-1.48629</td>\n",
       "      <td>-1.08464</td>\n",
       "      <td>-0.93660</td>\n",
       "      <td>-1.00841</td>\n",
       "      <td>-1.24523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>-0.95275</td>\n",
       "      <td>-0.96037</td>\n",
       "      <td>-0.83129</td>\n",
       "      <td>-0.75875</td>\n",
       "      <td>-0.82171</td>\n",
       "      <td>-0.79726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-0.52476</td>\n",
       "      <td>-0.52602</td>\n",
       "      <td>-0.69605</td>\n",
       "      <td>-0.65629</td>\n",
       "      <td>-0.72068</td>\n",
       "      <td>-0.56188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>-0.10801</td>\n",
       "      <td>-0.10992</td>\n",
       "      <td>-0.10131</td>\n",
       "      <td>-0.08329</td>\n",
       "      <td>-0.09995</td>\n",
       "      <td>-0.10144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>-0.01233</td>\n",
       "      <td>-0.01313</td>\n",
       "      <td>-0.01632</td>\n",
       "      <td>-0.01544</td>\n",
       "      <td>-0.01659</td>\n",
       "      <td>-0.01406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.02056</td>\n",
       "      <td>0.03427</td>\n",
       "      <td>-0.05245</td>\n",
       "      <td>-0.00525</td>\n",
       "      <td>-0.05039</td>\n",
       "      <td>-0.04384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>2.68673</td>\n",
       "      <td>2.67396</td>\n",
       "      <td>0.42892</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.31288</td>\n",
       "      <td>1.89485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>-17.76661</td>\n",
       "      <td>-18.25012</td>\n",
       "      <td>-0.15001</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.09624</td>\n",
       "      <td>-2.14193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.00069</td>\n",
       "      <td>0.00098</td>\n",
       "      <td>0.00720</td>\n",
       "      <td>0.00360</td>\n",
       "      <td>0.01231</td>\n",
       "      <td>-0.01062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.00931</td>\n",
       "      <td>0.00939</td>\n",
       "      <td>0.00906</td>\n",
       "      <td>0.00947</td>\n",
       "      <td>0.00879</td>\n",
       "      <td>0.01004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0.04642</td>\n",
       "      <td>0.04775</td>\n",
       "      <td>0.05540</td>\n",
       "      <td>0.04954</td>\n",
       "      <td>0.05563</td>\n",
       "      <td>0.04974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.30605</td>\n",
       "      <td>0.32042</td>\n",
       "      <td>0.32549</td>\n",
       "      <td>0.27745</td>\n",
       "      <td>0.33046</td>\n",
       "      <td>0.28022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>3.80987</td>\n",
       "      <td>3.80245</td>\n",
       "      <td>1.82569</td>\n",
       "      <td>2.49821</td>\n",
       "      <td>1.46092</td>\n",
       "      <td>3.67401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercepto</th>\n",
       "      <td>36.45949</td>\n",
       "      <td>36.95133</td>\n",
       "      <td>39.52662</td>\n",
       "      <td>32.52086</td>\n",
       "      <td>41.42140</td>\n",
       "      <td>27.55185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            LinearRegression      Lars    Ridge    Lasso  ElasticNet  \\\n",
       "features                                                               \n",
       "DIS                 -1.47557  -1.48629 -1.08464 -0.93660    -1.00841   \n",
       "PTRATIO             -0.95275  -0.96037 -0.83129 -0.75875    -0.82171   \n",
       "LSTAT               -0.52476  -0.52602 -0.69605 -0.65629    -0.72068   \n",
       "CRIM                -0.10801  -0.10992 -0.10131 -0.08329    -0.09995   \n",
       "TAX                 -0.01233  -0.01313 -0.01632 -0.01544    -0.01659   \n",
       "INDUS                0.02056   0.03427 -0.05245 -0.00525    -0.05039   \n",
       "CHAS                 2.68673   2.67396  0.42892  0.00000     0.31288   \n",
       "NOX                -17.76661 -18.25012 -0.15001 -0.00000    -0.09624   \n",
       "AGE                  0.00069   0.00098  0.00720  0.00360     0.01231   \n",
       "B                    0.00931   0.00939  0.00906  0.00947     0.00879   \n",
       "ZN                   0.04642   0.04775  0.05540  0.04954     0.05563   \n",
       "RAD                  0.30605   0.32042  0.32549  0.27745     0.33046   \n",
       "RM                   3.80987   3.80245  1.82569  2.49821     1.46092   \n",
       "intercepto          36.45949  36.95133 39.52662 32.52086    41.42140   \n",
       "\n",
       "            BayesianRidge  \n",
       "features                   \n",
       "DIS              -1.24523  \n",
       "PTRATIO          -0.79726  \n",
       "LSTAT            -0.56188  \n",
       "CRIM             -0.10144  \n",
       "TAX              -0.01406  \n",
       "INDUS            -0.04384  \n",
       "CHAS              1.89485  \n",
       "NOX              -2.14193  \n",
       "AGE              -0.01062  \n",
       "B                 0.01004  \n",
       "ZN                0.04974  \n",
       "RAD               0.28022  \n",
       "RM                3.67401  \n",
       "intercepto       27.55185  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resul.sort_values(by=\"Lasso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFrJ4c8LSSdx"
   },
   "source": [
    "* CRIM: per capita crime rate by town\n",
    "* ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "* INDUS    proportion of non-retail business acres per town\n",
    "* CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "* NOX      nitric oxides concentration (parts per 10 million)\n",
    "* RM       average number of rooms per dwelling\n",
    "* AGE      proportion of owner-occupied units built prior to 1940\n",
    "* DIS      weighted distances to five Boston employment centres\n",
    "* RAD      index of accessibility to radial highways\n",
    "* TAX      full-value property-tax rate per \\$10,000\n",
    "* PTRATIO  pupil-teacher ratio by town\n",
    "* B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "* LSTAT    % lower status of the population\n",
    "* MEDV     Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.690934Z",
     "start_time": "2024-10-05T13:47:46.684888Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:57:17.954741Z",
     "iopub.status.busy": "2024-02-23T01:57:17.952406Z",
     "iopub.status.idle": "2024-02-23T01:57:17.982826Z",
     "shell.execute_reply": "2024-02-23T01:57:17.980120Z",
     "shell.execute_reply.started": "2024-02-23T01:57:17.954647Z"
    },
    "id": "1QZUCGPQSSdx",
    "outputId": "bf621856-abfa-467d-e651-a46a7153a54a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   506.00000\n",
       "mean      0.55470\n",
       "std       0.11588\n",
       "min       0.38500\n",
       "25%       0.44900\n",
       "50%       0.53800\n",
       "75%       0.62400\n",
       "max       0.87100\n",
       "Name: NOX, dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"NOX\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.732503Z",
     "start_time": "2024-10-05T13:47:46.725783Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:57:23.014062Z",
     "iopub.status.busy": "2024-02-23T01:57:23.012414Z",
     "iopub.status.idle": "2024-02-23T01:57:23.042058Z",
     "shell.execute_reply": "2024-02-23T01:57:23.038702Z",
     "shell.execute_reply.started": "2024-02-23T01:57:23.013983Z"
    },
    "id": "SdaFsd2bSSdx",
    "outputId": "cac10567-7c5c-4ca6-cd6e-d689fdde4d43",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   506.00000\n",
       "mean      6.28463\n",
       "std       0.70262\n",
       "min       3.56100\n",
       "25%       5.88550\n",
       "50%       6.20850\n",
       "75%       6.62350\n",
       "max       8.78000\n",
       "Name: RM, dtype: float64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"RM\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRBLOcrhSSdx"
   },
   "source": [
    "#### Preservación de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.765526Z",
     "start_time": "2024-10-05T13:47:46.762982Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:57:57.360474Z",
     "iopub.status.busy": "2024-02-23T01:57:57.359738Z",
     "iopub.status.idle": "2024-02-23T01:57:57.373050Z",
     "shell.execute_reply": "2024-02-23T01:57:57.369680Z",
     "shell.execute_reply.started": "2024-02-23T01:57:57.360410Z"
    },
    "id": "G9pOyl09SSdx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.to_pickle(ridgereg, \"modelo.diplo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.803221Z",
     "start_time": "2024-10-05T13:47:46.800654Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:58:10.354556Z",
     "iopub.status.busy": "2024-02-23T01:58:10.353624Z",
     "iopub.status.idle": "2024-02-23T01:58:10.366270Z",
     "shell.execute_reply": "2024-02-23T01:58:10.364089Z",
     "shell.execute_reply.started": "2024-02-23T01:58:10.354456Z"
    },
    "id": "Q_PGuRSGSSdx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "otr_modelo = pd.read_pickle(\"modelo.diplo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.841307Z",
     "start_time": "2024-10-05T13:47:46.837475Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:58:11.474510Z",
     "iopub.status.busy": "2024-02-23T01:58:11.472772Z",
     "iopub.status.idle": "2024-02-23T01:58:11.491117Z",
     "shell.execute_reply": "2024-02-23T01:58:11.487960Z",
     "shell.execute_reply.started": "2024-02-23T01:58:11.474418Z"
    },
    "id": "1TXV3v5-SSdx",
    "outputId": "5f31b5a2-4149-4dd6-a4e3-93f43bacdcb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10130764,  0.05540278, -0.05244785,  0.42892425, -0.15000747,\n",
       "        1.82569   ,  0.00719893, -1.08464089,  0.32549476, -0.01631518,\n",
       "       -0.83129317,  0.00905722, -0.69605352])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgereg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.874653Z",
     "start_time": "2024-10-05T13:47:46.870343Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:58:15.889166Z",
     "iopub.status.busy": "2024-02-23T01:58:15.887966Z",
     "iopub.status.idle": "2024-02-23T01:58:15.907981Z",
     "shell.execute_reply": "2024-02-23T01:58:15.904775Z",
     "shell.execute_reply.started": "2024-02-23T01:58:15.889057Z"
    },
    "id": "B5U_M5-qSSdx",
    "outputId": "47521bfb-41f6-47cc-c65b-09e74b242e5b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10130764,  0.05540278, -0.05244785,  0.42892425, -0.15000747,\n",
       "        1.82569   ,  0.00719893, -1.08464089,  0.32549476, -0.01631518,\n",
       "       -0.83129317,  0.00905722, -0.69605352])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otr_modelo.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.901858Z",
     "start_time": "2024-10-05T13:47:46.900063Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:58:23.033551Z",
     "iopub.status.busy": "2024-02-23T01:58:23.031633Z",
     "iopub.status.idle": "2024-02-23T01:58:23.045068Z",
     "shell.execute_reply": "2024-02-23T01:58:23.041039Z",
     "shell.execute_reply.started": "2024-02-23T01:58:23.033451Z"
    },
    "id": "Bwlyk_h8SSdx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.929162Z",
     "start_time": "2024-10-05T13:47:46.926528Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:58:23.555061Z",
     "iopub.status.busy": "2024-02-23T01:58:23.554174Z",
     "iopub.status.idle": "2024-02-23T01:58:23.570094Z",
     "shell.execute_reply": "2024-02-23T01:58:23.565975Z",
     "shell.execute_reply.started": "2024-02-23T01:58:23.554967Z"
    },
    "id": "NKeL88pPSSdx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"modelo_pickle.diplo\", \"wb\") as f:\n",
    "    pickle.dump(ridgereg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.956529Z",
     "start_time": "2024-10-05T13:47:46.953806Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:58:28.340738Z",
     "iopub.status.busy": "2024-02-23T01:58:28.338397Z",
     "iopub.status.idle": "2024-02-23T01:58:28.355351Z",
     "shell.execute_reply": "2024-02-23T01:58:28.352252Z",
     "shell.execute_reply.started": "2024-02-23T01:58:28.340580Z"
    },
    "id": "GzFhBYe0SSdx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"modelo_pickle.diplo\", \"rb\") as f:\n",
    "    otro_modelo = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:46.996203Z",
     "start_time": "2024-10-05T13:47:46.993024Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:58:29.070790Z",
     "iopub.status.busy": "2024-02-23T01:58:29.069936Z",
     "iopub.status.idle": "2024-02-23T01:58:29.092520Z",
     "shell.execute_reply": "2024-02-23T01:58:29.088494Z",
     "shell.execute_reply.started": "2024-02-23T01:58:29.070718Z"
    },
    "id": "jfUdp_acSSdx",
    "outputId": "4b7fb62a-d124-4c8c-9814-71629161dfa3",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=170)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otro_modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTrOv1XUSSdx"
   },
   "source": [
    "#### Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:47.030643Z",
     "start_time": "2024-10-05T13:47:47.027227Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:58:31.655618Z",
     "iopub.status.busy": "2024-02-23T01:58:31.654524Z",
     "iopub.status.idle": "2024-02-23T01:58:31.676557Z",
     "shell.execute_reply": "2024-02-23T01:58:31.673653Z",
     "shell.execute_reply.started": "2024-02-23T01:58:31.655517Z"
    },
    "id": "Wvx1sAW-SSdx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"y_hat\"] = otro_modelo.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T13:47:47.093708Z",
     "start_time": "2024-10-05T13:47:47.058839Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-23T01:59:05.920884Z",
     "iopub.status.busy": "2024-02-23T01:59:05.919876Z",
     "iopub.status.idle": "2024-02-23T01:59:06.090770Z",
     "shell.execute_reply": "2024-02-23T01:59:06.087905Z",
     "shell.execute_reply.started": "2024-02-23T01:59:05.920813Z"
    },
    "id": "06czdPPrSSdx",
    "outputId": "896bba39-bd5e-4de2-b7bb-a45a0a15e397",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "histfunc": "count",
         "histnorm": "",
         "marker": {
          "color": "rgba(255, 153, 51, 1.0)",
          "line": {
           "color": "#D9D9D9",
           "width": 1.3
          }
         },
         "name": "target",
         "opacity": 0.8,
         "orientation": "v",
         "type": "histogram",
         "x": [
          24,
          21.6,
          34.7,
          33.4,
          36.2,
          28.7,
          22.9,
          27.1,
          16.5,
          18.9,
          15,
          18.9,
          21.7,
          20.4,
          18.2,
          19.9,
          23.1,
          17.5,
          20.2,
          18.2,
          13.6,
          19.6,
          15.2,
          14.5,
          15.6,
          13.9,
          16.6,
          14.8,
          18.4,
          21,
          12.7,
          14.5,
          13.2,
          13.1,
          13.5,
          18.9,
          20,
          21,
          24.7,
          30.8,
          34.9,
          26.6,
          25.3,
          24.7,
          21.2,
          19.3,
          20,
          16.6,
          14.4,
          19.4,
          19.7,
          20.5,
          25,
          23.4,
          18.9,
          35.4,
          24.7,
          31.6,
          23.3,
          19.6,
          18.7,
          16,
          22.2,
          25,
          33,
          23.5,
          19.4,
          22,
          17.4,
          20.9,
          24.2,
          21.7,
          22.8,
          23.4,
          24.1,
          21.4,
          20,
          20.8,
          21.2,
          20.3,
          28,
          23.9,
          24.8,
          22.9,
          23.9,
          26.6,
          22.5,
          22.2,
          23.6,
          28.7,
          22.6,
          22,
          22.9,
          25,
          20.6,
          28.4,
          21.4,
          38.7,
          43.8,
          33.2,
          27.5,
          26.5,
          18.6,
          19.3,
          20.1,
          19.5,
          19.5,
          20.4,
          19.8,
          19.4,
          21.7,
          22.8,
          18.8,
          18.7,
          18.5,
          18.3,
          21.2,
          19.2,
          20.4,
          19.3,
          22,
          20.3,
          20.5,
          17.3,
          18.8,
          21.4,
          15.7,
          16.2,
          18,
          14.3,
          19.2,
          19.6,
          23,
          18.4,
          15.6,
          18.1,
          17.4,
          17.1,
          13.3,
          17.8,
          14,
          14.4,
          13.4,
          15.6,
          11.8,
          13.8,
          15.6,
          14.6,
          17.8,
          15.4,
          21.5,
          19.6,
          15.3,
          19.4,
          17,
          15.6,
          13.1,
          41.3,
          24.3,
          23.3,
          27,
          50,
          50,
          50,
          22.7,
          25,
          50,
          23.8,
          23.8,
          22.3,
          17.4,
          19.1,
          23.1,
          23.6,
          22.6,
          29.4,
          23.2,
          24.6,
          29.9,
          37.2,
          39.8,
          36.2,
          37.9,
          32.5,
          26.4,
          29.6,
          50,
          32,
          29.8,
          34.9,
          37,
          30.5,
          36.4,
          31.1,
          29.1,
          50,
          33.3,
          30.3,
          34.6,
          34.9,
          32.9,
          24.1,
          42.3,
          48.5,
          50,
          22.6,
          24.4,
          22.5,
          24.4,
          20,
          21.7,
          19.3,
          22.4,
          28.1,
          23.7,
          25,
          23.3,
          28.7,
          21.5,
          23,
          26.7,
          21.7,
          27.5,
          30.1,
          44.8,
          50,
          37.6,
          31.6,
          46.7,
          31.5,
          24.3,
          31.7,
          41.7,
          48.3,
          29,
          24,
          25.1,
          31.5,
          23.7,
          23.3,
          22,
          20.1,
          22.2,
          23.7,
          17.6,
          18.5,
          24.3,
          20.5,
          24.5,
          26.2,
          24.4,
          24.8,
          29.6,
          42.8,
          21.9,
          20.9,
          44,
          50,
          36,
          30.1,
          33.8,
          43.1,
          48.8,
          31,
          36.5,
          22.8,
          30.7,
          50,
          43.5,
          20.7,
          21.1,
          25.2,
          24.4,
          35.2,
          32.4,
          32,
          33.2,
          33.1,
          29.1,
          35.1,
          45.4,
          35.4,
          46,
          50,
          32.2,
          22,
          20.1,
          23.2,
          22.3,
          24.8,
          28.5,
          37.3,
          27.9,
          23.9,
          21.7,
          28.6,
          27.1,
          20.3,
          22.5,
          29,
          24.8,
          22,
          26.4,
          33.1,
          36.1,
          28.4,
          33.4,
          28.2,
          22.8,
          20.3,
          16.1,
          22.1,
          19.4,
          21.6,
          23.8,
          16.2,
          17.8,
          19.8,
          23.1,
          21,
          23.8,
          23.1,
          20.4,
          18.5,
          25,
          24.6,
          23,
          22.2,
          19.3,
          22.6,
          19.8,
          17.1,
          19.4,
          22.2,
          20.7,
          21.1,
          19.5,
          18.5,
          20.6,
          19,
          18.7,
          32.7,
          16.5,
          23.9,
          31.2,
          17.5,
          17.2,
          23.1,
          24.5,
          26.6,
          22.9,
          24.1,
          18.6,
          30.1,
          18.2,
          20.6,
          17.8,
          21.7,
          22.7,
          22.6,
          25,
          19.9,
          20.8,
          16.8,
          21.9,
          27.5,
          21.9,
          23.1,
          50,
          50,
          50,
          50,
          50,
          13.8,
          13.8,
          15,
          13.9,
          13.3,
          13.1,
          10.2,
          10.4,
          10.9,
          11.3,
          12.3,
          8.8,
          7.2,
          10.5,
          7.4,
          10.2,
          11.5,
          15.1,
          23.2,
          9.7,
          13.8,
          12.7,
          13.1,
          12.5,
          8.5,
          5,
          6.3,
          5.6,
          7.2,
          12.1,
          8.3,
          8.5,
          5,
          11.9,
          27.9,
          17.2,
          27.5,
          15,
          17.2,
          17.9,
          16.3,
          7,
          7.2,
          7.5,
          10.4,
          8.8,
          8.4,
          16.7,
          14.2,
          20.8,
          13.4,
          11.7,
          8.3,
          10.2,
          10.9,
          11,
          9.5,
          14.5,
          14.1,
          16.1,
          14.3,
          11.7,
          13.4,
          9.6,
          8.7,
          8.4,
          12.8,
          10.5,
          17.1,
          18.4,
          15.4,
          10.8,
          11.8,
          14.9,
          12.6,
          14.1,
          13,
          13.4,
          15.2,
          16.1,
          17.8,
          14.9,
          14.1,
          12.7,
          13.5,
          14.9,
          20,
          16.4,
          17.7,
          19.5,
          20.2,
          21.4,
          19.9,
          19,
          19.1,
          19.1,
          20.1,
          19.9,
          19.6,
          23.2,
          29.8,
          13.8,
          13.3,
          16.7,
          12,
          14.6,
          21.4,
          23,
          23.7,
          25,
          21.8,
          20.6,
          21.2,
          19.1,
          20.6,
          15.2,
          7,
          8.1,
          13.6,
          20.1,
          21.8,
          24.5,
          23.1,
          19.7,
          18.3,
          21.2,
          17.5,
          16.8,
          22.4,
          20.6,
          23.9,
          22,
          11.9
         ]
        },
        {
         "histfunc": "count",
         "histnorm": "",
         "marker": {
          "color": "rgba(55, 128, 191, 1.0)",
          "line": {
           "color": "#D9D9D9",
           "width": 1.3
          }
         },
         "name": "y_hat",
         "opacity": 0.8,
         "orientation": "v",
         "type": "histogram",
         "x": [
          31.26435085283581,
          25.12450265532787,
          29.91116141469107,
          29.208064703804265,
          27.89383957450729,
          26.679533661644488,
          23.992079584312734,
          19.402143771043352,
          10.696551804361306,
          19.658127449896174,
          18.381038171014264,
          22.805490655760828,
          21.35790222775802,
          21.836637176977042,
          20.988993613300757,
          21.657585576347294,
          22.83906683368074,
          17.973124029302873,
          18.36091753339918,
          20.309171978982448,
          13.263818791884571,
          18.878024559208654,
          15.854903183591205,
          14.381615309701168,
          16.725726523336306,
          15.033541948071807,
          17.0764251291594,
          15.354243813007727,
          20.086600451128966,
          21.073930247271583,
          11.788122727612546,
          19.330503712555057,
          7.6589547426891045,
          15.199655405858245,
          13.531880282543984,
          24.782464245130637,
          23.163748631664056,
          24.448035837012874,
          23.68504676882528,
          32.02796278461284,
          34.3960610585938,
          27.6765097833666,
          25.910833124086743,
          24.950860172970547,
          23.421898424922993,
          22.94743033937575,
          20.389535615141114,
          17.29346348155341,
          7.691699596967801,
          17.759260335047045,
          21.73592643314472,
          24.926302364550082,
          28.261763629649536,
          25.135159708553932,
          15.639838346556907,
          31.644600002639645,
          26.820141366129903,
          34.34803440768141,
          23.869371614119757,
          22.977306497457157,
          19.699907318872995,
          19.69341721670032,
          25.505517580438443,
          23.127518991939336,
          23.70268127175012,
          30.923569869165114,
          26.2231701278559,
          21.583372180235326,
          17.700815691460107,
          21.198513314685485,
          24.079974323867045,
          21.057758245006333,
          24.34592279612473,
          23.122043742950964,
          24.111040558488114,
          22.532188027923645,
          21.023929895490816,
          21.827224716849386,
          19.607483652556198,
          21.725507958126805,
          28.089013143280134,
          26.80223978144387,
          26.308839681200464,
          25.56028502481829,
          24.511085689886364,
          27.48846747201272,
          21.925825082231555,
          26.007657527735454,
          30.186634557046315,
          30.01242228601205,
          26.975641230711318,
          27.447864437235417,
          28.051232690792688,
          28.82228987512141,
          26.25031338953582,
          27.814455664157954,
          24.098739303335257,
          32.63277274911398,
          32.3155959722829,
          29.970516891528185,
          23.835318004219296,
          25.016066528485617,
          19.57096480070639,
          20.073454694213147,
          21.22929437411144,
          18.172658272418786,
          16.484213958222224,
          20.176099395492713,
          21.894018674022142,
          18.94944088353362,
          20.181230087247698,
          25.470995146527574,
          20.22047706806052,
          19.74932404256112,
          24.836604404470933,
          19.9501753587639,
          23.031949976831378,
          24.02303996672405,
          19.942324819097998,
          21.02496040060582,
          22.085324269414937,
          22.464394237232987,
          20.02317925501336,
          14.732799233442044,
          20.236516992053524,
          22.365133628092885,
          13.07060639925082,
          15.538860731264279,
          18.16969440153145,
          14.399345328235746,
          19.811468574159868,
          19.563532399537024,
          20.341461141397026,
          16.496104653486277,
          13.740360871581704,
          16.530128434345684,
          15.851633793124726,
          18.696924876362974,
          13.109555248787064,
          15.648913724652658,
          11.699860695827432,
          2.634175288527807,
          15.37124655068613,
          15.162928767941317,
          12.322869519489444,
          13.548390049404684,
          20.276891936041327,
          12.05270717720957,
          12.970655648152448,
          18.427671788493974,
          24.71821203479687,
          23.759854512454712,
          24.226642439261738,
          21.736975417723635,
          23.853670749602195,
          21.54771915535705,
          18.940417469095145,
          32.55494909002925,
          29.72346680462966,
          29.902682644009303,
          30.9092390918278,
          35.468791399579644,
          36.41443384267558,
          36.34493713557959,
          25.212199923814605,
          25.623421899000384,
          34.75653415979675,
          23.338929344926008,
          25.9235560089315,
          26.022550660122935,
          22.498061135931533,
          24.631163999401657,
          23.586117404928338,
          28.965695691164946,
          27.34016529632687,
          30.852539919555,
          26.228424095981342,
          29.895116411862823,
          30.85459457712573,
          32.531159506940305,
          32.47201791907388,
          28.21218061633532,
          33.3578333868318,
          31.56836606238202,
          23.793990058680308,
          24.873400441617164,
          34.02091033763898,
          31.750332784510583,
          31.778347382747626,
          32.55114006214197,
          29.95070930782081,
          30.02713860479692,
          32.06832742370471,
          31.470161681940823,
          31.478605694504594,
          39.025537329078226,
          35.000013910202284,
          31.149854102965524,
          33.19621677664149,
          29.898885644061274,
          30.14475241130306,
          29.798859351936635,
          35.30186057018413,
          39.941204856896604,
          40.89094893604988,
          22.869685677077733,
          23.33966773571736,
          17.507186659595366,
          20.781609005578733,
          14.39957904913085,
          19.509494018597096,
          14.026375935431098,
          20.035801451637383,
          24.76156881268683,
          8.841118709560106,
          24.484277322732055,
          24.562479643608892,
          28.04071884069355,
          22.152220288650618,
          27.534198827025165,
          29.661325128636232,
          19.89100233158161,
          28.815099465030176,
          29.613651602911848,
          35.34585588468403,
          35.82755515074588,
          35.36113509856001,
          31.322600145015194,
          33.41085088359581,
          31.494647458903046,
          24.947348501392383,
          32.06548840755218,
          35.55899683049911,
          34.50759672589757,
          29.096132095238165,
          25.654736676585934,
          27.66797519623043,
          31.894629367162423,
          28.37768500340961,
          28.112055810031876,
          25.846242860017014,
          23.781062582056883,
          24.038382208540007,
          27.99006502412397,
          18.176006691446084,
          14.156289112850324,
          21.179137548302926,
          20.911738766434585,
          21.750173408129086,
          24.27301757155361,
          24.772576232408408,
          26.080020762502635,
          25.51144814059983,
          27.961914877119536,
          25.623636598380436,
          23.263815481785187,
          36.3504910477697,
          41.30966231635287,
          36.87764035098561,
          36.55373672228607,
          35.11910982547427,
          37.30480896055778,
          39.68900857731199,
          34.29431915522119,
          36.38418087217956,
          31.4942827217308,
          31.048222939923267,
          38.10280409173002,
          39.03588366763927,
          23.540981106861242,
          22.707706770181936,
          27.773348545297964,
          28.37117391335847,
          31.120085843617485,
          33.57972370181953,
          33.57039642342143,
          32.027010898862244,
          32.343805805279,
          30.023222482590068,
          34.52896825411864,
          36.64704059638621,
          33.765177746083744,
          36.51565845738485,
          40.24930607690398,
          30.528538871904157,
          27.040028495323373,
          20.90706160928177,
          27.714211585288908,
          27.68976646773033,
          26.425547004146996,
          33.4320342005832,
          33.79003380826849,
          32.024196805684404,
          24.981500425039307,
          23.671372996398198,
          27.185597550949534,
          26.28473951754485,
          18.705580809085582,
          29.81847133887638,
          31.207702596377448,
          30.41660639616132,
          27.886816290491634,
          28.01696505572587,
          31.61402737364503,
          32.41102129989706,
          30.713692366731877,
          34.31691692242058,
          32.437150010026315,
          29.4660047888101,
          24.676013665284746,
          20.69977460384191,
          28.017687275407553,
          23.950310804258145,
          26.50593644129394,
          25.76979397236513,
          22.22832115764639,
          17.7789393124191,
          19.14638206091862,
          24.60364049068595,
          21.895078872284934,
          25.46720150983935,
          25.61859524608589,
          24.184418043054734,
          20.894610803988854,
          25.897459248732787,
          25.700058418170435,
          24.85810620944201,
          19.93109770989515,
          21.285680115991454,
          23.837743797926837,
          21.609868974506174,
          20.729773113050726,
          24.20208351551298,
          24.72916026264848,
          23.97486328082259,
          23.15147356572469,
          22.50234641484212,
          21.681627331668956,
          24.129941310359143,
          23.201669626262092,
          23.57750046943826,
          29.820361177581383,
          22.6537283604356,
          28.271152564385424,
          29.304492341253415,
          17.63249719633773,
          15.76495640091336,
          26.612447433754415,
          29.03687871609189,
          22.905070793989033,
          22.154458698321527,
          22.26594565477291,
          19.466804838816095,
          28.52836526018615,
          18.235343556829122,
          20.375024276057218,
          19.045709830207613,
          22.57553939707587,
          22.94163798291272,
          21.92638365905719,
          25.70866107085528,
          21.1042802369043,
          22.7993670368628,
          20.79341876707041,
          32.789950858634114,
          21.802925289509197,
          19.184789703425373,
          15.31257975235605,
          27.620594161788272,
          30.720589273874978,
          32.10032724006148,
          25.184437108184092,
          25.337951527138102,
          5.301787030143231,
          0.9639608970771931,
          23.512132931549154,
          15.54531633305276,
          18.08798893999542,
          14.17707777467816,
          15.804351926889431,
          13.078856297510864,
          16.95907284938876,
          13.976128254674848,
          13.451025378472416,
          4.929917607598291,
          7.865962316865911,
          7.6869061773396155,
          5.7907847531892145,
          7.1437195713689405,
          15.560486178225545,
          18.62269670892609,
          17.748907451657157,
          11.14603280648987,
          20.81740847262028,
          18.98472259868644,
          20.031468651021243,
          18.710485973821818,
          16.977534697716763,
          6.104102298371821,
          9.44126237965159,
          10.978317892291397,
          17.22887841094802,
          17.558630360257773,
          14.55821709288755,
          7.315249065223476,
          8.786994003665061,
          10.637648275896332,
          21.550627346296736,
          11.747329556905068,
          16.675434656468934,
          16.145394223616258,
          13.982079943852419,
          0.5570636830517159,
          12.079992964217954,
          -3.7761730315662803,
          7.300038530189411,
          10.837845380266167,
          7.149919520473823,
          6.61645659751894,
          13.10071991307926,
          20.340628942653645,
          19.49998093092523,
          19.070525619654312,
          11.298415182722746,
          14.27167532361592,
          9.495160824657383,
          15.624646714473343,
          14.746529495667453,
          13.549292467560818,
          11.673514732880989,
          16.243539827205453,
          15.544344755102397,
          20.386244600876438,
          17.54736510097753,
          17.174455286080423,
          12.766267470022306,
          15.13977101387341,
          8.63169959782828,
          3.67276722813083,
          14.316040568387521,
          13.804798586382727,
          17.69898977909633,
          19.98179731252258,
          18.406191667605874,
          12.269468710426807,
          11.55608812144957,
          18.503915545831774,
          19.414241608127128,
          18.203854954269495,
          17.229427998351714,
          16.275299832030715,
          19.252236986325535,
          19.16411212522732,
          21.092887610482123,
          14.951027086551974,
          15.877858360582579,
          13.758239283634715,
          14.434908243121143,
          18.094915831476175,
          20.060111829319233,
          19.083667322827708,
          21.090746022349705,
          20.971579971816794,
          23.93816905175653,
          20.82399431517444,
          19.040986965156776,
          14.874207640396818,
          15.2408479054067,
          15.962115434563884,
          18.41624930147445,
          19.033274266285055,
          21.528149499406645,
          21.00034990880581,
          23.928536817377505,
          16.353758373021506,
          13.521512599393375,
          18.74299175607746,
          11.049099743143753,
          18.12536681496367,
          21.42286639913167,
          22.328230255130705,
          25.4946450656801,
          26.51778172518684,
          21.0362713066632,
          19.4562206751569,
          21.994918772354872,
          19.08750523260389,
          21.44476019256085,
          10.615292743964641,
          6.074372913206027,
          1.2043268401783749,
          11.526306723370677,
          14.500202686549969,
          21.985864988745725,
          21.193093736269304,
          17.360503363910073,
          14.724244635487828,
          20.245567663523136,
          21.967033310537225,
          19.69306058423215,
          21.008719795992565,
          23.888242314028677,
          23.743578938389646,
          27.932326101909926,
          26.726793627513196,
          24.207920500491007
         ]
        }
       ],
       "layout": {
        "barmode": "overlay",
        "legend": {
         "bgcolor": "#151516",
         "font": {
          "color": "#D9D9D9"
         }
        },
        "paper_bgcolor": "#151516",
        "plot_bgcolor": "#151516",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "#D9D9D9"
         }
        },
        "xaxis": {
         "gridcolor": "#434343",
         "showgrid": true,
         "tickfont": {
          "color": "#C2C2C2"
         },
         "title": {
          "font": {
           "color": "#D9D9D9"
          },
          "text": ""
         },
         "zerolinecolor": "#666570"
        },
        "yaxis": {
         "gridcolor": "#434343",
         "showgrid": true,
         "tickfont": {
          "color": "#C2C2C2"
         },
         "title": {
          "font": {
           "color": "#D9D9D9"
          },
          "text": ""
         },
         "zerolinecolor": "#666570"
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"ddf1a978-81d6-42bc-ad4b-88bb63d67f55\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';                                    if (document.getElementById(\"ddf1a978-81d6-42bc-ad4b-88bb63d67f55\")) {                    Plotly.newPlot(                        \"ddf1a978-81d6-42bc-ad4b-88bb63d67f55\",                        [{\"histfunc\":\"count\",\"histnorm\":\"\",\"marker\":{\"color\":\"rgba(255, 153, 51, 1.0)\",\"line\":{\"color\":\"#D9D9D9\",\"width\":1.3}},\"name\":\"target\",\"opacity\":0.8,\"orientation\":\"v\",\"type\":\"histogram\",\"x\":[24.0,21.6,34.7,33.4,36.2,28.7,22.9,27.1,16.5,18.9,15.0,18.9,21.7,20.4,18.2,19.9,23.1,17.5,20.2,18.2,13.6,19.6,15.2,14.5,15.6,13.9,16.6,14.8,18.4,21.0,12.7,14.5,13.2,13.1,13.5,18.9,20.0,21.0,24.7,30.8,34.9,26.6,25.3,24.7,21.2,19.3,20.0,16.6,14.4,19.4,19.7,20.5,25.0,23.4,18.9,35.4,24.7,31.6,23.3,19.6,18.7,16.0,22.2,25.0,33.0,23.5,19.4,22.0,17.4,20.9,24.2,21.7,22.8,23.4,24.1,21.4,20.0,20.8,21.2,20.3,28.0,23.9,24.8,22.9,23.9,26.6,22.5,22.2,23.6,28.7,22.6,22.0,22.9,25.0,20.6,28.4,21.4,38.7,43.8,33.2,27.5,26.5,18.6,19.3,20.1,19.5,19.5,20.4,19.8,19.4,21.7,22.8,18.8,18.7,18.5,18.3,21.2,19.2,20.4,19.3,22.0,20.3,20.5,17.3,18.8,21.4,15.7,16.2,18.0,14.3,19.2,19.6,23.0,18.4,15.6,18.1,17.4,17.1,13.3,17.8,14.0,14.4,13.4,15.6,11.8,13.8,15.6,14.6,17.8,15.4,21.5,19.6,15.3,19.4,17.0,15.6,13.1,41.3,24.3,23.3,27.0,50.0,50.0,50.0,22.7,25.0,50.0,23.8,23.8,22.3,17.4,19.1,23.1,23.6,22.6,29.4,23.2,24.6,29.9,37.2,39.8,36.2,37.9,32.5,26.4,29.6,50.0,32.0,29.8,34.9,37.0,30.5,36.4,31.1,29.1,50.0,33.3,30.3,34.6,34.9,32.9,24.1,42.3,48.5,50.0,22.6,24.4,22.5,24.4,20.0,21.7,19.3,22.4,28.1,23.7,25.0,23.3,28.7,21.5,23.0,26.7,21.7,27.5,30.1,44.8,50.0,37.6,31.6,46.7,31.5,24.3,31.7,41.7,48.3,29.0,24.0,25.1,31.5,23.7,23.3,22.0,20.1,22.2,23.7,17.6,18.5,24.3,20.5,24.5,26.2,24.4,24.8,29.6,42.8,21.9,20.9,44.0,50.0,36.0,30.1,33.8,43.1,48.8,31.0,36.5,22.8,30.7,50.0,43.5,20.7,21.1,25.2,24.4,35.2,32.4,32.0,33.2,33.1,29.1,35.1,45.4,35.4,46.0,50.0,32.2,22.0,20.1,23.2,22.3,24.8,28.5,37.3,27.9,23.9,21.7,28.6,27.1,20.3,22.5,29.0,24.8,22.0,26.4,33.1,36.1,28.4,33.4,28.2,22.8,20.3,16.1,22.1,19.4,21.6,23.8,16.2,17.8,19.8,23.1,21.0,23.8,23.1,20.4,18.5,25.0,24.6,23.0,22.2,19.3,22.6,19.8,17.1,19.4,22.2,20.7,21.1,19.5,18.5,20.6,19.0,18.7,32.7,16.5,23.9,31.2,17.5,17.2,23.1,24.5,26.6,22.9,24.1,18.6,30.1,18.2,20.6,17.8,21.7,22.7,22.6,25.0,19.9,20.8,16.8,21.9,27.5,21.9,23.1,50.0,50.0,50.0,50.0,50.0,13.8,13.8,15.0,13.9,13.3,13.1,10.2,10.4,10.9,11.3,12.3,8.8,7.2,10.5,7.4,10.2,11.5,15.1,23.2,9.7,13.8,12.7,13.1,12.5,8.5,5.0,6.3,5.6,7.2,12.1,8.3,8.5,5.0,11.9,27.9,17.2,27.5,15.0,17.2,17.9,16.3,7.0,7.2,7.5,10.4,8.8,8.4,16.7,14.2,20.8,13.4,11.7,8.3,10.2,10.9,11.0,9.5,14.5,14.1,16.1,14.3,11.7,13.4,9.6,8.7,8.4,12.8,10.5,17.1,18.4,15.4,10.8,11.8,14.9,12.6,14.1,13.0,13.4,15.2,16.1,17.8,14.9,14.1,12.7,13.5,14.9,20.0,16.4,17.7,19.5,20.2,21.4,19.9,19.0,19.1,19.1,20.1,19.9,19.6,23.2,29.8,13.8,13.3,16.7,12.0,14.6,21.4,23.0,23.7,25.0,21.8,20.6,21.2,19.1,20.6,15.2,7.0,8.1,13.6,20.1,21.8,24.5,23.1,19.7,18.3,21.2,17.5,16.8,22.4,20.6,23.9,22.0,11.9]},{\"histfunc\":\"count\",\"histnorm\":\"\",\"marker\":{\"color\":\"rgba(55, 128, 191, 1.0)\",\"line\":{\"color\":\"#D9D9D9\",\"width\":1.3}},\"name\":\"y_hat\",\"opacity\":0.8,\"orientation\":\"v\",\"type\":\"histogram\",\"x\":[31.26435085283581,25.12450265532787,29.91116141469107,29.208064703804265,27.89383957450729,26.679533661644488,23.992079584312734,19.402143771043352,10.696551804361306,19.658127449896174,18.381038171014264,22.805490655760828,21.35790222775802,21.836637176977042,20.988993613300757,21.657585576347294,22.83906683368074,17.973124029302873,18.36091753339918,20.309171978982448,13.263818791884571,18.878024559208654,15.854903183591205,14.381615309701168,16.725726523336306,15.033541948071807,17.0764251291594,15.354243813007727,20.086600451128966,21.073930247271583,11.788122727612546,19.330503712555057,7.6589547426891045,15.199655405858245,13.531880282543984,24.782464245130637,23.163748631664056,24.448035837012874,23.68504676882528,32.02796278461284,34.3960610585938,27.6765097833666,25.910833124086743,24.950860172970547,23.421898424922993,22.94743033937575,20.389535615141114,17.29346348155341,7.691699596967801,17.759260335047045,21.73592643314472,24.926302364550082,28.261763629649536,25.135159708553932,15.639838346556907,31.644600002639645,26.820141366129903,34.34803440768141,23.869371614119757,22.977306497457157,19.699907318872995,19.69341721670032,25.505517580438443,23.127518991939336,23.70268127175012,30.923569869165114,26.2231701278559,21.583372180235326,17.700815691460107,21.198513314685485,24.079974323867045,21.057758245006333,24.34592279612473,23.122043742950964,24.111040558488114,22.532188027923645,21.023929895490816,21.827224716849386,19.607483652556198,21.725507958126805,28.089013143280134,26.80223978144387,26.308839681200464,25.56028502481829,24.511085689886364,27.48846747201272,21.925825082231555,26.007657527735454,30.186634557046315,30.01242228601205,26.975641230711318,27.447864437235417,28.051232690792688,28.82228987512141,26.25031338953582,27.814455664157954,24.098739303335257,32.63277274911398,32.3155959722829,29.970516891528185,23.835318004219296,25.016066528485617,19.57096480070639,20.073454694213147,21.22929437411144,18.172658272418786,16.484213958222224,20.176099395492713,21.894018674022142,18.94944088353362,20.181230087247698,25.470995146527574,20.22047706806052,19.74932404256112,24.836604404470933,19.9501753587639,23.031949976831378,24.02303996672405,19.942324819097998,21.02496040060582,22.085324269414937,22.464394237232987,20.02317925501336,14.732799233442044,20.236516992053524,22.365133628092885,13.07060639925082,15.538860731264279,18.16969440153145,14.399345328235746,19.811468574159868,19.563532399537024,20.341461141397026,16.496104653486277,13.740360871581704,16.530128434345684,15.851633793124726,18.696924876362974,13.109555248787064,15.648913724652658,11.699860695827432,2.634175288527807,15.37124655068613,15.162928767941317,12.322869519489444,13.548390049404684,20.276891936041327,12.05270717720957,12.970655648152448,18.427671788493974,24.71821203479687,23.759854512454712,24.226642439261738,21.736975417723635,23.853670749602195,21.54771915535705,18.940417469095145,32.55494909002925,29.72346680462966,29.902682644009303,30.9092390918278,35.468791399579644,36.41443384267558,36.34493713557959,25.212199923814605,25.623421899000384,34.75653415979675,23.338929344926008,25.9235560089315,26.022550660122935,22.498061135931533,24.631163999401657,23.586117404928338,28.965695691164946,27.34016529632687,30.852539919555,26.228424095981342,29.895116411862823,30.85459457712573,32.531159506940305,32.47201791907388,28.21218061633532,33.3578333868318,31.56836606238202,23.793990058680308,24.873400441617164,34.02091033763898,31.750332784510583,31.778347382747626,32.55114006214197,29.95070930782081,30.02713860479692,32.06832742370471,31.470161681940823,31.478605694504594,39.025537329078226,35.000013910202284,31.149854102965524,33.19621677664149,29.898885644061274,30.14475241130306,29.798859351936635,35.30186057018413,39.941204856896604,40.89094893604988,22.869685677077733,23.33966773571736,17.507186659595366,20.781609005578733,14.39957904913085,19.509494018597096,14.026375935431098,20.035801451637383,24.76156881268683,8.841118709560106,24.484277322732055,24.562479643608892,28.04071884069355,22.152220288650618,27.534198827025165,29.661325128636232,19.89100233158161,28.815099465030176,29.613651602911848,35.34585588468403,35.82755515074588,35.36113509856001,31.322600145015194,33.41085088359581,31.494647458903046,24.947348501392383,32.06548840755218,35.55899683049911,34.50759672589757,29.096132095238165,25.654736676585934,27.66797519623043,31.894629367162423,28.37768500340961,28.112055810031876,25.846242860017014,23.781062582056883,24.038382208540007,27.99006502412397,18.176006691446084,14.156289112850324,21.179137548302926,20.911738766434585,21.750173408129086,24.27301757155361,24.772576232408408,26.080020762502635,25.51144814059983,27.961914877119536,25.623636598380436,23.263815481785187,36.3504910477697,41.30966231635287,36.87764035098561,36.55373672228607,35.11910982547427,37.30480896055778,39.68900857731199,34.29431915522119,36.38418087217956,31.4942827217308,31.048222939923267,38.10280409173002,39.03588366763927,23.540981106861242,22.707706770181936,27.773348545297964,28.37117391335847,31.120085843617485,33.57972370181953,33.57039642342143,32.027010898862244,32.343805805279,30.023222482590068,34.52896825411864,36.64704059638621,33.765177746083744,36.51565845738485,40.24930607690398,30.528538871904157,27.040028495323373,20.90706160928177,27.714211585288908,27.68976646773033,26.425547004146996,33.4320342005832,33.79003380826849,32.024196805684404,24.981500425039307,23.671372996398198,27.185597550949534,26.28473951754485,18.705580809085582,29.81847133887638,31.207702596377448,30.41660639616132,27.886816290491634,28.01696505572587,31.61402737364503,32.41102129989706,30.713692366731877,34.31691692242058,32.437150010026315,29.4660047888101,24.676013665284746,20.69977460384191,28.017687275407553,23.950310804258145,26.50593644129394,25.76979397236513,22.22832115764639,17.7789393124191,19.14638206091862,24.60364049068595,21.895078872284934,25.46720150983935,25.61859524608589,24.184418043054734,20.894610803988854,25.897459248732787,25.700058418170435,24.85810620944201,19.93109770989515,21.285680115991454,23.837743797926837,21.609868974506174,20.729773113050726,24.20208351551298,24.72916026264848,23.97486328082259,23.15147356572469,22.50234641484212,21.681627331668956,24.129941310359143,23.201669626262092,23.57750046943826,29.820361177581383,22.6537283604356,28.271152564385424,29.304492341253415,17.63249719633773,15.76495640091336,26.612447433754415,29.03687871609189,22.905070793989033,22.154458698321527,22.26594565477291,19.466804838816095,28.52836526018615,18.235343556829122,20.375024276057218,19.045709830207613,22.57553939707587,22.94163798291272,21.92638365905719,25.70866107085528,21.1042802369043,22.7993670368628,20.79341876707041,32.789950858634114,21.802925289509197,19.184789703425373,15.31257975235605,27.620594161788272,30.720589273874978,32.10032724006148,25.184437108184092,25.337951527138102,5.301787030143231,0.9639608970771931,23.512132931549154,15.54531633305276,18.08798893999542,14.17707777467816,15.804351926889431,13.078856297510864,16.95907284938876,13.976128254674848,13.451025378472416,4.929917607598291,7.865962316865911,7.6869061773396155,5.7907847531892145,7.1437195713689405,15.560486178225545,18.62269670892609,17.748907451657157,11.14603280648987,20.81740847262028,18.98472259868644,20.031468651021243,18.710485973821818,16.977534697716763,6.104102298371821,9.44126237965159,10.978317892291397,17.22887841094802,17.558630360257773,14.55821709288755,7.315249065223476,8.786994003665061,10.637648275896332,21.550627346296736,11.747329556905068,16.675434656468934,16.145394223616258,13.982079943852419,0.5570636830517159,12.079992964217954,-3.7761730315662803,7.300038530189411,10.837845380266167,7.149919520473823,6.61645659751894,13.10071991307926,20.340628942653645,19.49998093092523,19.070525619654312,11.298415182722746,14.27167532361592,9.495160824657383,15.624646714473343,14.746529495667453,13.549292467560818,11.673514732880989,16.243539827205453,15.544344755102397,20.386244600876438,17.54736510097753,17.174455286080423,12.766267470022306,15.13977101387341,8.63169959782828,3.67276722813083,14.316040568387521,13.804798586382727,17.69898977909633,19.98179731252258,18.406191667605874,12.269468710426807,11.55608812144957,18.503915545831774,19.414241608127128,18.203854954269495,17.229427998351714,16.275299832030715,19.252236986325535,19.16411212522732,21.092887610482123,14.951027086551974,15.877858360582579,13.758239283634715,14.434908243121143,18.094915831476175,20.060111829319233,19.083667322827708,21.090746022349705,20.971579971816794,23.93816905175653,20.82399431517444,19.040986965156776,14.874207640396818,15.2408479054067,15.962115434563884,18.41624930147445,19.033274266285055,21.528149499406645,21.00034990880581,23.928536817377505,16.353758373021506,13.521512599393375,18.74299175607746,11.049099743143753,18.12536681496367,21.42286639913167,22.328230255130705,25.4946450656801,26.51778172518684,21.0362713066632,19.4562206751569,21.994918772354872,19.08750523260389,21.44476019256085,10.615292743964641,6.074372913206027,1.2043268401783749,11.526306723370677,14.500202686549969,21.985864988745725,21.193093736269304,17.360503363910073,14.724244635487828,20.245567663523136,21.967033310537225,19.69306058423215,21.008719795992565,23.888242314028677,23.743578938389646,27.932326101909926,26.726793627513196,24.207920500491007]}],                        {\"barmode\":\"overlay\",\"legend\":{\"bgcolor\":\"#151516\",\"font\":{\"color\":\"#D9D9D9\"}},\"paper_bgcolor\":\"#151516\",\"plot_bgcolor\":\"#151516\",\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"color\":\"#D9D9D9\"}},\"xaxis\":{\"gridcolor\":\"#434343\",\"showgrid\":true,\"tickfont\":{\"color\":\"#C2C2C2\"},\"title\":{\"font\":{\"color\":\"#D9D9D9\"},\"text\":\"\"},\"zerolinecolor\":\"#666570\"},\"yaxis\":{\"gridcolor\":\"#434343\",\"showgrid\":true,\"tickfont\":{\"color\":\"#C2C2C2\"},\"title\":{\"font\":{\"color\":\"#D9D9D9\"},\"text\":\"\"},\"zerolinecolor\":\"#666570\"}},                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('ddf1a978-81d6-42bc-ad4b-88bb63d67f55');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[[\"target\", \"y_hat\"]].iplot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sregkkOFSSdx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "diplo_cdd (3.8.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
