{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b77e85",
   "metadata": {},
   "source": [
    "# Práctica 2 — Solución Analítica (YouTube Comment Sentiment)\n",
    "\n",
    "**Dataset:** `AmaanP314/youtube-comment-sentiment` (Hugging Face)\n",
    "\n",
    "**Objetivo:**  \n",
    "1) Definir una variable objetivo discreta y una continua (y justificar).  \n",
    "2) Entrenar el mejor modelo para la discreta.  \n",
    "3) Entrenar el mejor modelo para la continua.  \n",
    "4) Interpretación en función del negocio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15efc0f4",
   "metadata": {},
   "source": [
    "## 0. Carga y exploración inicial del dataset\n",
    "\n",
    "En esta sección:\n",
    "- Cargamos el dataset desde Hugging Face.\n",
    "- Revisamos columnas disponibles.\n",
    "- Verificamos tamaño y valores faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d74653b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidmc/Documents/05-Aprendizaje/01-Diplomados/01-Ciencia_de_Datos/02-Modulo/02-Practica/.venv/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Generating train split: 100%|██████████| 1032225/1032225 [00:03<00:00, 301246.55 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1032225, 12),\n",
       " Index(['CommentID', 'VideoID', 'VideoTitle', 'AuthorName', 'AuthorChannelID',\n",
       "        'CommentText', 'Sentiment', 'Likes', 'Replies', 'PublishedAt',\n",
       "        'CountryCode', 'CategoryID'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"AmaanP314/youtube-comment-sentiment\")\n",
    "df = ds[\"train\"].to_pandas()\n",
    "\n",
    "df.shape, df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9343e23a",
   "metadata": {},
   "source": [
    "### Auditoría inicial del dataset (calidad y consistencia)\n",
    "\n",
    "Objetivos:\n",
    "1) Revisar **missing** (NaN/None) en TODAS las columnas.\n",
    "2) Detectar **missing disfrazados**: strings vacíos, espacios, \"nan\", \"null\", etc.\n",
    "3) Validar tipos (dtypes) y rangos básicos (Likes/Replies).\n",
    "4) Parsear `PublishedAt` y medir fallos de parseo.\n",
    "5) Ver cardinalidad de categóricas (`Sentiment`/`CountryCode`/`CategoryID`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88b11243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AuthorName    0.000611\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_all = df.isna().mean().sort_values(ascending=False)\n",
    "missing_all[missing_all > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b42f522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_empty_or_spaces</th>\n",
       "      <th>pct_missing_words</th>\n",
       "      <th>pct_literal_&lt;NA&gt;</th>\n",
       "      <th>examples_empty</th>\n",
       "      <th>examples_missing_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VideoTitle</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AuthorName</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AuthorChannelID</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CommentText</th>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.00016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[, , ]</td>\n",
       "      <td>[, , ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountryCode</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PublishedAt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pct_empty_or_spaces pct_missing_words pct_literal_<NA>  \\\n",
       "VideoTitle                      0.0               0.0              0.0   \n",
       "AuthorName                      0.0               0.0              0.0   \n",
       "AuthorChannelID                 0.0               0.0              0.0   \n",
       "CommentText                0.000156           0.00016              0.0   \n",
       "CountryCode                     0.0               0.0              0.0   \n",
       "PublishedAt                     0.0               0.0              0.0   \n",
       "Sentiment                       0.0               0.0              0.0   \n",
       "\n",
       "                examples_empty examples_missing_words  \n",
       "VideoTitle                  []                     []  \n",
       "AuthorName                  []                     []  \n",
       "AuthorChannelID             []                     []  \n",
       "CommentText             [, , ]                 [, , ]  \n",
       "CountryCode                 []                     []  \n",
       "PublishedAt                 []                     []  \n",
       "Sentiment                   []                     []  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def disguised_missing_stats(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(\"string\")\n",
    "    stripped = s.str.strip()\n",
    "\n",
    "    missing_words = {\"\", \"nan\", \"null\", \"none\", \"na\", \"n/a\", \"nil\", \"missing\"}\n",
    "\n",
    "    is_empty = stripped.eq(\"\")\n",
    "    is_word_missing = stripped.str.lower().isin(missing_words)\n",
    "\n",
    "    is_literal_na = stripped.eq(\"<NA>\")\n",
    "\n",
    "    return pd.Series({\n",
    "        \"pct_empty_or_spaces\": float(is_empty.mean()),\n",
    "        \"pct_missing_words\": float(is_word_missing.mean()),\n",
    "        \"pct_literal_<NA>\": float(is_literal_na.mean()),\n",
    "        \"examples_empty\": stripped[is_empty].head(3).tolist(),\n",
    "        \"examples_missing_words\": stripped[is_word_missing].head(3).tolist(),\n",
    "    })\n",
    "\n",
    "text_cols = [\"VideoTitle\", \"AuthorName\", \"AuthorChannelID\", \"CommentText\", \"CountryCode\", \"PublishedAt\", \"Sentiment\"]\n",
    "audit_text = pd.DataFrame({c: disguised_missing_stats(df[c]) for c in text_cols}).T\n",
    "audit_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "086bd05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "Negative    346075\n",
       "Positive    343317\n",
       "Neutral     342833\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9954ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pct_missing_like_empty': 0.0,\n",
       " 'len_counts_top': {np.int64(2): 1032225},\n",
       " 'sample_weird_len': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = df[\"CountryCode\"].astype(\"string\").str.strip()\n",
    "cc_len = cc.str.len()\n",
    "\n",
    "{\n",
    "    \"pct_missing_like_empty\": float((cc_len==0).mean()),\n",
    "    \"len_counts_top\": cc_len.value_counts(dropna=False).head(10).to_dict(),\n",
    "    \"sample_weird_len\": cc[~cc_len.isin([0,2])].dropna().unique()[:15].tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a52777d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pct_non_numeric': 0.0,\n",
       " 'min': 1.0,\n",
       " 'max': 28.0,\n",
       " 'n_unique': 11,\n",
       " 'top_values': {25: 332543,\n",
       "  27: 290237,\n",
       "  26: 85502,\n",
       "  17: 69322,\n",
       "  15: 49635,\n",
       "  24: 48406,\n",
       "  28: 47887,\n",
       "  2: 44749,\n",
       "  20: 32088,\n",
       "  22: 17532}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = pd.to_numeric(df[\"CategoryID\"], errors=\"coerce\")\n",
    "{\n",
    "    \"pct_non_numeric\": float(cat.isna().mean()),\n",
    "    \"min\": float(cat.min()),\n",
    "    \"max\": float(cat.max()),\n",
    "    \"n_unique\": int(cat.nunique(dropna=True)),\n",
    "    \"top_values\": cat.value_counts().head(10).to_dict()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21e930e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'likes_pct_non_numeric': 0.0,\n",
       " 'replies_pct_non_numeric': 0.0,\n",
       " 'likes_pct_negative': 0.0,\n",
       " 'replies_pct_negative': 0.0,\n",
       " 'likes_desc': {'count': 1032225.0,\n",
       "  'mean': 101.66075419603284,\n",
       "  'std': 1538.978145542954,\n",
       "  'min': 0.0,\n",
       "  '50%': 0.0,\n",
       "  '90%': 35.0,\n",
       "  '95%': 157.0,\n",
       "  '99%': 1633.0,\n",
       "  'max': 275849.0},\n",
       " 'replies_desc': {'count': 1032225.0,\n",
       "  'mean': 2.023081208069946,\n",
       "  'std': 14.144702381178911,\n",
       "  'min': 0.0,\n",
       "  '50%': 0.0,\n",
       "  '90%': 2.0,\n",
       "  '95%': 7.0,\n",
       "  '99%': 42.0,\n",
       "  'max': 751.0}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likes = pd.to_numeric(df[\"Likes\"], errors=\"coerce\")\n",
    "replies = pd.to_numeric(df[\"Replies\"], errors=\"coerce\")\n",
    "\n",
    "{\n",
    "    \"likes_pct_non_numeric\": float(likes.isna().mean()),\n",
    "    \"replies_pct_non_numeric\": float(replies.isna().mean()),\n",
    "    \"likes_pct_negative\": float((likes < 0).mean()),\n",
    "    \"replies_pct_negative\": float((replies < 0).mean()),\n",
    "    \"likes_desc\": likes.describe(percentiles=[.5,.9,.95,.99]).to_dict(),\n",
    "    \"replies_desc\": replies.describe(percentiles=[.5,.9,.95,.99]).to_dict(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba2d3849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pct_parse_fail': 0.0,\n",
       " 'min_dt': '2013-04-05 22:47:16+00:00',\n",
       " 'max_dt': '2025-02-05 14:33:11+00:00',\n",
       " 'sample_raw_failures': []}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "published_dt = pd.to_datetime(df[\"PublishedAt\"], errors=\"coerce\", utc=True)\n",
    "\n",
    "{\n",
    "    \"pct_parse_fail\": float(published_dt.isna().mean()),\n",
    "    \"min_dt\": str(published_dt.min()),\n",
    "    \"max_dt\": str(published_dt.max()),\n",
    "    \"sample_raw_failures\": df.loc[published_dt.isna(), \"PublishedAt\"].astype(\"string\").head(10).tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35f8bd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pct_dup_commentid': 0.00035457385744387123,\n",
       " 'pct_dup_commenttext': 0.04103368936036232}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_commentid = df[\"CommentID\"].duplicated().mean()\n",
    "dup_text = df[\"CommentText\"].astype(\"string\").str.strip().duplicated().mean()\n",
    "\n",
    "{\"pct_dup_commentid\": float(dup_commentid), \"pct_dup_commenttext\": float(dup_text)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2c58bd",
   "metadata": {},
   "source": [
    "### Limpieza final para modelado\n",
    "\n",
    "Aplicamos limpieza mínima y justificada:\n",
    "\n",
    "1) Eliminamos comentarios con `CommentText` vacío (espacios).\n",
    "2) Eliminamos duplicados por `CommentID` (consistencia de identificador).\n",
    "3) Parseamos `PublishedAt` a datetime y creamos variables de tiempo.\n",
    "4) (Opcional) Eliminamos duplicados exactos de `CommentText` para reducir leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ca8857d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1031698, 19),\n",
       "                                          CommentText    y_disc  Likes  \\\n",
       " 0                    Anyone know what movie this is?   Neutral      0   \n",
       " 1  The fact they're holding each other back while...  Positive      0   \n",
       " 2                        waiting next video will be?   Neutral      1   \n",
       " \n",
       "    Replies  hour  dow  month  is_weekend    y_cont  \n",
       " 0        2     0    2      1           0  0.000000  \n",
       " 1        0    23    0      1           0  0.000000  \n",
       " 2        0    13    0      7           0  0.693147  )"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model = df.copy()\n",
    "\n",
    "# 1) Quitar textos vacíos o solo espacios\n",
    "df_model[\"CommentText\"] = df_model[\"CommentText\"].astype(\"string\")\n",
    "mask_nonempty = df_model[\"CommentText\"].str.strip().fillna(\"\").ne(\"\")\n",
    "df_model = df_model[mask_nonempty].copy()\n",
    "\n",
    "# 2) Deduplicar por CommentID (mantener primera ocurrencia)\n",
    "df_model = df_model.drop_duplicates(subset=[\"CommentID\"], keep=\"first\").copy()\n",
    "\n",
    "# 3) Parseo de fecha + features temporales\n",
    "df_model[\"published_dt\"] = pd.to_datetime(df_model[\"PublishedAt\"], errors=\"coerce\", utc=True)\n",
    "df_model[\"hour\"] = df_model[\"published_dt\"].dt.hour\n",
    "df_model[\"dow\"] = df_model[\"published_dt\"].dt.dayofweek\n",
    "df_model[\"month\"] = df_model[\"published_dt\"].dt.month\n",
    "df_model[\"is_weekend\"] = df_model[\"dow\"].isin([5,6]).astype(int)\n",
    "\n",
    "# Targets\n",
    "df_model[\"y_disc\"] = df_model[\"Sentiment\"].astype(str)\n",
    "df_model[\"Likes\"] = pd.to_numeric(df_model[\"Likes\"], errors=\"coerce\")\n",
    "df_model[\"Replies\"] = pd.to_numeric(df_model[\"Replies\"], errors=\"coerce\")\n",
    "\n",
    "df_model[\"y_cont\"] = np.log1p(df_model[\"Likes\"].astype(float))\n",
    "\n",
    "df_model.shape, df_model[[\"CommentText\",\"y_disc\",\"Likes\",\"Replies\",\"hour\",\"dow\",\"month\",\"is_weekend\",\"y_cont\"]].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7969b1",
   "metadata": {},
   "source": [
    "## 1. Variables objetivo\n",
    "\n",
    "Se requieren dos variables objetivo:\n",
    "\n",
    "### 1.1 Variable objetivo discreta (clasificación)\n",
    "Definimos la variable objetivo discreta como:\n",
    "\n",
    "- **y_disc = Sentiment** ∈ {Negative, Neutral, Positive}\n",
    "\n",
    "**Justificación / utilidad (negocio):**\n",
    "Clasificar el sentimiento de comentarios permite monitorear reputación, moderación de contenido, priorización de atención y análisis del clima de la comunidad.\n",
    "\n",
    "### 1.2 Variable objetivo continua (regresión)\n",
    "Definimos la variable objetivo continua como el engagement del comentario medido por likes:\n",
    "\n",
    "- **Likes** = número de \"me gusta\" del comentario  \n",
    "- Debido a que `Likes` suele ser altamente asimétrico (muchos ceros y pocos valores grandes), se usa:\n",
    "- **y_cont = log1p(Likes)** = log(1 + Likes)\n",
    "\n",
    "**Justificación / utilidad (negocio):**\n",
    "Predecir engagement permite priorizar comentarios valiosos, mejorar ranking/visibilidad y asignar recursos de moderación o respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98a39f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_disc</th>\n",
       "      <th>Likes</th>\n",
       "      <th>y_cont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>3</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_disc  Likes    y_cont\n",
       "0   Neutral      0  0.000000\n",
       "1  Positive      0  0.000000\n",
       "2   Neutral      1  0.693147\n",
       "3   Neutral      0  0.000000\n",
       "4  Positive      3  1.386294"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model[[\"y_disc\", \"Likes\", \"y_cont\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5511ce4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y_disc\n",
       "Negative    0.3354\n",
       "Positive    0.3326\n",
       "Neutral     0.3321\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model[\"y_disc\"].value_counts(normalize=True).round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
