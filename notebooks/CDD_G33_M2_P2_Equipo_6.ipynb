{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b77e85",
   "metadata": {},
   "source": [
    "# Práctica 2 — Solución Analítica (YouTube Comment Sentiment)\n",
    "\n",
    "**Dataset:** `AmaanP314/youtube-comment-sentiment` (Hugging Face)\n",
    "\n",
    "**Objetivo:**  \n",
    "1) Definir una variable objetivo discreta y una continua (y justificar).  \n",
    "2) Entrenar el mejor modelo para la discreta.  \n",
    "3) Entrenar el mejor modelo para la continua.  \n",
    "4) Interpretación en función del negocio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "61a72230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, classification_report, mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15efc0f4",
   "metadata": {},
   "source": [
    "## 0. Carga y exploración inicial del dataset\n",
    "\n",
    "En esta sección:\n",
    "- Cargamos el dataset desde Hugging Face.\n",
    "- Revisamos columnas disponibles.\n",
    "- Verificamos tamaño y valores faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d74653b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1032225, 12),\n",
       " Index(['CommentID', 'VideoID', 'VideoTitle', 'AuthorName', 'AuthorChannelID',\n",
       "        'CommentText', 'Sentiment', 'Likes', 'Replies', 'PublishedAt',\n",
       "        'CountryCode', 'CategoryID'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"AmaanP314/youtube-comment-sentiment\")\n",
    "df = ds[\"train\"].to_pandas()\n",
    "\n",
    "df.shape, df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9343e23a",
   "metadata": {},
   "source": [
    "### Auditoría inicial del dataset (calidad y consistencia)\n",
    "\n",
    "Objetivos:\n",
    "1) Revisar **missing** (NaN/None) en TODAS las columnas.\n",
    "2) Detectar **missing disfrazados**: strings vacíos, espacios, \"nan\", \"null\", etc.\n",
    "3) Validar tipos (dtypes) y rangos básicos (Likes/Replies).\n",
    "4) Parsear `PublishedAt` y medir fallos de parseo.\n",
    "5) Ver cardinalidad de categóricas (`Sentiment`/`CountryCode`/`CategoryID`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "88b11243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AuthorName    0.000611\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_all = df.isna().mean().sort_values(ascending=False)\n",
    "missing_all[missing_all > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3b42f522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_empty_or_spaces</th>\n",
       "      <th>pct_missing_words</th>\n",
       "      <th>pct_literal_&lt;NA&gt;</th>\n",
       "      <th>examples_empty</th>\n",
       "      <th>examples_missing_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VideoTitle</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AuthorName</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AuthorChannelID</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CommentText</th>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.00016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[, , ]</td>\n",
       "      <td>[, , ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountryCode</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PublishedAt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pct_empty_or_spaces pct_missing_words pct_literal_<NA>  \\\n",
       "VideoTitle                      0.0               0.0              0.0   \n",
       "AuthorName                      0.0               0.0              0.0   \n",
       "AuthorChannelID                 0.0               0.0              0.0   \n",
       "CommentText                0.000156           0.00016              0.0   \n",
       "CountryCode                     0.0               0.0              0.0   \n",
       "PublishedAt                     0.0               0.0              0.0   \n",
       "Sentiment                       0.0               0.0              0.0   \n",
       "\n",
       "                examples_empty examples_missing_words  \n",
       "VideoTitle                  []                     []  \n",
       "AuthorName                  []                     []  \n",
       "AuthorChannelID             []                     []  \n",
       "CommentText             [, , ]                 [, , ]  \n",
       "CountryCode                 []                     []  \n",
       "PublishedAt                 []                     []  \n",
       "Sentiment                   []                     []  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def disguised_missing_stats(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(\"string\")\n",
    "    stripped = s.str.strip()\n",
    "\n",
    "    missing_words = {\"\", \"nan\", \"null\", \"none\", \"na\", \"n/a\", \"nil\", \"missing\"}\n",
    "\n",
    "    is_empty = stripped.eq(\"\")\n",
    "    is_word_missing = stripped.str.lower().isin(missing_words)\n",
    "\n",
    "    is_literal_na = stripped.eq(\"<NA>\")\n",
    "\n",
    "    return pd.Series({\n",
    "        \"pct_empty_or_spaces\": float(is_empty.mean()),\n",
    "        \"pct_missing_words\": float(is_word_missing.mean()),\n",
    "        \"pct_literal_<NA>\": float(is_literal_na.mean()),\n",
    "        \"examples_empty\": stripped[is_empty].head(3).tolist(),\n",
    "        \"examples_missing_words\": stripped[is_word_missing].head(3).tolist(),\n",
    "    })\n",
    "\n",
    "text_cols = [\"VideoTitle\", \"AuthorName\", \"AuthorChannelID\", \"CommentText\", \"CountryCode\", \"PublishedAt\", \"Sentiment\"]\n",
    "audit_text = pd.DataFrame({c: disguised_missing_stats(df[c]) for c in text_cols}).T\n",
    "audit_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "086bd05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "Negative    346075\n",
       "Positive    343317\n",
       "Neutral     342833\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f9954ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pct_missing_like_empty': 0.0,\n",
       " 'len_counts_top': {np.int64(2): 1032225},\n",
       " 'sample_weird_len': []}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = df[\"CountryCode\"].astype(\"string\").str.strip()\n",
    "cc_len = cc.str.len()\n",
    "\n",
    "{\n",
    "    \"pct_missing_like_empty\": float((cc_len==0).mean()),\n",
    "    \"len_counts_top\": cc_len.value_counts(dropna=False).head(10).to_dict(),\n",
    "    \"sample_weird_len\": cc[~cc_len.isin([0,2])].dropna().unique()[:15].tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6a52777d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pct_non_numeric': 0.0,\n",
       " 'min': 1.0,\n",
       " 'max': 28.0,\n",
       " 'n_unique': 11,\n",
       " 'top_values': {25: 332543,\n",
       "  27: 290237,\n",
       "  26: 85502,\n",
       "  17: 69322,\n",
       "  15: 49635,\n",
       "  24: 48406,\n",
       "  28: 47887,\n",
       "  2: 44749,\n",
       "  20: 32088,\n",
       "  22: 17532}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = pd.to_numeric(df[\"CategoryID\"], errors=\"coerce\")\n",
    "{\n",
    "    \"pct_non_numeric\": float(cat.isna().mean()),\n",
    "    \"min\": float(cat.min()),\n",
    "    \"max\": float(cat.max()),\n",
    "    \"n_unique\": int(cat.nunique(dropna=True)),\n",
    "    \"top_values\": cat.value_counts().head(10).to_dict()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "21e930e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'likes_pct_non_numeric': 0.0,\n",
       " 'replies_pct_non_numeric': 0.0,\n",
       " 'likes_pct_negative': 0.0,\n",
       " 'replies_pct_negative': 0.0,\n",
       " 'likes_desc': {'count': 1032225.0,\n",
       "  'mean': 101.66075419603284,\n",
       "  'std': 1538.978145542954,\n",
       "  'min': 0.0,\n",
       "  '50%': 0.0,\n",
       "  '90%': 35.0,\n",
       "  '95%': 157.0,\n",
       "  '99%': 1633.0,\n",
       "  'max': 275849.0},\n",
       " 'replies_desc': {'count': 1032225.0,\n",
       "  'mean': 2.023081208069946,\n",
       "  'std': 14.144702381178911,\n",
       "  'min': 0.0,\n",
       "  '50%': 0.0,\n",
       "  '90%': 2.0,\n",
       "  '95%': 7.0,\n",
       "  '99%': 42.0,\n",
       "  'max': 751.0}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likes = pd.to_numeric(df[\"Likes\"], errors=\"coerce\")\n",
    "replies = pd.to_numeric(df[\"Replies\"], errors=\"coerce\")\n",
    "\n",
    "{\n",
    "    \"likes_pct_non_numeric\": float(likes.isna().mean()),\n",
    "    \"replies_pct_non_numeric\": float(replies.isna().mean()),\n",
    "    \"likes_pct_negative\": float((likes < 0).mean()),\n",
    "    \"replies_pct_negative\": float((replies < 0).mean()),\n",
    "    \"likes_desc\": likes.describe(percentiles=[.5,.9,.95,.99]).to_dict(),\n",
    "    \"replies_desc\": replies.describe(percentiles=[.5,.9,.95,.99]).to_dict(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ba2d3849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pct_parse_fail': 0.0,\n",
       " 'min_dt': '2013-04-05 22:47:16+00:00',\n",
       " 'max_dt': '2025-02-05 14:33:11+00:00',\n",
       " 'sample_raw_failures': []}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "published_dt = pd.to_datetime(df[\"PublishedAt\"], errors=\"coerce\", utc=True)\n",
    "\n",
    "{\n",
    "    \"pct_parse_fail\": float(published_dt.isna().mean()),\n",
    "    \"min_dt\": str(published_dt.min()),\n",
    "    \"max_dt\": str(published_dt.max()),\n",
    "    \"sample_raw_failures\": df.loc[published_dt.isna(), \"PublishedAt\"].astype(\"string\").head(10).tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "35f8bd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pct_dup_commentid': 0.00035457385744387123,\n",
       " 'pct_dup_commenttext': 0.04103368936036232}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_commentid = df[\"CommentID\"].duplicated().mean()\n",
    "dup_text = df[\"CommentText\"].astype(\"string\").str.strip().duplicated().mean()\n",
    "\n",
    "{\"pct_dup_commentid\": float(dup_commentid), \"pct_dup_commenttext\": float(dup_text)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2c58bd",
   "metadata": {},
   "source": [
    "### Limpieza final para modelado\n",
    "\n",
    "Aplicamos limpieza mínima y justificada:\n",
    "\n",
    "1) Eliminamos comentarios con `CommentText` vacío (espacios).\n",
    "2) Eliminamos duplicados por `CommentID` (consistencia de identificador).\n",
    "3) Parseamos `PublishedAt` a datetime y creamos variables de tiempo.\n",
    "4) (Opcional) Eliminamos duplicados exactos de `CommentText` para reducir leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7ca8857d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1031698, 19),\n",
       "                                          CommentText    y_disc  Likes  \\\n",
       " 0                    Anyone know what movie this is?   Neutral      0   \n",
       " 1  The fact they're holding each other back while...  Positive      0   \n",
       " 2                        waiting next video will be?   Neutral      1   \n",
       " \n",
       "    Replies  hour  dow  month  is_weekend    y_cont  \n",
       " 0        2     0    2      1           0  0.000000  \n",
       " 1        0    23    0      1           0  0.000000  \n",
       " 2        0    13    0      7           0  0.693147  )"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model = df.copy()\n",
    "\n",
    "# 1) Quitar textos vacíos o solo espacios\n",
    "df_model[\"CommentText\"] = df_model[\"CommentText\"].astype(\"string\")\n",
    "mask_nonempty = df_model[\"CommentText\"].str.strip().fillna(\"\").ne(\"\")\n",
    "df_model = df_model[mask_nonempty].copy()\n",
    "\n",
    "# 2) Deduplicar por CommentID (mantener primera ocurrencia)\n",
    "df_model = df_model.drop_duplicates(subset=[\"CommentID\"], keep=\"first\").copy()\n",
    "\n",
    "# 3) Parseo de fecha + features temporales\n",
    "df_model[\"published_dt\"] = pd.to_datetime(df_model[\"PublishedAt\"], errors=\"coerce\", utc=True)\n",
    "df_model[\"hour\"] = df_model[\"published_dt\"].dt.hour\n",
    "df_model[\"dow\"] = df_model[\"published_dt\"].dt.dayofweek\n",
    "df_model[\"month\"] = df_model[\"published_dt\"].dt.month\n",
    "df_model[\"is_weekend\"] = df_model[\"dow\"].isin([5,6]).astype(int)\n",
    "\n",
    "# Targets\n",
    "df_model[\"y_disc\"] = df_model[\"Sentiment\"].astype(str)\n",
    "df_model[\"Likes\"] = pd.to_numeric(df_model[\"Likes\"], errors=\"coerce\")\n",
    "df_model[\"Replies\"] = pd.to_numeric(df_model[\"Replies\"], errors=\"coerce\")\n",
    "\n",
    "df_model[\"y_cont\"] = np.log1p(df_model[\"Likes\"].astype(float))\n",
    "\n",
    "df_model.shape, df_model[[\"CommentText\",\"y_disc\",\"Likes\",\"Replies\",\"hour\",\"dow\",\"month\",\"is_weekend\",\"y_cont\"]].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7969b1",
   "metadata": {},
   "source": [
    "## 1. Variables objetivo\n",
    "\n",
    "Se requieren dos variables objetivo:\n",
    "\n",
    "### 1.1 Variable objetivo discreta (clasificación)\n",
    "Definimos la variable objetivo discreta como:\n",
    "\n",
    "- **y_disc = Sentiment** ∈ {Negative, Neutral, Positive}\n",
    "\n",
    "**Justificación / utilidad (negocio):**\n",
    "Clasificar el sentimiento de comentarios permite monitorear reputación, moderación de contenido, priorización de atención y análisis del clima de la comunidad.\n",
    "\n",
    "### 1.2 Variable objetivo continua (regresión)\n",
    "Definimos la variable objetivo continua como el engagement del comentario medido por likes:\n",
    "\n",
    "- **Likes** = número de \"me gusta\" del comentario  \n",
    "- Debido a que `Likes` suele ser altamente asimétrico (muchos ceros y pocos valores grandes), se usa:\n",
    "- **y_cont = log1p(Likes)** = log(1 + Likes)\n",
    "\n",
    "**Justificación / utilidad (negocio):**\n",
    "Predecir engagement permite priorizar comentarios valiosos, mejorar ranking/visibilidad y asignar recursos de moderación o respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "98a39f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_disc</th>\n",
       "      <th>Likes</th>\n",
       "      <th>y_cont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>3</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_disc  Likes    y_cont\n",
       "0   Neutral      0  0.000000\n",
       "1  Positive      0  0.000000\n",
       "2   Neutral      1  0.693147\n",
       "3   Neutral      0  0.000000\n",
       "4  Positive      3  1.386294"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model[[\"y_disc\", \"Likes\", \"y_cont\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5511ce4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y_disc\n",
       "Negative    0.3354\n",
       "Positive    0.3326\n",
       "Neutral     0.3321\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model[\"y_disc\"].value_counts(normalize=True).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbd0496",
   "metadata": {},
   "source": [
    "## 2. Selección del mejor modelo (clasificación)\n",
    "\n",
    "Se comparan varios modelos lineales sobre una misma representación TF-IDF:\n",
    "\n",
    "- LogisticRegression (baseline)\n",
    "- SGDClassifier (varias pérdidas / regularizaciones)\n",
    "\n",
    "Criterios de evaluación:\n",
    "- **F1-macro** (principal, multiclass)\n",
    "- **ROC-AUC One-vs-Rest (OVR)** (si hay `predict_proba` o `decision_function`)\n",
    "- Matriz de confusión y reporte por clase\n",
    "\n",
    "Se elige como “mejor” el modelo con mejor desempeño promedio en validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b5cd829d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((350000,), (150000,))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_work = df_model.sample(500_000, random_state=777)\n",
    "\n",
    "X = df_work[\"CommentText\"].astype(str)\n",
    "y = df_work[\"y_disc\"].astype(str)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=777, stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fca41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(pipe, X_train, y_train, X_test, y_test):\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pred = pipe.predict(X_test)\n",
    "\n",
    "    out = {\n",
    "        \"accuracy\": accuracy_score(y_test, pred),\n",
    "        \"f1_macro\": f1_score(y_test, pred, average=\"macro\"),\n",
    "    }\n",
    "\n",
    "    # ROC-AUC OVR (si es posible)\n",
    "    try:\n",
    "        if hasattr(pipe, \"predict_proba\"):\n",
    "            scores = pipe.predict_proba(X_test)\n",
    "            out[\"roc_auc_ovr\"] = roc_auc_score(y_test, scores, multi_class=\"ovr\")\n",
    "        elif hasattr(pipe, \"decision_function\"):\n",
    "            scores = pipe.decision_function(X_test)\n",
    "            out[\"roc_auc_ovr\"] = roc_auc_score(y_test, scores, multi_class=\"ovr\")\n",
    "        else:\n",
    "            out[\"roc_auc_ovr\"] = np.nan\n",
    "    except Exception:\n",
    "        out[\"roc_auc_ovr\"] = np.nan\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ffeb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    }
   ],
   "source": [
    "pipe_sgd = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), min_df=3, max_df=0.9)),\n",
    "    (\"model\", SGDClassifier(random_state=777))\n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    \"model__loss\": [\"log_loss\", \"modified_huber\", \"hinge\"],\n",
    "    \"model__penalty\": [\"l2\", \"l1\", \"elasticnet\"],\n",
    "    \"model__alpha\": np.logspace(-6, -3, 30),\n",
    "    \"model__l1_ratio\": np.linspace(0, 1, 11),\n",
    "}\n",
    "\n",
    "search_sgd = RandomizedSearchCV(\n",
    "    pipe_sgd,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=777,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "search_sgd.fit(X_train, y_train)\n",
    "best_cls = search_sgd.best_estimator_\n",
    "search_sgd.best_params_, search_sgd.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59399c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 macro (test): 0.6810307360797688\n",
      "ROC-AUC OVR (test): 0.8468439276470052\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.67      0.70      0.68     20104\n",
      "     Neutral       0.62      0.65      0.64     19911\n",
      "    Positive       0.76      0.69      0.72     19985\n",
      "\n",
      "    accuracy                           0.68     60000\n",
      "   macro avg       0.68      0.68      0.68     60000\n",
      "weighted avg       0.68      0.68      0.68     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = best_cls.predict(X_test)\n",
    "\n",
    "print(\"F1 macro (test):\", f1_score(y_test, pred, average=\"macro\"))\n",
    "# ROC-AUC OVR (si aplica)\n",
    "try:\n",
    "    if hasattr(best_cls, \"predict_proba\"):\n",
    "        scores = best_cls.predict_proba(X_test)\n",
    "    else:\n",
    "        scores = best_cls.decision_function(X_test)\n",
    "    print(\"ROC-AUC OVR (test):\", roc_auc_score(y_test, scores, multi_class=\"ovr\"))\n",
    "except Exception as e:\n",
    "    print(\"ROC-AUC no disponible:\", e)\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed640d9f",
   "metadata": {},
   "source": [
    "## 3. Selección del mejor modelo (regresión)\n",
    "\n",
    "Se comparan modelos lineales vistos en clase sobre TF-IDF:\n",
    "\n",
    "- LinearRegression (referencia)\n",
    "- Ridge, Lasso, ElasticNet (regularizados)\n",
    "- SGDRegressor (descenso estocástico)\n",
    "\n",
    "Métricas:\n",
    "- MAE (principal, interpretable)\n",
    "- RMSE\n",
    "- R²\n",
    "\n",
    "Se elige el mejor modelo por desempeño promedio en validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39daef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xr = df_work[\"CommentText\"].astype(str)\n",
    "yr = df_work[\"y_cont\"].astype(float)\n",
    "\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
    "    Xr, yr, test_size=0.30, random_state=777\n",
    ")\n",
    "\n",
    "X_train_r.shape, X_test_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b986f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_regressor(pipe, X_train, y_train, X_test, y_test):\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pred = pipe.predict(X_test)\n",
    "    return {\n",
    "        \"mae\": mean_absolute_error(y_test, pred),\n",
    "        \"rmse\": mean_squared_error(y_test, pred, squared=False),\n",
    "        \"r2\": r2_score(y_test, pred),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4599e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_r = TfidfVectorizer(ngram_range=(1,2), min_df=3, max_df=0.9)\n",
    "\n",
    "models_reg = {\n",
    "    \"LinReg\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"Lasso\": Lasso(alpha=1e-4, max_iter=5000),\n",
    "    \"ElasticNet\": ElasticNet(alpha=1e-4, l1_ratio=0.15, max_iter=5000),\n",
    "    \"SGDRegressor\": SGDRegressor(penalty=\"l2\", alpha=1e-5, random_state=777),\n",
    "}\n",
    "\n",
    "results_reg = []\n",
    "fitted_reg = {}\n",
    "\n",
    "for name, model in models_reg.items():\n",
    "    pipe = Pipeline([(\"tfidf\", vectorizer_r), (\"model\", model)])\n",
    "    metrics = evaluate_regressor(pipe, X_train_r, y_train_r, X_test_r, y_test_r)\n",
    "    metrics[\"model\"] = name\n",
    "    results_reg.append(metrics)\n",
    "    fitted_reg[name] = pipe\n",
    "\n",
    "pd.DataFrame(results_reg).sort_values(\"mae\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfeb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_ridge = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), min_df=3, max_df=0.9)),\n",
    "    (\"model\", Ridge())\n",
    "])\n",
    "\n",
    "grid = {\"model__alpha\": np.logspace(-2, 3, 15)}\n",
    "\n",
    "search_ridge = GridSearchCV(\n",
    "    pipe_ridge, grid, scoring=\"r2\", cv=3, n_jobs=-1, verbose=1\n",
    ")\n",
    "search_ridge.fit(X_train_r, y_train_r)\n",
    "\n",
    "best_reg = search_ridge.best_estimator_\n",
    "search_ridge.best_params_, search_ridge.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f69f62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_r = best_reg.predict(X_test_r)\n",
    "\n",
    "mae = mean_absolute_error(y_test_r, pred_r)\n",
    "rmse = mean_squared_error(y_test_r, pred_r, squared=False)\n",
    "r2 = r2_score(y_test_r, pred_r)\n",
    "\n",
    "mae, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3bc05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = best_cls.named_steps[\"tfidf\"]\n",
    "clf = best_cls.named_steps[\"model\"]\n",
    "\n",
    "feat = np.array(tfidf.get_feature_names_out())\n",
    "classes = clf.classes_\n",
    "coefs = clf.coef_\n",
    "\n",
    "top_n = 15\n",
    "for i, c in enumerate(classes):\n",
    "    top_pos = np.argsort(coefs[i])[-top_n:][::-1]\n",
    "    print(f\"\\nClase {c} - términos que empujan hacia {c}:\")\n",
    "    print(feat[top_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf79e041",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_r = best_reg.named_steps[\"tfidf\"]\n",
    "reg = best_reg.named_steps[\"model\"]\n",
    "\n",
    "feat_r = np.array(tfidf_r.get_feature_names_out())\n",
    "coef_r = reg.coef_\n",
    "\n",
    "top_n = 20\n",
    "top_pos = np.argsort(coef_r)[-top_n:][::-1]\n",
    "top_neg = np.argsort(coef_r)[:top_n]\n",
    "\n",
    "print(\"Aumentan engagement (log1p likes):\")\n",
    "print(feat_r[top_pos])\n",
    "\n",
    "print(\"\\nDisminuyen engagement (log1p likes):\")\n",
    "print(feat_r[top_neg])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
